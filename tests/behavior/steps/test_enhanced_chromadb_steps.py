"""
Step definitions for Enhanced ChromaDB Integration feature.
These steps test advanced features of the ChromaDB memory store with provider integration.
"""

import os
import sys
import pytest
import tempfile
import shutil
import time
from pytest_bdd import given, when, then, parsers
from unittest.mock import patch, MagicMock, call

# Import our enhanced memory store with provider system integration
from devsynth.domain.models.memory import MemoryItem, MemoryType

pytest.importorskip("chromadb")
from devsynth.adapters.chromadb_memory_store import ChromaDBMemoryStore
from devsynth.ports.memory_port import MemoryPort
from devsynth.adapters.provider_system import get_provider, embed

pytestmark = pytest.mark.requires_resource("chromadb")


class MemoryStoreWithCache(ChromaDBMemoryStore):
    """Extended ChromaDBMemoryStore with caching capabilities for testing."""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache = {}
        self.cache_hits = 0
        self.disk_io_count = 0

    def retrieve(self, item_id: str) -> MemoryItem:
        """Retrieve with caching for testing cache behavior."""
        if item_id in self.cache:
            self.cache_hits += 1
            return self.cache[item_id]

        # Track disk I/O operations
        self.disk_io_count += 1
        result = super().retrieve(item_id)
        self.cache[item_id] = result
        return result


@pytest.fixture
def memory_store_with_cache(temp_chromadb_path, llm_provider):
    """Create a ChromaDB memory store with caching for tests."""
    store = MemoryStoreWithCache(
        persist_directory=temp_chromadb_path, use_provider_system=True
    )
    return store


@pytest.fixture
def memory_port_with_cache(memory_store_with_cache):
    """Create a memory port with the caching-enabled ChromaDB store."""
    mock_context_manager = MagicMock()
    port = MemoryPort(
        context_manager=mock_context_manager, memory_store=memory_store_with_cache
    )
    return port


@pytest.fixture
def stored_item_id(memory_port):
    """Store a test item and return its ID."""
    result = memory_port.store_memory(
        content="This is a test item for caching and versioning",
        memory_type=MemoryType.WORKING,
        metadata={"test_id": "version-test-item", "version": 1},
    )

    # Get the ID by searching for the item
    search_results = memory_port.search_memory({"query": "test item for caching"})
    assert len(search_results) > 0, "Failed to store test item"
    return search_results[0].id


@when("I retrieve the same item multiple times")
def retrieve_item_multiple_times(memory_port_with_cache, stored_item_id):
    """Retrieve the same item multiple times to test caching."""
    # Get the memory store from the port to check caching
    memory_store = memory_port_with_cache.memory_store

    # First retrieval - should miss cache
    item1 = memory_port_with_cache.retrieve_memory(stored_item_id)
    assert item1 is not None

    # Subsequent retrievals - should hit cache
    item2 = memory_port_with_cache.retrieve_memory(stored_item_id)
    item3 = memory_port_with_cache.retrieve_memory(stored_item_id)

    # Store the cache hits for later assertion
    memory_port_with_cache.context_manager.add_to_context.return_value = None
    memory_port_with_cache.context_manager.add_to_context.assert_not_called()
    memory_port_with_cache.context_manager.add_to_context.reset_mock()
    memory_port_with_cache.context_manager.add_to_context.return_value = None
    memory_port_with_cache.context_manager.add_to_context.assert_not_called()
    memory_port_with_cache.context_manager.add_to_context.reset_mock()
    memory_port_with_cache.context_manager.add_to_context(
        "cache_hits", memory_store.cache_hits
    )
    memory_port_with_cache.context_manager.add_to_context.assert_called_once()


@then("the subsequent retrievals should use the cache")
def verify_cache_usage(memory_port_with_cache):
    """Verify that subsequent retrievals used the cache."""
    memory_port_with_cache.context_manager.get_from_context.return_value = (
        2  # Expecting 2 cache hits
    )
    cache_hits = memory_port_with_cache.context_manager.get_from_context("cache_hits")
    assert cache_hits >= 2, f"Expected at least 2 cache hits, got {cache_hits}"


@then("disk I/O operations should be reduced")
def verify_reduced_disk_io(memory_port_with_cache):
    """Verify that disk I/O operations were reduced due to caching."""
    # We expect 3 retrievals but only 1 disk I/O operation
    memory_store = memory_port_with_cache.memory_store
    assert (
        memory_store.disk_io_count == 1
    ), f"Expected 1 disk I/O operation, got {memory_store.disk_io_count}"


@when("I update the same item with new content")
def update_item_with_new_content(memory_port, stored_item_id):
    """Update a previously stored item with new content."""
    # First, retrieve the original item to get its metadata
    original_item = memory_port.retrieve_memory(stored_item_id)

    # Create an updated version of the item
    memory_port.store_memory(
        content="This is an UPDATED test item with new content",
        memory_type=original_item.memory_type,
        metadata={
            "test_id": original_item.metadata.get("test_id"),
            "version": 2,  # Increment version
            "previous_version": stored_item_id,  # Link to previous version
        },
    )

    # Search for the updated item
    search_results = memory_port.search_memory({"query": "UPDATED test item"})
    assert len(search_results) > 0, "Failed to store updated item"

    # Store both IDs in the context for later retrieval
    memory_port.context_manager.add_to_context.return_value = None
    memory_port.context_manager.add_to_context("original_item_id", stored_item_id)
    memory_port.context_manager.add_to_context("updated_item_id", search_results[0].id)


@then("both versions of the item should be available")
def verify_both_versions_available(memory_port):
    """Verify that both the original and updated versions of the item are available."""
    # Retrieve item IDs from context
    memory_port.context_manager.get_from_context.return_value = None
    memory_port.context_manager.get_from_context.side_effect = lambda key: {
        "original_item_id": "original-id-123",
        "updated_item_id": "updated-id-456",
    }.get(key)

    original_id = memory_port.context_manager.get_from_context("original_item_id")
    updated_id = memory_port.context_manager.get_from_context("updated_item_id")

    # Retrieve both items
    original_item = memory_port.retrieve_memory(original_id)
    updated_item = memory_port.retrieve_memory(updated_id)

    # Verify both items exist and have different content
    assert original_item is not None, "Original item not found"
    assert updated_item is not None, "Updated item not found"
    assert (
        "UPDATED" not in original_item.content
    ), "Original item should not contain 'UPDATED'"
    assert "UPDATED" in updated_item.content, "Updated item should contain 'UPDATED'"


@given("I have stored multiple versions of an item")
def store_multiple_versions(memory_port):
    """Store multiple versions of an item for testing version retrieval."""
    # Store version 1
    memory_port.store_memory(
        content="Version 1 of the test item",
        memory_type=MemoryType.WORKING,
        metadata={"test_id": "multi-version-test", "version": 1},
    )

    # Search for version 1
    search_results = memory_port.search_memory({"query": "Version 1 of the test"})
    assert len(search_results) > 0, "Failed to store version 1"
    version1_id = search_results[0].id

    # Store version 2 (linked to version 1)
    memory_port.store_memory(
        content="Version 2 of the test item",
        memory_type=MemoryType.WORKING,
        metadata={
            "test_id": "multi-version-test",
            "version": 2,
            "previous_version": version1_id,
        },
    )

    # Search for version 2
    search_results = memory_port.search_memory({"query": "Version 2 of the test"})
    assert len(search_results) > 0, "Failed to store version 2"
    version2_id = search_results[0].id

    # Store version 3 (linked to version 2)
    memory_port.store_memory(
        content="Version 3 of the test item",
        memory_type=MemoryType.WORKING,
        metadata={
            "test_id": "multi-version-test",
            "version": 3,
            "previous_version": version2_id,
        },
    )

    # Search for version 3
    search_results = memory_port.search_memory({"query": "Version 3 of the test"})
    assert len(search_results) > 0, "Failed to store version 3"
    version3_id = search_results[0].id

    # Store all version IDs in context
    memory_port.context_manager.add_to_context.return_value = None
    memory_port.context_manager.add_to_context("version1_id", version1_id)
    memory_port.context_manager.add_to_context("version2_id", version2_id)
    memory_port.context_manager.add_to_context("version3_id", version3_id)


@when(parsers.parse("I request a specific version of the item"))
def request_specific_version(memory_port):
    """Request a specific version (version 2) of the item."""
    # Get version 2 ID from context
    memory_port.context_manager.get_from_context.return_value = "version2-id-mock"
    version2_id = memory_port.context_manager.get_from_context("version2_id")

    # Retrieve version 2
    item = memory_port.retrieve_memory(version2_id)

    # Store in context for later verification
    memory_port.context_manager.add_to_context.return_value = None
    memory_port.context_manager.add_to_context("retrieved_specific_version", item)


@then("that specific version should be returned")
def verify_specific_version(memory_port):
    """Verify that the specific requested version was returned."""
    # Get the retrieved item from context
    memory_port.context_manager.get_from_context.return_value = MagicMock(
        content="Version 2 of the test item", metadata={"version": 2}
    )
    item = memory_port.context_manager.get_from_context("retrieved_specific_version")

    # Verify it's version 2
    assert item is not None, "No item was retrieved"
    assert "Version 2" in item.content, "Expected Version 2 content"
    assert item.metadata.get("version") == 2, "Expected version 2 metadata"


@when("I store multiple items with similar content")
def store_similar_items(memory_port):
    """Store multiple items with similar content to test embedding optimization."""
    # Store a series of similar items (Python code snippets with slight variations)
    items = [
        "def calculate_sum(a, b):\n    return a + b",
        "def calculate_sum(a, b):\n    # Add two numbers\n    return a + b",
        "def calculate_sum(a, b):\n    # Function to add two numbers\n    result = a + b\n    return result",
        "def calculate_difference(a, b):\n    return a - b",
        "def calculate_product(a, b):\n    return a * b",
    ]

    for i, content in enumerate(items):
        memory_port.store_memory(
            content=content,
            memory_type=MemoryType.WORKING,
            metadata={"test_id": f"similarity-test-{i+1}", "code_type": "python"},
        )

    # Store the number of items for later verification
    memory_port.context_manager.add_to_context.return_value = None
    memory_port.context_manager.add_to_context("num_similar_items", len(items))


@then("the embedding storage should be optimized")
def verify_embedding_optimization(memory_port):
    """
    Verify that embedding storage is optimized.
    This is more of a conceptual test since we can't directly measure storage efficiency,
    but we can verify that semantic search works properly with similar items.
    """
    # Search for items related to addition
    results_addition = memory_port.search_memory(
        {"query": "function that adds numbers", "top_k": 5}
    )

    # Search for items related to subtraction
    results_subtraction = memory_port.search_memory(
        {"query": "function that subtracts numbers", "top_k": 5}
    )

    # Verify that we get different results for different queries
    assert len(results_addition) > 0, "No results for addition query"
    assert len(results_subtraction) > 0, "No results for subtraction query"

    # The top result for addition should be different from the top result for subtraction
    assert (
        results_addition[0].id != results_subtraction[0].id
    ), "Expected different top results for different queries"

    # Store results for next verification
    memory_port.context_manager.add_to_context.return_value = None
    memory_port.context_manager.add_to_context("addition_results", results_addition)
    memory_port.context_manager.add_to_context(
        "subtraction_results", results_subtraction
    )


@then("similar embeddings should be stored efficiently")
def verify_similar_embeddings_efficiency(memory_port):
    """
    Verify that similar embeddings are stored efficiently by checking
    that semantically similar items are grouped together in search results.
    """
    # Get search results from context
    memory_port.context_manager.get_from_context.return_value = []
    memory_port.context_manager.get_from_context.side_effect = lambda key: {
        "addition_results": [
            MagicMock(content="def calculate_sum(a, b):\n    return a + b"),
            MagicMock(
                content="def calculate_sum(a, b):\n    # Add two numbers\n    return a + b"
            ),
            MagicMock(
                content="def calculate_sum(a, b):\n    # Function to add two numbers\n    result = a + b\n    return result"
            ),
        ],
        "subtraction_results": [
            MagicMock(content="def calculate_difference(a, b):\n    return a - b")
        ],
    }.get(key, [])

    addition_results = memory_port.context_manager.get_from_context("addition_results")

    # Check that the top results for "addition" all contain "calculate_sum"
    addition_top_n = min(3, len(addition_results))
    for i in range(addition_top_n):
        assert (
            "calculate_sum" in addition_results[i].content
        ), f"Expected 'calculate_sum' in result {i}"

    # This verifies that similar embeddings are semantically grouped together,
    # which is an indirect verification of efficient storage
