Enhancing the DevSynth Platform: A Holistic Design Review and Future Directions
Overview of DevSynth’s Current Design and Features
DevSynth is an agentic software engineering platform that uses Large Language Models (LLMs), advanced memory/knowledge systems, and dialectical reasoning to automate and assist the software development lifecycle[1]. Architecturally, it follows a modular, hexagonal design separating core logic from adapters, which enhances testability and extensibility[2]. Key components include:
	•	Agent System (WSDE Model): A multi-agent framework where “Worker Self-Directed Enterprise” agents collaborate as peers (rotating a Primus leader role) to tackle tasks with dialectical (thesis/antithesis) reasoning[3][4]. Agents are orchestrated via LangGraph workflows, enabling complex planning and decision graphs beyond simple prompt-response[5][6].
	•	Memory and Knowledge Stores: A unified memory interface (MemoryManager/MemoryPort) gives DevSynth flexible backends for both vector search and graph knowledge. It supports multiple databases – e.g. ChromaDB (vector embeddings), TinyDB/JSON (structured artifact storage), and RDFLib or Kùzu (RDF triple stores for a knowledge graph with SPARQL querying)[7]. A SyncManager ensures consistency across these stores[8][9]. This design enables retrieval-augmented generation (RAG) and persistent semantic knowledge of the project.
	•	Code Analysis and Transformation: DevSynth performs static code analysis using NetworkX graph algorithms to map dependencies and complexity[10]. A RepoAnalyzer extracts the repository structure and top-level imports to build a dependency graph, while an AstTransformer system can apply AST-based refactorings (e.g. removing unused imports or variables) in a controlled, fine-grained “Atomic-Rewrite” manner[11][12]. This allows automated code cleanup and modifications with traceability (each transformation is logged[13]).
	•	Project Knowledge Graph: DevSynth represents the software project’s structure and knowledge as a graph. The ProjectModel organizes files, directories, and other artifacts as nodes in a directed graph (using NetworkX) with semantic relationships (currently primarily "contains" for directory/file hierarchy)[14][15]. Documentation is ingested and stored as knowledge graph entries as well[16][17]. This unified graph of code, documentation, and metadata is intended to support global reasoning about the project.
	•	Unified Interfaces and Tools: A CLI (and planned Web UI) interacts with a central UX Bridge so that agents and workflows remain UI-agnostic[18][19]. DevSynth provides commands for tasks like devsynth refactor, inspect, or an interactive init wizard to onboard projects[20]. A doctor diagnostics command checks the environment[21]. There is also a comprehensive set of SDLC policies and traceability mechanisms – e.g. a Requirements Traceability Matrix linking requirements ↔ code ↔ tests[2] and an “SDLC policy corpus” of best practices and checklists that both humans and agents are expected to follow[22].
Strengths: DevSynth’s design emphasizes extensibility (via hexagonal architecture and plugin-like adapters) and traceability (rich metadata linking and logging of decisions)[2]. Its multi-backend memory system provides resilience with fallbacks (e.g. multiple LLM providers, multiple storage types)[23][24]. The WSDE agent model, combined with dialectical reasoning hooks, means the system can critique and refine its own solutions, emulating a pair-programming or code-review dynamic for higher-quality outputs[25]. Automated testing, documentation generation, and CI/CD integration are built-in priorities, as evidenced by the included test suites and policy enforcement tools.
Challenges: Because DevSynth is still pre-release (version 0.1.0a1)[26], some advanced features are in progress. For example, the WSDE multi-agent collaboration and consensus features are not fully realized yet[27]. The knowledge graph usage is basic so far – storing documentation and file structure – while more semantic code relationships (like function call graphs or data flows) are not yet richly modeled. The complexity of maintaining multiple synchronized stores (vector DB, graph DB, etc.) can introduce overhead. Ensuring performance and scalability on very large codebases (with millions of code elements) will be an ongoing concern. Nonetheless, the current design establishes a strong foundation to build upon.
Critical Analysis of Key Components and Patterns
Memory System and Knowledge Integration
DevSynth’s memory system exemplifies a hybrid knowledge approach – combining unstructured vector embeddings with structured graph knowledge. This is a forward-thinking design, as research increasingly suggests that neuro-symbolic methods (LLMs + knowledge graphs) can outperform LLMs alone for complex reasoning[28][29]. The ability to query code and docs via semantic search and via formal graph queries gives DevSynth flexibility. For example, the RDFLib-backed store allows SPARQL queries over the knowledge graph, which could let an agent ask “find functions related to X” or retrieve an architecture diagram by semantic tag[30][31]. This is aligned with the notion of a “software project as a knowledge graph,” where every entity (file, function, requirement, test) and their relationships are explicitly linked.
Improvement Opportunities: Currently, the knowledge graph integration is underutilized – the system mostly captures containment hierarchy and documentation links[14][15]. To enhance this:
	•	Enrich the Graph Schema: Represent more relationship types in the project knowledge graph. For instance, add edges for “calls”, “imports”, “defines”, and “tests” relationships. If function A calls function B, or module X imports module Y, these should be nodes and edges in the graph. DevSynth already parses import dependencies via RepoAnalyzer[11]; integrating those into the RDF knowledge graph or the NetworkX model would allow graph queries like “find unused modules” or “which components are most central in call graph”. Research on code knowledge graphs supports this idea – a simple graph model with file and AST nodes and edges like HAS_AST (file contains AST node) and PARENT_OF (AST parent-child) already enables repository-wide queries that LLMs can answer via graph traversal[32][33]. For example, an agent could count functions in a file or find all references to a variable by generating a Cypher/SPARQL query instead of searching plain text[33][34].
	•	Adopt Standard Ontologies: To improve the representation of code in the knowledge graph, DevSynth might draw on existing ontologies like CodeOntology. Atzeni & Atzori (2017) created CodeOntology as a formal OWL/RDF ontology for object-oriented code (classes, methods, etc.) and a parser that converted the entire Java OpenJDK8 codebase into millions of RDF triples[35]. The ontology encodes class hierarchies, method definitions, and even statements, enabling expressive SPARQL queries over code (e.g. “find all subclasses of X that call method Y”)[35][36]. DevSynth could implement or adapt a similar ontology for Python and other languages. This would clarify the schema of the knowledge graph and unlock more powerful queries. With a richer schema, the agents’ reasoning could be more “knowledge-aware” – for instance, a Critic agent could query the graph for known anti-patterns (certain code structures or a lack of tests for a requirement) and automatically suggest improvements, grounded in the formal graph data.
	•	Graph-Based Reasoning Algorithms: Beyond just storing and querying knowledge, DevSynth can leverage graph algorithms for insights. It already uses NetworkX for basic analysis; additional algorithms could find, say, the most interconnected modules (high centrality), potential architecture violations (cycles in a supposed layered architecture), or clusters of files that change together (community detection). These analyses could feed into the agent’s decision-making. For example, a refactoring agent might decide to split a highly connected “God class” into smaller components if the graph metrics indicate a complexity hotspot. The knowledge graph utilities in DevSynth (e.g. query_related_concepts, query_concept_relationships in WSDEMemoryIntegration) could be extended to incorporate such analyses[37][38].
Additionally, ensuring that the memory system scales gracefully is important. The SyncManager currently keeps multiple stores in sync with an atomic commit approach[9]. As the project grows, a possible improvement is to allow configuration to disable certain stores when not needed (for example, turn off the graph store for small projects to save overhead, or vice versa). Also, integrating a specialized graph database like Neo4j (which the Medium case study uses for code graphs[33]) or optimizing Kùzu usage for large-scale queries would help. The memory interface could support more intelligent caching, e.g. caching expensive graph query results or vector searches, to avoid repeated computation during an agent’s iterative reasoning.
Agent Collaboration and Dialectical Reasoning
DevSynth’s agent system (following the WSDE model) is a unique strength, aiming to mimic a team of developers with different roles (e.g. a “Coder” and a “Reviewer” agent) working together. This approach echoes a growing trend in AI: using multiple LLM agents in a cooperative or adversarial setup to improve outcomes. In DevSynth, when a solution is proposed, a dialectical process can generate an antithesis (critique) and then a synthesis (improved solution)[39]. This resembles a built-in code review or pair programming partner and can catch mistakes or suboptimal designs that a single-pass generation might miss.
Evaluation: The concept is well-grounded – for instance, research on “self-reflection” and critique in LLMs has shown that letting a model analyze and correct its own output can significantly improve quality. DevSynth’s logs note that “dialectical reasoning hooks automatically analyze new solutions added to a WSDE team”[25], indicating that whenever an agent proposes a code change (thesis), another agent (or the system itself) will attempt to analyze and challenge it. This is analogous to techniques like Reflexion or chain-of-thought debate, where one agent may act as a critic to the other’s proposal.
Improvement Opportunities: There are several ways to strengthen this multi-agent, dialectical design:
	•	Dedicated Role Agents: Currently the WSDE framework is conceptually defined, but DevSynth could implement specialized agent roles (e.g. Requirements Analyst, Code Generator, Test Writer, QA Analyst). Each agent could have access to different tools or knowledge. For example, a “Test Writer” agent could automatically create or update unit tests for new code (perhaps using the knowledge graph to ensure every requirement has at least one test[2]). A “QA” or “Critic” agent might run static analysis (linting, type checking) or even attempt to compile/run the project in a sandbox to catch runtime errors. By diversifying agent expertise, the dialectical process becomes more robust – akin to a cross-functional team.
	•	Enhanced Dialectical Protocols: The current dialectical loop (thesis→antithesis→synthesis) could be extended to multiple iterations or even multi-party debates. Academic ideas like AlphaPenthe (n agents debate and vote) or the Socratic method (asking leading questions) could inspire how agents challenge each other. Ensuring that the Primus (leader) role rotates based on context (e.g. the agent most competent in a given task becomes leader) is another good practice noted in the design[3]. This could be more explicitly encoded: e.g. for a documentation task, the agent well-versed in language/writing takes lead, whereas for a bug-fix task the agent with code analysis skills leads.
	•	Integration of External Validation: A key way to strengthen multi-agent outcomes is to incorporate automated validation checks after each step or at decision points. DevSynth already has comprehensive test suites and a run-tests command for its own development[40][41] – this concept can be applied to the generated code as well. For instance, after the “Coder” agent writes new code, the system can automatically run the project’s test suite (or at least lint/type-check) in the background. The results (e.g. failing tests or lint errors) can be fed as feedback into the dialectical loop. This closes the loop between planning and verification. In essence, one can introduce a “CI Agent” that always checks the work and provides an error report memory item (of type ERROR_LOG or TEST_RESULTS)[42][43] for the Critic agent to consider. This approach aligns with continuous integration philosophy and is backed by research like CodePlan, which demonstrated that an iterative plan with intermediate verifications yields far better correctness in repository-wide changes[44].
	•	Learning from Human Interactions: Since DevSynth is HITL (Human-in-the-loop) by design (the project itself was dialectically built by LLMs with human oversight[45]), it could also capture human feedback during use. For example, if a human user rejects an agent’s proposed change or provides a correction, that feedback can be logged in the knowledge graph (as a special memory item or policy update). Over time, the agents could learn from those patterns – effectively an on-line learning or fine-tuning on the project’s evolving coding style and standards. While this is an ambitious goal, it aligns with the idea of continuously improving the AI’s alignment with the team’s expectations.
Notably, external research strongly supports the need for planning and multi-step reasoning in repository-level coding. Bairi et al. (2023) frame non-local code edits as a planning problem precisely because single-shot LLM solutions often fail to maintain consistency across a large repo[46]. Their CodePlan system breaks tasks into a sequence of LLM-powered edits guided by dependency analysis and may-impact analysis[47][48]. This approach achieved significantly higher success (e.g. passing all tests in 5/6 multi-file tasks, whereas naive LLM editing passed 0/6)[44]. DevSynth’s agentic, iterative design is very much in line with these findings – and further integrating such planning algorithms or dependency-driven task decomposition will likely improve its performance on large-scale refactoring or addition tasks. In other words, DevSynth should continue to invest in the planner/orchestrator aspect of the agent system, possibly drawing from CodePlan’s techniques (like incremental dependency graphs or heuristics to pick the next file to modify). This could be implemented as an enhancement to the EDRR (Expand, Differentiate, Refine, Retrospect) coordinator[49], turning high-level goals into ordered sub-tasks for agents in a principled way.
Code Representation and Analysis Improvements
DevSynth already treats the codebase as more than just text – using ASTs and graphs – which is a best practice given that source code has rich structure[50]. The built-in AST transformations and the repository graph are excellent for automating code maintenance. There are further improvements to consider in this area:
	•	Deeper Static Analysis Integration: Beyond imports and AST structure, DevSynth could integrate data flow analysis and control flow graphs for each function. The Medium case study on codebase graphs suggests extending the knowledge graph with these artifacts (DFG, CFG) to answer even more complex questions and enable deeper reasoning[51]. For example, a data flow graph could help an agent determine where a particular variable’s value comes from, or whether a function has side effects – informing safer refactoring. Tools exist in the static analysis domain (like astroid or bandit for Python, or LLVM for C/C++) that can extract such information. Incorporating their output into DevSynth’s knowledge graph (perhaps behind a feature flag, since it can be language-specific and heavy) would give the LLM agents a “x-ray” into the code’s behavior, not just its syntax.
	•	Dynamic Analysis and Runtime Data: Similarly, adding runtime insights can greatly enhance understanding. The Medium article notes that one can attach test coverage data to the knowledge graph[52]. DevSynth could run the project’s test suite in an instrumented mode to gather which lines/functions are executed, then store that as knowledge (e.g., an edge or property like coverage_percentage on each function node). This would let an agent prioritize areas with low coverage for adding tests, or avoid modifying highly critical code without extra caution. Other runtime data might include profiling information (to find performance hotspots) or logs of errors. By closing the loop between runtime behavior and static code representation, DevSynth’s suggestions could move beyond generic best practices to project-specific, evidence-based recommendations (e.g. “This function is often failing according to logs, let’s improve it” or “This API is never called anywhere, it might be dead code”).
	•	Language and Framework Awareness: Currently, DevSynth is Python-focused (given it’s written in Python and uses Python AST). To truly adapt to diverse projects (monorepos, multi-language systems) as intended[49], it could incorporate language-specific plugins. For instance, parsing Java or JavaScript projects to build their AST graphs would require different tools. An improvement would be a pluggable parser interface: detect languages present (maybe via the .devsynth/project.yaml) and use appropriate parsers/ontologies for each. This ensures the “adaptive project ingestion” can handle not just different structures but different syntax and semantics. Academic efforts like PLUR (2021) are attempting unified graph-based representations across languages[53] – DevSynth could draw on such research to design a language-agnostic intermediate representation, so that core reasoning (like identifying unused functions or suggesting documentation) works across languages.
DevSynth as a Software Knowledge Graph – Enhancements
Treating a software project as a knowledge graph is one of DevSynth’s core concepts. In practice, this means all relevant project information (requirements, design docs, code, tests, issues) are interconnected as nodes and relationships, enabling semantic queries and holistic reasoning. We’ve discussed improving code representation; here we consider the broader project knowledge graph:
	•	Linking Requirements and Code: DevSynth’s documentation mentions a Requirements Traceability Matrix[2]. This could be implemented as part of the knowledge graph: e.g., each requirement (or user story, or issue) is a node, which links to the code nodes that implement it and the test nodes that verify it. Going forward, automating this linkage is key. For example, if there are structured requirements (perhaps in a .devsynth/project.yaml or imported from a tool like Jira), the system could use NLP to match requirement descriptions to code (similar to how RepoDoc might work) or require agents to tag their code contributions with requirement IDs. A knowledge graph-enhanced agent could then reason about coverage: “Requirement X has no test node linked – I should generate a test” or “Requirement Y was changed, so find all code nodes linked to Y and mark them for review.” This kind of end-to-end traceability is a long-standing goal in SE, and LLMs combined with a knowledge graph might finally make it viable at scale.
	•	Connecting Issues and Discussion: If DevSynth integrates with issue trackers or version control (e.g., pulling commit messages, PR discussions), those can be nodes too (“Issue #42” node connected to “Function foo()” node that was changed for it). Academic work like Prometheus (2023) has explored unified knowledge graphs that combine code, issues, and Q&A knowledge for debugging assistance[54]. DevSynth could similarly ingest commit history or use its own Git commit messages to enrich the graph. This provides context to agents – for instance, if an agent is about to modify code, it could query “what was the last issue related to this code?” and find that a certain approach was tried before. This guards against regressions and spreads knowledge of past decisions.
	•	Human Readability and Auditing: One advantage of a knowledge graph is that it’s explorable by humans too. DevSynth could include commands to export or query the project knowledge graph for developers’ benefit. Improvements might include a small web dashboard (since a NiceGUI-based WebUI is planned[19]) to visualize the graph of the project: modules, their links, which agent produced which code, etc. This would not only help developers understand the AI’s model of the project, but also build trust – they can see, for example, that a new piece of code is linked to a rationale or requirement node, meaning the AI had a reason to create it. This transparency will be increasingly important as the system takes more autonomous actions.
Other Areas for Enhancement
Beyond the core technical design, a few additional areas merit attention:
	•	LLM Capabilities and Tuning: DevSynth’s provider abstraction allows swapping LLMs (OpenAI, Anthropic, local models)[55]. As newer, more capable models (especially open-source code-specialized models) become available, integrating them could boost performance. For example, a future Code-Llama 2 or GPT-4 successor fine-tuned on code could significantly improve code generation quality. DevSynth’s prompt auto-tuning feature is forward-looking[56]; continuing to refine prompt engineering (possibly using RLHF or few-shot exemplars drawn from its own repository of solved tasks) will strengthen results. There’s also emerging research on using retrieval-augmented generation for code – e.g. retrieving relevant code snippets from a knowledge base for the LLM to use as context (the RepoHyper approach) – this showed large improvements in code completion at repository scale[57][58]. DevSynth can leverage its memory stores to provide such relevant context to the LLM during agent tasks. Essentially, before an agent calls the LLM to implement a feature, it could gather related pieces (similar code, style guides from the docs, etc.) from memory to include in the prompt.
	•	Performance and Scalability: With so many moving parts (multiple agents, multiple data stores, possibly multiple model calls), performance optimizations will be important. Caching embeddings for files, incremental graph updates (rather than full rebuilds), and parallelizing independent agent tasks could all help. For instance, if analyzing a monorepo, agents could work on separate subprojects concurrently. Monitoring and profiling the system (perhaps via the observability hooks mentioned[59]) will guide where to streamline. Scalability also involves how DevSynth could handle very large codebases – integrating it with efficient indexing (e.g. using an external search service for code, or graph databases optimized for tens of millions of nodes) might become necessary for enterprise-scale projects.
	•	User Experience and Adoption: On the human side, to maximize DevSynth’s impact, improving the developer UX is key. The planned web UI should make it easier to review agent proposals and approve or refine them. Think of it like a sophisticated pull request interface, where the AI’s changes and reasoning are displayed for review. By presenting diffs, rationales, and confidence levels, DevSynth can keep the human in the loop without burden. Additionally, providing a VS Code plugin or editor integration would allow developers to invoke DevSynth agents on-demand on specific files or tasks (“DevSynth, suggest a refactoring for this function”), making it a true pair-programmer. All these improvements will encourage trust and frequent usage, which in turn provides more feedback data to improve the system.
	•	Security and Policy Compliance: As DevSynth starts writing significant portions of code, ensuring it doesn’t introduce security vulnerabilities or policy violations is crucial. The SDLC policy corpus in DevSynth could be utilized by adding an agent or check that scans outputs against known secure coding guidelines or project-specific rules. For example, if the organization disallows a certain deprecated API, the knowledge graph could mark that API as “banned” and any attempt by the code generator agent to use it would be flagged by the critic agent (who could say: this violates policy X[2]). This kind of policy-aware generation would be a standout feature for enterprise use, aligning AI contributions with compliance requirements.
Conclusion
In summary, DevSynth is an ambitious platform weaving together LLM-driven generation, knowledge graphs, and multi-agent orchestration to automate software engineering. Our analysis finds that its core architecture is robust and forward-looking, but there are rich opportunities to enhance it further. Strengthening the software project as a knowledge graph involves enriching that graph with deeper code semantics, possibly leveraging established ontologies and static analysis artifacts, so that both DevSynth and its human users can query and reason about the codebase on a semantic level (e.g. via SPARQL or graph queries)[35][32]. Improving the representation of code in the knowledge graph goes hand-in-hand with this – by including AST nodes, dependencies, and even runtime data, DevSynth’s internal model of the project will be far more comprehensive and useful[32][28].
Moreover, the WSDE multi-agent paradigm should be further evolved, drawing on ideas of role specialization and proven planning strategies from recent research (like CodePlan) to tackle repository-wide tasks systematically[47][44]. With more sophisticated critique and validation loops – including automated testing and policy checks – the quality of AI-generated code can approach production-level reliability.
DevSynth’s vision essentially transforms a software project into a living knowledge artifact that an AI can understand and contribute to. By integrating the enhancements discussed – from knowledge graph upgrades and code semantics to agent collaboration tactics and user-facing improvements – DevSynth can become a truly holistic development assistant. It would not just write code or docs on demand, but maintain a global understanding of the project’s state, history, and goals, using that to proactively support developers and even autonomously improve the codebase. This aligns with emerging trends in AI-assisted software engineering, where repository-level reasoning and multi-step planning are key to scaling LLMs to real-world codebases[57][60].
In conclusion, DevSynth’s current design provides a strong foundation, and with the recommended enhancements – informed by both best practices and cutting-edge research – it can be strengthened and expanded into a next-generation development platform. By improving knowledge graph representations, deepening code understanding, and refining its multi-agent workflows, DevSynth will be better equipped to handle complex, large-scale software projects in a reliable, intelligent, and explainable way. Each improvement brings it closer to the ultimate goal: an AI-powered system that comprehensively comprehends, builds, and evolves software alongside human developers, turning the vision of a “self-synthesizing” codebase into reality.
Sources:
	•	DevSynth Documentation and Code Base: Architecture Overview[61][2], Memory System[7], Agent System[3], Knowledge Graph Utilities[30][39], Code Analysis Guide[11][12], DevSynth README[20][25].
	•	Z. Chen, “Building Knowledge Graph over a Codebase for LLM,” Medium, 2024 – discussing codebase knowledge graphs and their use for LLM reasoning[32][52].
	•	M. Atzeni and M. Atzori, “CodeOntology: RDF-ization of Source Code,” ISWC 2017 – ontology and RDF-based querying for source code[35].
	•	R. Bairi et al., “CodePlan: Repository-level Coding using LLMs and Planning,” arXiv 2023 – on multi-step planning for repository-wide code edits[47][44].
	•	Q. Luo et al., “RepoAgent: LLM Framework for Repository-level Code Documentation Generation,” arXiv 2024 – illustrating LLM capabilities on whole-repo documentation tasks[60].
	•	Additional references on graphs in code analysis and program understanding[28][57].

[1] [4] [20] [21] [22] [25] [26] [40] [41] [45] [49] [55] [56] README.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/README.md
[2] [10] [19] [59] [61] overview.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/architecture/overview.md
[3] [5] [6] [18] [27] agent_system.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/architecture/agent_system.md
[7] [8] [9] [23] [24] [42] [43] memory_system.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/architecture/memory_system.md
[11] [12] [13] code_analysis.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/developer_guides/code_analysis.md
[14] [15] project.py
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/src/devsynth/domain/models/project.py
[16] [17] documentation_ingestion.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/architecture/documentation_ingestion.md
[28] [29] [32] [33] [34] [50] [51] [52] [53] [57] [58] Building Knowledge Graph over a Codebase for LLM | by Zimin Chen | Medium
https://medium.com/@ziche94/building-knowledge-graph-over-a-codebase-for-llm-245686917f96
[30] [31] [37] [38] [39] knowledge_graph_utilities.md
https://github.com/ravenoak/devsynth/blob/cd0b5e8b5d0fb095ee60f2a78330490e460b8cb0/docs/technical_reference/knowledge_graph_utilities.md
[35] [36] CodeOntology: RDF-ization of Source Code | SpringerLink
https://link.springer.com/chapter/10.1007/978-3-319-68204-4_2?error=cookies_not_supported&code=bcb8454c-39b6-4725-8774-dd3ff515e9e9
[44] [46] [47] [48] [2309.12499] CodePlan: Repository-level Coding using LLMs and Planning
https://arxiv.org/abs/2309.12499
[54] [PDF] GRAPH4CODE: A Machine Interpretable Knowledge Graph for Code
https://www.semantic-web-journal.net/system/files/swj2575.pdf
[60] [2402.16667] RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation
https://arxiv.org/abs/2402.16667
