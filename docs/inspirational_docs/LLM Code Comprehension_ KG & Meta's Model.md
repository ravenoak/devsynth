

# **From Static Knowledge to Dynamic Worlds: A Critical Evaluation of Modern Paradigms for LLM Code Comprehension**

## **Part I: The Thesis \- Code as a Structured Knowledge Artifact**

The pursuit of artificial intelligence capable of genuine code comprehension necessitates moving beyond the superficial pattern-matching of raw text. The first major paradigm in this endeavor posits that deep understanding can be achieved by treating a codebase not as a sequence of characters, but as a static, interconnected, and machine-queryable knowledge artifact. This approach, rooted in classical program analysis, prioritizes the explicit representation of structure, relationships, and verifiable facts. It seeks to build a comprehensive "map" of the software, which can then be used to guide a Large Language Model's (LLM) reasoning processes. This section establishes this thesis by deconstructing code into its fundamental machine-interpretable components, detailing the construction of comprehensive Knowledge Graphs (KGs) from these components, and evaluating how these KGs can ground LLMs to produce more accurate and context-aware outputs.

### **Section 1: Foundations of Machine-Interpretable Code Representation**

Source code, in its raw textual form, is ambiguous and lacks the explicit structure required for rigorous computational analysis. To enable machines to "understand" code, it must first be transformed into a more structured intermediate representation. This process of abstraction is foundational to all modern code comprehension techniques. The evolution of these representations reveals a clear trajectory from capturing pure syntax to modeling complex semantic and behavioral properties, culminating in rich, multi-layered graphs that serve as the building blocks for comprehensive knowledge systems.

#### **Abstract Syntax Trees (ASTs)**

The first and most fundamental step in moving beyond raw text is parsing the code into an Abstract Syntax Tree (AST). An AST is a hierarchical, tree-based representation that captures the abstract syntactic structure of the source code.1 It abstracts away syntactically irrelevant details such as comments, whitespace, and punctuation, focusing instead on the code's logical organization. Each node in the tree corresponds to a construct in the code, such as a function definition, a loop, or a variable declaration.3

LLMs often struggle with raw code because they process it as a linear sequence of tokens, failing to naturally recognize the nested, hierarchical relationships inherent in programming languages.3 By providing the code in an AST format, the model is given a structured "roadmap" that makes explicit the relationships between different code components. This structured input has been shown to be more intelligible to models, leading to significant improvements in a variety of software engineering tasks. For instance, studies have demonstrated that using ASTs as an intermediate representation can enhance the accuracy of LLM-based code translation 5 and enable more robust, "surgical" merging of AI-generated code snippets into existing files without corrupting the original structure.6 Tools like the tree-sitter library are commonly used to perform this initial parsing across multiple programming languages, forming the first layer of nearly all advanced code analysis pipelines.4

#### **Control Flow Graphs (CFGs)**

While an AST perfectly captures the static, syntactic structure of code, it does not explicitly represent the order in which statements will be executed. To capture this dynamic aspect, a Control Flow Graph (CFG) is used. A CFG is a directed graph that models all possible paths of execution through a program.8 The nodes in a CFG are "basic blocks"—sequences of straight-line code with no jumps in or out—and the directed edges represent the transfers of control between these blocks, such as those caused by conditional statements (if/else), loops (while, for), or function calls.8 By modeling the program's logical flow, the CFG provides a representation that moves beyond pure syntax to capture an essential element of the code's behavior.

#### **Data Flow Graphs (DFGs)**

Complementing the CFG, a Data Flow Graph (DFG) adds another layer of semantic information by tracking how data is propagated and transformed throughout the program.1 A DFG connects variable definitions to all their subsequent uses, creating what are known as "definition-use chains".2 This representation is crucial for understanding the semantic impact of code, as it makes explicit how the value of a variable at one point in the program affects computations at another. It provides a variable-centric view of the code's semantics that is essential for tasks like optimization, bug detection, and understanding functional dependencies.

#### **Synthesizing Representations: CPGs and SCGs**

The true power of these foundational representations is realized when they are combined into a single, unified structure. Advanced models like the Code Property Graph (CPG) and the Semantic Code Graph (SCG) integrate ASTs, CFGs, and DFGs to provide a holistic view of the code.2 A CPG, for example, overlays control flow and data flow edges directly onto the underlying AST, allowing an analysis engine to collectively reason about syntax, control flow, and data dependencies within a single graph structure.2

Similarly, the Semantic Code Graph (SCG) is an information model specifically designed to facilitate software comprehension by capturing a detailed, abstract representation of code dependencies that maintains a close relationship to the source code itself.10 Empirical studies have shown the SCG to be a more comprehensive model than traditional representations like Call Graphs or Class Collaboration Networks. Its ability to capture dependencies at multiple levels of granularity—from classes down to local variables—enables deeper analytical insights, such as identifying excessive variable usage or discovering functionally similar methods for refactoring.10

This progression from simple ASTs to complex, multi-layered graphs like CPGs and SCGs represents a deliberate trade-off. Each layer of abstraction adds significant semantic richness, moving the representation closer to the code's true meaning. However, this process is not without its complexities. The act of abstraction is inherently "lossy"; in creating a clean, structured representation for an idealized reasoning engine, certain information from the raw text is intentionally discarded. For example, an AST discards comments and formatting. Yet, recent research has revealed that current transformer-based LLMs are surprisingly sensitive to this supposedly "irrelevant" information.12 A misleading comment or a change in variable naming can significantly degrade an LLM's performance on a comprehension task, even though these elements are non-functional. This creates a fundamental tension: the very abstractions that are necessary for structured, logical analysis may create a mismatch with how today's LLMs actually process information, suggesting that a truly holistic system may need to operate on multiple levels of representation simultaneously.

| Representation | Primary Focus | Granularity | Key Use Cases | Complexity to Generate |
| :---- | :---- | :---- | :---- | :---- |
| **Abstract Syntax Tree (AST)** | Syntactic Structure | Statement, Expression | Code Linting, Refactoring, Transpilation | Low |
| **Control Flow Graph (CFG)** | Execution Paths | Basic Block | Optimization, Dead Code Elimination, Complexity Analysis | Medium |
| **Data Flow Graph (DFG)** | Data Propagation | Variable Definition/Use | Taint Analysis, Bug Detection, Slicing | Medium |
| **Code Property Graph (CPG)** | Unified Syntax & Semantics | Statement, Variable | Vulnerability Detection, Deep Code Analysis | High |
| **Semantic Code Graph (SCG)** | Code Dependencies | Class, Method, Variable | Software Comprehension, Architectural Mining | High |

---

*Table 1: A comparative analysis of foundational and synthesized code graph representations, detailing their primary focus, level of granularity, common applications, and relative complexity of generation. The table illustrates the progression towards more semantically rich and comprehensive models like CPGs and SCGs, which are necessary for deep code comprehension.*

### **Section 2: The Codebase as a Knowledge Graph**

While the graph representations discussed in the previous section provide a deep analysis of individual programs or files, modern software systems are vast ecosystems of interconnected modules, libraries, and services. To achieve true system-level comprehension, it is necessary to scale this graph-based approach to model an entire codebase. This is accomplished by constructing a formal Knowledge Graph (KG), a comprehensive, queryable map that captures not only the code's internal structure but also its metadata, documentation, and external dependencies.14

#### **Defining the Code Knowledge Graph**

A code KG is a living, graph-structured representation of a software repository that models code entities (like functions, classes, and variables) as nodes and the relationships between them (like function calls, inheritance, and data flow) as edges.14 Unlike single-program graphs, a code KG is designed to be holistic, capturing the hierarchical organization, dependencies, and usage patterns across an entire project or even multiple repositories.17 This graph can be enriched with additional layers of information, including metadata from version control systems (e.g., commit history), links to documentation, and even connections to external knowledge sources like API specifications or forum discussions on Stack Overflow.1

#### **Schema and Ontology: The Foundation of Reasoning**

The foundation of any robust KG is a well-defined schema or ontology. This formal structure dictates the types of nodes and edges that can exist in the graph and the rules that govern their interactions.16 A typical code KG schema defines node types such as File, Module, Class, Function, and Variable. Each node type has a set of defined properties, for example, a Function node might have properties for its name, return\_type, access\_modifier, and associated documentation.15

The schema also defines the types of relationships (edges) that can connect these nodes, such as CALLS, INHERITS\_FROM, IMPLEMENTS, DEPENDS\_ON, and DEFINED\_IN.15 This formal ontology is critical because it provides a shared vocabulary and structure that allows both humans and machines to understand and reason about the graph's contents in a consistent and logical manner.16

#### **The KG Construction Pipeline**

Building a comprehensive code KG is a multi-stage process that transforms raw source code into a structured, queryable database.14 The typical pipeline includes:

1. **Static Analysis:** The process begins by parsing the entire codebase, often using the techniques described in the previous section to generate ASTs and other intermediate representations for each file.14  
2. **Graph Construction:** From these representations, nodes are created for each identified code entity (classes, functions, etc.), and edges are created to represent their relationships. This information is then ingested into a specialized graph database, such as Neo4j.15  
3. **Metadata and NLP Integration:** The graph is then enriched with metadata. This can include version history extracted from Git, which links code entities to the developers who created or modified them. Natural Language Processing (NLP) techniques are used to analyze unstructured text artifacts like code comments, docstrings, and README files, linking this natural language documentation directly to the code entities it describes.14 Some advanced pipelines even use LLMs to generate concise descriptions for code snippets, capturing their functional meaning and storing it as a property on the corresponding node.17

The result of this pipeline is a powerful, unified data model that centralizes disparate forms of knowledge about the software project. Information that was previously siloed across different tools and mental models—the code's structure, its documentation, its version history, its dependencies—is now integrated into a single, queryable "source of truth." This has a profound effect on software intelligence. Tasks that were once separate activities, such as a developer reading a function's documentation, an architect analyzing dependencies, or a new hire reviewing commit history, are transformed into different types of queries over the same underlying graph. A single, multi-faceted query can now ask, "Show me all functions that depend on this deprecated API, who last modified them, and what the associated documentation says." This type of cross-functional analysis, which is nearly impossible with traditional tools, becomes straightforward, enabling a new generation of integrated and intelligent development environments.

### **Section 3: Grounding LLMs with Graph-Augmented Generation (GraphRAG)**

While a Knowledge Graph provides a powerful, static representation of a codebase, its true potential for enhancing AI is unlocked when it is paired with a Large Language Model. The KG serves as an external, structured "brain" that can ground the LLM's reasoning, mitigating its inherent weaknesses and enabling a more sophisticated level of code comprehension. This synergy is most effectively realized through a technique known as Graph-based Retrieval-Augmented Generation (GraphRAG).

#### **The Problem: Ungrounded LLMs and Code**

When operating solely on the knowledge encoded in their parameters, LLMs face several critical limitations, especially in the context of specific, evolving codebases. They are prone to "hallucination," where they confidently generate inaccurate or fabricated information, such as inventing API functions that do not exist.19 They lack domain-specific knowledge of a particular private repository and are unable to incorporate new information or code changes without expensive retraining or fine-tuning.19 For code-related tasks, this means an LLM's output may be inconsistent with the project's architecture, rely on outdated dependencies, or fail to adhere to established coding patterns.17

#### **GraphRAG as the Grounding Mechanism**

GraphRAG directly addresses these limitations by connecting the LLM to the code KG as a dynamic, external knowledge base.19 The core principle of RAG is to augment the prompt given to the LLM with relevant, factual information retrieved from an external source. In GraphRAG, this source is the highly structured and interconnected code KG.19

The process typically unfolds as follows 20:

1. **Query Analysis:** A user's natural language query (e.g., "How does our application handle payment processing?") is first parsed to identify key entities and intent.  
2. **Graph Retrieval:** The system then executes a formal query against the KG to retrieve a relevant subgraph. This is not a fuzzy similarity search but a deterministic traversal of the graph. For the example query, it might retrieve the PaymentProcessor class, the functions it calls, the classes it inherits from, and their associated documentation. This step allows for complex, "multi-hop" reasoning, such as finding functions that call function X, which in turn depends on library Y.21  
3. **Contextual Augmentation:** The retrieved subgraph—a collection of structured facts—is then linearized into a format the LLM can process, such as a textual description, JSON, or another structured format.  
4. **Grounded Generation:** This linearized, factual context is prepended to the original user query and sent to the LLM. The model is then instructed to generate its response based *only* on the provided context.

This mechanism fundamentally transforms the LLM's role from that of a "knower" to that of a "reasoner." Without RAG, a developer must rely on the knowledge implicitly and often unreliably stored in the LLM's weights. A standard vector-based RAG system might retrieve irrelevant text chunks from comments or outdated documents that happen to contain similar keywords.24 In contrast, a GraphRAG system executes a precise, verifiable query against the KG, such as MATCH (c:Class {name: 'PaymentProcessor'})--\>(f:Function) RETURN f.name, f.documentation. The result is a set of trustworthy facts. The LLM's task is no longer to *recall* the answer from memory, but to *synthesize* a coherent, human-readable explanation based on the provided, ground-truth data. This separation of concerns—with knowledge reliably stored in the KG and reasoning performed by the LLM—creates a system that is more accurate, auditable, and easily kept up-to-date, as the KG can be continuously updated to reflect code changes without any need to retrain the LLM.14

## **Part II: The Antithesis \- Code as a Dynamic, Executable Process**

The thesis that code comprehension can be achieved through static knowledge representation, while powerful, rests on the assumption that a sufficiently detailed map of the code is equivalent to understanding the code's purpose and behavior. The antithesis to this view argues that true comprehension cannot be derived from static structures alone. Instead, it must be learned from the code's dynamic properties—its behavior during execution, its effect on a computational environment, and its semantic consequences. This section presents this contrasting paradigm, first by critically examining the inherent limitations of static analysis and then by introducing Meta's Code World Model (CWM) as the prime exemplar of a new approach focused on learning an internal, predictive model of code execution.

### **Section 4: The Inherent Limits of Static Representation**

Despite the sophistication of modern code KGs and the grounding they provide, systems built solely on static analysis exhibit fundamental limitations that reveal a "shallow" form of understanding. Empirical research demonstrates that while LLMs can generate syntactically correct and plausible code, their reasoning is often not rooted in a deep, functional model of the program's semantics. This shallowness is most starkly revealed by their fragility in the face of changes that are semantically irrelevant but textually distinct.

#### **The "Shallow Understanding" Problem**

Multiple studies have concluded that LLM code comprehension remains heavily tied to lexical and syntactic features rather than abstract, functional logic.12 Models often rely on non-functional cues, such as the names of variables and functions or the content of comments, to make inferences about a program's behavior.12 For example, an LLM might correctly infer the purpose of a function named calculate\_interest based on its name, without ever truly analyzing the mathematical operations within its body. This reliance on surface-level patterns means the model's "understanding" is brittle and can be easily misled.

#### **Brittleness to Semantic-Preserving Mutations (SPMs)**

The most compelling evidence for this shallow understanding comes from experiments involving Semantic-Preserving Mutations (SPMs). SPMs are changes made to a program's source code that do not alter its underlying functionality or behavior in any way.13 Examples of SPMs include:

* **Identifier Renaming:** Changing the name of a variable or function (e.g., from user\_list to items).  
* **Annotative Changes:** Modifying non-executing parts of the code, such as adding a misleading comment or altering a docstring.  
* **Structural Changes:** Inserting unreachable "dead code" or reordering the declaration of functions within a file.

A model with a deep, semantic understanding of code should be entirely insensitive to such changes. If it correctly identifies a bug in a piece of code, it should still be able to identify the same bug after a variable is renamed or a comment is added. However, research demonstrates the opposite. In one large-scale study, LLMs that initially succeeded at a debugging task failed on the same task in 81% of cases after SPMs were applied to the code.12 Another found that simply changing a function name and adding a misleading comment caused GPT-4o to fail a fault localization task it had previously solved, even though the core logic remained identical.13 This extreme sensitivity to non-functional properties provides strong evidence that the models are not reasoning about the code's behavior but are instead relying on a fragile form of pattern recognition.

#### **The Gap Between Structure and Execution**

This fragility exposes the core limitation of any purely static approach, including the KG paradigm. A Knowledge Graph, no matter how detailed, represents the *potential* for execution; it is a blueprint of the program's structure, not a model of the program's execution itself. It can show that function A calls function B, but it cannot intrinsically represent the state of the program's memory before and after that call, nor can it capture emergent behaviors or side effects that only manifest at runtime.

This gap between the static blueprint and the dynamic process of execution is critical. The failure of LLMs on SPM tasks can be understood through an analogy: it is like a security guard who has memorized a building's blueprint but becomes completely disoriented if someone paints a door a different color. This reveals that the guard never understood the functional purpose of the door (to be opened and closed) but only learned its superficial appearance on the map. Similarly, the brittleness of LLMs suggests that even when provided with a perfect blueprint (a comprehensive KG), their underlying reasoning mechanism is still susceptible to superficial distractions. This implies that providing a better static map may not be sufficient. To develop a more robust and genuine form of comprehension, the model must learn from the "building in use"—the dynamic, runtime behavior of the code. This provides the fundamental motivation for a new paradigm: the Code World Model.

### **Section 5: Meta's Code World Model (CWM): A New Frontier**

In direct response to the limitations of static analysis, Meta has introduced the Code World Model (CWM), a paradigm-shifting LLM designed to learn an internal, predictive model of code execution.27 The revolutionary promise of CWM is to move beyond matching the patterns of static code and instead model the *execution world* of the code itself.29 It achieves this by learning not just from finished source code, but from vast quantities of "observe-act-observe" trajectories that capture the dynamic state changes that occur as programs run.28

#### **CWM Architecture**

At its core, CWM is a 32-billion-parameter, dense, decoder-only Transformer model.27 Its architecture is optimized for handling the long and complex sequences found in code and execution traces. Key features include a very large context window of up to 131,000 tokens and the use of Grouped-Query Attention (GQA), an architectural innovation that reduces the memory requirements of the attention mechanism while maintaining high expressive power, making it feasible to process such long contexts.29

#### **The Three-Stage Training Pipeline**

The defining innovation of CWM lies in its unique, three-stage training pipeline, which is explicitly designed to build its world modeling capabilities incrementally.

1. **Pre-training:** The process begins with a standard pre-training phase to build a foundational model. CWM was trained on 8 trillion tokens of data, comprising approximately 30% source code from various languages and 70% general text, with a focus on English and STEM-related content. This stage provides the model with broad programming knowledge and general language understanding.29  
2. **Mid-training:** This is the crucial "world modeling" phase where CWM learns the dynamics of code execution. In this stage, the model is trained for an additional 5 trillion tokens on highly specialized datasets that consist of execution trajectories. This data includes:  
   * **Python Memory Traces:** Approximately 200 million traces capturing the step-by-step execution of Python functions. These traces record the sequence of function calls, the state of variables in memory, and the flow of control, effectively showing the model the consequences of each line of code.29  
   * **Agentic Trajectories:** Approximately 3 million trajectories from AI agents attempting to solve coding tasks within containerized Docker environments. This data captures a sequence of actions (e.g., writing code, running tests, debugging) and their observed outcomes, teaching the model a higher-level understanding of the software development process.28  
   * **Specialized Code Data:** The mid-training corpus also includes other forms of data that reflect code dynamics, such as GitHub pull request diffs (showing code evolution) and compiler intermediate representations.29  
3. **Post-training:** Finally, the model is refined for specific tasks through a combination of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During the RL phase, which used approximately 172 billion tokens, the model was trained on a multi-task mixture of verifiable coding challenges, mathematical problems, and software engineering scenarios. It received rewards for successful outcomes, such as passing unit tests or arriving at a correct mathematical solution, further honing its reasoning and problem-solving abilities.28

This training process represents a fundamental departure from static methods. The mid-training phase is a form of "implicit simulation" that forces the model to build an intuitive "physics engine" for code. In a traditional AI world model, the system learns a predictive model of its environment.32 CWM applies this concept to code. The execution trajectories effectively present the model with sequences of (state\_1, action, state\_2), where state is the program's memory and action is a line of code. The model's task is to learn to predict state\_2 given state\_1 and action. By mastering this predictive task over billions of examples, the LLM is not merely memorizing syntax; it is learning the *semantic effect* of that syntax on a computational environment. This is a much deeper level of understanding than that offered by a static KG, which can only represent the code as a node with fixed properties. CWM learns a *function* that transforms state, building an internal model of computation itself.

| Component | Specification | Key Data Sources | Purpose |
| :---- | :---- | :---- | :---- |
| **Architecture** | 32B parameters, Decoder-only Transformer, 131k context, Grouped-Query Attention (GQA) | N/A | High-capacity model for processing long, complex code and execution sequences. |
| **Pre-training** | 8 trillion tokens | \~30% source code, \~70% general text (English, STEM) | Build foundational knowledge of programming languages and natural language. |
| **Mid-training** | 5 trillion tokens | Python memory traces, Agentic Docker trajectories, GitHub PR diffs, Compiler IRs | **(World Modeling)** Learn the dynamic behavior and semantic consequences of code execution. |
| **Post-training** | \~100B SFT tokens, \~172B RL tokens | Verifiable coding challenges (e.g., SWE-bench), Mathematical problems (e.g., AIME) | Refine the model for complex, multi-step reasoning and agentic problem-solving. |

---

*Table 2: An overview of the architecture and three-stage training pipeline of Meta's Code World Model (CWM). The table highlights the novel "mid-training" phase, which is dedicated to teaching the model an internal, predictive model of code execution dynamics.*

### **Section 6: CWM in Practice: Simulation, Agency, and Performance**

The theoretical advantages of CWM's dynamic training paradigm are substantiated by its practical capabilities and its exceptional performance on a range of difficult industry benchmarks. These results validate the claim that learning from execution builds a more robust and powerful form of code comprehension, extending beyond simple code generation to encompass simulation, agentic problem-solving, and formal reasoning.

#### **Demonstrated Capabilities**

The "world model" trained into CWM manifests as several concrete, advanced capabilities:

* **Execution Simulation:** CWM can perform a step-by-step "mental simulation" of Python code execution. Given a piece of code, it can generate a natural language description of how the program state (variables, memory) changes line by line, effectively predicting the execution trace.27 This ability to reason about runtime behavior is the foundation of its other advanced skills.  
* **Agentic Coding:** The model shows strong potential for agentic tasks, where it acts as an autonomous agent to solve complex software engineering problems. This involves breaking down a problem, planning a sequence of actions (e.g., write code, run tests, read error messages, debug), and executing that plan within a computational environment like a Docker container.27  
* **General World Modeling:** The underlying concept of using an LLM to generate an executable world model is not limited to code. Other research has shown that this approach can be applied to different domains, such as classical board games. In this application, the LLM translates the natural language rules of a game into a formal, executable Python model. This generated model then serves as a verifiable simulation engine for high-performance planning algorithms like Monte Carlo Tree Search (MCTS), leading to strategically superior play compared to using the LLM directly.33

#### **Benchmark Performance**

CWM's effectiveness is quantitatively demonstrated by its state-of-the-art or highly competitive performance on several of the most challenging benchmarks in coding and mathematical reasoning:

* **SWE-bench Verified:** CWM achieves a pass@1 score of 65.8% on this benchmark, which requires agents to resolve real-world bugs and feature requests from open-source projects on GitHub. This is a strong result on a task that demands deep, repository-level context and practical debugging skills.27  
* **LiveCodeBench:** The model scores 68.6% on this benchmark, which evaluates performance on problems from live, timed competitive programming contests, a task that requires both algorithmic correctness and efficiency.27  
* **Mathematical Reasoning:** CWM's performance on math benchmarks is particularly revealing. It achieves a near-perfect 96.6% on Math-500 (a dataset of grade-school math word problems) and, more impressively, a score of 76.0% on the AIME 2024 problems. AIME is a high-school mathematics Olympiad, and a 76.0% score represents a very high level of performance on problems that require complex, multi-step formal reasoning.27  
* **Other Benchmarks:** The model also demonstrates strong results on a variety of other specialized tasks, including coding puzzles (CruxEval), reasoning about algorithmic complexity (BigOBench), and long-context code understanding (RULER and LoCoDiff).29

The model's exceptional performance on mathematical reasoning is not an ancillary benefit; it is a direct consequence of its training on code execution. There is a deep structural isomorphism between solving a formal math problem and executing a computer program. Both processes involve a sequence of discrete, logical steps where each step transforms the state of the system (the mathematical expression or the computer's memory) according to a set of strict, formal rules (axioms and theorems or the semantics of the programming language). The core structure of the reasoning is identical: $state\_{n+1} \= f(state\_n, rule)$. By training CWM on millions of Python execution traces, its developers were not just teaching it "Python"; they were training it to be a general-purpose symbolic reasoning engine. This powerful, generalized capability is then transferable to other formal domains like mathematics, explaining its remarkable success on Olympiad-level problems. The Code World Model is, in essence, a Formal Reasoning World Model.

## **Part III: Synthesis \- Towards a Holistic Framework for Code Comprehension**

Having established the dialectic between the static, structure-oriented Knowledge Graph paradigm (the thesis) and the dynamic, execution-oriented Code World Model paradigm (the antithesis), the final part of this report seeks a synthesis. A holistic framework for code comprehension must reconcile these seemingly opposing views. This section will directly compare the two approaches, explore their potential for synergistic integration, place them within a broader ecosystem of enhancement techniques, and use a Socratic lens to probe the fundamental limits of our current understanding, charting a course for future research and practice.

### **Section 7: A Dialectical Synthesis: Reconciling Static and Dynamic Models**

The KG and CWM paradigms represent two distinct and powerful philosophies for achieving code comprehension. The former prioritizes explicit, verifiable knowledge of structure, while the latter prioritizes an implicit, predictive understanding of behavior. A simple "A versus B" comparison is insufficient; a deeper analysis reveals them to be complementary, with the potential for a powerful synthesis that combines the strengths of both.

A direct comparison highlights their fundamental differences. KGs provide an *explicit* graph-based representation of the codebase, which is human-inspectable, formally queryable, and easily verifiable.14 Their primary mode of reasoning is *retrieval and traversal*—finding factual information within the graph. In contrast, CWMs build an *implicit* neural model of the code's execution world, stored within the model's weights.28 Their primary reasoning mode is *predictive simulation*—forecasting the consequences of code execution. While KGs excel at providing a comprehensive, static architectural view, they are inherently limited in their ability to capture runtime dynamics. CWMs excel at modeling these dynamics but lack the explicit verifiability of a KG; their internal model is an opaque "black box."

This juxtaposition invites a Socratic inquiry into their potential synergy. Are these approaches truly mutually exclusive, or are they two essential components of a more complete system? Several potential integrations emerge:

* **Can a KG bootstrap a World Model?** An agentic model like CWM, when faced with a large, unfamiliar codebase, could use a KG as a high-level "map" to guide its exploration and planning. The KG could quickly provide the architectural context—identifying key modules, critical dependencies, and relevant APIs—allowing the CWM to focus its more computationally expensive simulations on the most pertinent parts of the code. The KG provides the architectural "what" and "where," while the CWM simulates the behavioral "how" and "what if".19  
* **Can a World Model enrich a KG?** The relationship can also be reciprocal. The dynamic insights generated by a CWM could be used to augment and validate a static KG. For example, by simulating common usage scenarios, a CWM could identify runtime data flows, performance bottlenecks, or frequently co-occurring function calls that are not apparent from static analysis alone. This information could then be added as new edges or properties in the KG, transforming the static "blueprint" into a living document that reflects actual, dynamic usage patterns.  
* **Can Hybrid Representations Bridge the Gap?** A more radical integration involves changing the representation itself. Recent research has explored representing KGs *as code*—for instance, defining entities and relationships as Python classes and method calls—and then using this code as training data for an LLM.22 This approach leverages the LLM's natural affinity for parsing and understanding structured code to more effectively internalize the logical relationships of the graph, tightly integrating the structured knowledge into the model's reasoning process.

This line of inquiry leads to a powerful synthesis: the ultimate system for code comprehension will likely be a hybrid "Digital Twin" of the codebase. In this model, the KG serves as the static, structural "blueprint," providing a complete and verifiable map of the system's design. The CWM component acts as the dynamic "physics simulation engine," capable of modeling the behavior of the system under various conditions. A query like, "What is the blast radius if I change this core API?" would be answered through a two-stage process. First, the system would execute a fast, deterministic query against the KG to identify all direct and indirect static dependencies, mapping the potential blast radius. Second, for a few critical downstream components identified in the first stage, the system would invoke the CWM to run a "mental simulation" of the proposed change, predicting whether tests would fail or if runtime behavior would be altered in unexpected ways. This hybrid approach combines the architectural breadth and verifiability of the KG with the behavioral depth and predictive insight of the CWM, creating a far more powerful and comprehensive comprehension system than either paradigm could achieve in isolation.

| Dimension | Knowledge Graph (KG) with RAG | Code World Model (CWM) |
| :---- | :---- | :---- |
| **Representation Type** | Explicit, symbolic graph (nodes & edges) | Implicit, sub-symbolic neural network weights |
| **Primary Reasoning Mode** | Query, retrieval, and graph traversal | Predictive simulation and pattern completion |
| **Handling of Dynamics** | Limited; represents static potential for execution | Core strength; models runtime state changes and behavior |
| **Verifiability** | High; retrieved facts are explicit and auditable | Low; reasoning is opaque ("black box") |
| **Update Mechanism** | Continuous; graph can be updated as code changes | Episodic; requires expensive retraining/fine-tuning |
| **Key Strength** | Architectural overview, verifiable facts, multi-hop structural queries | Deep semantic understanding of execution, agentic planning, reasoning about emergent behavior |
| **Key Weakness** | Inability to model runtime state and side effects | High computational cost, lack of explicit verifiability, potential for hallucination in simulation |

---

*Table 3: A comparative analysis of the Knowledge Graph-RAG and Code World Model paradigms across key dimensions. The table highlights their complementary strengths and weaknesses, motivating the need for a synthesized, hybrid approach.*

### **Section 8: A Systems-Level View of the Comprehension Ecosystem**

The KG and CWM paradigms, while central, do not exist in a vacuum. They are the core components of a broader, emerging ecosystem of techniques, each playing a specific role. A systems-level perspective reveals that these methods are not merely a collection of alternatives but are forming a coherent, hierarchical "stack" for code comprehension, where each layer builds upon the one below it.

1. **Layer 1: Input Processing and Representation.** At the base of the stack is the initial processing of raw code into intelligent, machine-readable units. Naive methods like splitting code by line or fixed token count are being superseded by structure-aware techniques. **Chunking via Abstract Syntax Trees (CAST)**, for example, uses the AST to recursively break code into self-contained, semantically coherent chunks that respect syntactic boundaries.4 This intelligent chunking is a critical prerequisite for all subsequent layers, as it provides higher-quality input for both KG construction and for retrieval in RAG systems.  
2. **Layer 2: Knowledge Modeling and Encoding.** Once the code is chunked, this layer is responsible for building the core knowledge representations. This is where the two primary paradigms reside: the construction of a static **Code Knowledge Graph** to model structure and relationships, and the generation of **execution trajectories** to train a dynamic **Code World Model**.14 This layer also includes **Code Representation Learning**, which uses techniques like contrastive learning (e.g., ContraCode) to generate dense **vector embeddings** of code snippets.37 These embeddings, which place functionally similar code close together in a vector space, are essential for semantic search and can be used to enrich the nodes of a KG or as inputs to a CWM.17  
3. **Layer 3: Context Provisioning and Retrieval.** When a user query arrives, this layer is responsible for providing the core LLM with the necessary context to generate an informed response. For the KG paradigm, this involves **Retrieval-Augmented Generation**, where a relevant subgraph is retrieved and provided as context.20 For the CWM paradigm, this might involve setting up an initial state for a predictive simulation.  
4. **Layer 4: Reasoning and Synthesis.** This is the "brain" of the system, where a core LLM operates on the context provided by the layer below. The LLM's reasoning is structured and guided by **Advanced Prompting Strategies**. Frameworks like **Chain-of-Thought (CoT)**, where the model is prompted to "think step by step," or agentic frameworks like **ReAct** (Reason+Act), provide the scaffolding for the LLM to decompose complex problems, formulate plans, and synthesize information from the retrieved context.35 The prompt serves as the API to the model's latent reasoning capabilities.  
5. **Layer 5: Specialization and Adaptation.** At the top of the stack, the entire system can be specialized for a particular domain or codebase through **Fine-Tuning**. A general-purpose model, whether used for RAG or as a CWM agent, can be further trained on a company's proprietary codebase, its internal documentation, or its specific runtime logs to adapt its behavior and improve its performance on domain-specific tasks.44 This specialization must be approached with caution, as some argue that fine-tuning can act as a "destructive overwrite," potentially degrading the model's general capabilities.46

This layered view demonstrates that the various methods for enhancing LLM code comprehension are not competitors but are becoming integrated components of a full-stack code intelligence system. Each layer addresses a specific part of the problem, from parsing raw text to executing complex reasoning, forming a complete pipeline from code to comprehension.

### **Section 9: Unanswered Questions and Future Trajectories**

As the field rapidly advances, it is crucial to apply a Socratic lens to challenge its core assumptions, identify its blind spots, and define the next set of fundamental questions. The progress from static KGs to dynamic CWMs is significant, but it also brings the limits of our current understanding into sharper focus, suggesting future trajectories that must transcend today's paradigms.

#### **What is "Understanding"?**

The central, and perhaps most difficult, unanswered question is what we truly mean by "comprehension" for a non-sentient artificial agent. Current state-of-the-art evaluation is dominated by metrics of functional correctness, such as the pass@k metric, which measures the percentage of time a model generates code that passes a set of unit tests.47 While useful, the research on Semantic-Preserving Mutations (SPMs) strongly suggests that functional correctness is not equivalent to genuine understanding.12 A model can learn to generate statistically likely code that passes tests for problems it has seen in its training data, while possessing no deeper model of the code's intent or logic. This raises profound questions: Are we building systems that truly reason about code, or are we building exceptionally sophisticated mimics? The next generation of research must grapple with the gap between mimicking behavior and possessing a robust, generalizable model of computational principles.

#### **The Crisis of Evaluation**

This ambiguity in the definition of understanding leads directly to a crisis in evaluation. Current benchmarks are facing significant challenges. They are susceptible to data contamination, where the benchmark problems inevitably become part of the training data for next-generation models, rendering them unreliable measures of true generalization.12 Furthermore, some code similarity metrics used in evaluation have been shown to be heavily biased towards surface-level textual similarity rather than true functional or semantic equivalence.48 To move forward, the field urgently needs new evaluation paradigms that probe for deeper reasoning. Future benchmarks might need to focus on:

* **Novelty:** Testing a model's ability to explain or implement entirely novel algorithms it has never seen before.  
* **Abstraction:** Evaluating the ability to identify high-level architectural patterns or flaws, rather than just line-level bugs.  
* **Non-Functional Requirements:** Assessing comprehension of concepts like algorithmic complexity (as in BigOBench 29), security vulnerabilities, or performance characteristics.

#### **Scaling, Efficiency, and the Path to a "Meaning Barrier"**

The current trajectory of building ever-larger models is hitting practical limits. Training a 32B+ parameter model like CWM or constructing and maintaining a comprehensive KG for a massive enterprise codebase are computationally and financially prohibitive for all but a few organizations.29 This necessitates research into more efficient methods. Can the rich, dynamic knowledge of a large CWM be "distilled" into a smaller, faster model? How can we leverage LLMs to automate the labor-intensive process of KG construction and curation?21

More fundamentally, the field may be approaching a "Meaning Barrier." Current models, whether static or dynamic, are exceptionally proficient at manipulating syntax and modeling the operational semantics of code.29 They are learning *what* the code is and *how* it executes. However, none of these paradigms explicitly model the *why*. Why was this architecture chosen over another? What business requirement does this module fulfill? What was the programmer's *intent* when writing this line of code? This layer of intentionality and design rationale is not present in the source code's text or its execution trace. It exists in unstructured, natural language artifacts: design documents, code review discussions, commit messages, and the tacit knowledge of the engineering team.52 The next major breakthrough in code comprehension will likely come not from simply scaling today's architectures, but from developing a new paradigm that can successfully bridge the gap from "what the code does" to "what the code is *for*," creating a truly holistic understanding that integrates structure, behavior, and intent.

### **Section 10: Recommendations for Research and Practice**

The critical evaluation of modern paradigms for LLM code comprehension yields a set of actionable recommendations for practitioners seeking to leverage these technologies, for researchers pushing the boundaries of the field, and for the broader AI community dedicated to building more capable and reliable systems.

#### **For Practitioners (Software Architects and Engineering Leads)**

1. **Invest in a Code Knowledge Graph as a Foundational Asset.** The immediate, practical value of a code KG is immense. The process of building a KG, even with basic static analysis tools, provides invaluable insights into a codebase's architecture, dependencies, and health.14 This graph serves as a durable, foundational asset that powers immediate use cases like enhanced code search, new developer onboarding, and architectural drift detection, while also paving the way for future, more advanced GraphRAG applications.14  
2. **Prioritize GraphRAG for Codebase-Specific Q\&A.** For the task of grounding an LLM in a specific, private codebase, the GraphRAG approach is currently superior to fine-tuning. RAG offers a more reliable, auditable, and cost-effective solution for knowledge injection.19 It allows the knowledge base (the KG) to be updated continuously as the code evolves, without the need for expensive model retraining. This avoids the potential pitfalls of fine-tuning, which can be an opaque and sometimes destructive process that overwrites a model's general capabilities.46

#### **For AI/ML Researchers**

1. **Focus on Hybrid Architectures.** The dialectical synthesis of this report strongly indicates that the most promising path forward lies in hybrid models that integrate the strengths of static KGs and dynamic World Models. The future is not a choice between the two but a combination of both. Research into novel architectures that treat the KG as a first-class component for agentic planning, memory, and reasoning—rather than just an external context to be stuffed into a prompt—is critical. This could involve tighter integration, such as using Graph Neural Networks (GNNs) to operate directly on the KG within the LLM's reasoning loop.16  
2. **Develop New Frontiers in Evaluation.** The field is constrained by its metrics. A concerted effort is needed to move beyond benchmarks based on functional correctness alone. Researchers should focus on creating novel evaluation frameworks that probe for deeper semantic reasoning. This includes developing benchmarks that are robust to data contamination, that incorporate adversarial SPMs by design, and that test for higher-order understanding of abstract software engineering concepts like design patterns, algorithmic complexity, and security principles.

#### **For the Broader AI Community**

1. **Support and Contribute to Open Models and Datasets.** Progress in a field as complex as code comprehension is accelerated by collaboration and shared resources. The release of powerful open-weights models like Meta's CWM is a vital contribution, as it provides a common, state-of-the-art testbed for the global research community to explore, critique, and build upon these new paradigms.27 Continued support for open models, open-source tooling for KG construction, and open, dynamic execution-based datasets will be essential for driving the next wave of innovation.

#### **Works cited**

1. GRAPH4CODE: A Machine Interpretable Knowledge Graph for Code \- Semantic Web Journal, accessed October 20, 2025, [https://www.semantic-web-journal.net/system/files/swj2575.pdf](https://www.semantic-web-journal.net/system/files/swj2575.pdf)  
2. Learning Graph-based Code Representations for ... \- Jun ZENG, accessed October 20, 2025, [https://jun-zeng.github.io/file/tailor\_paper.pdf](https://jun-zeng.github.io/file/tailor_paper.pdf)  
3. How Abstract Syntax Trees Unlock LLM's Code Understanding | by Danilka AKarawita, accessed October 20, 2025, [https://medium.com/@nishandanilka/how-abstract-syntax-trees-unlock-llms-code-understanding-5fa88877123a](https://medium.com/@nishandanilka/how-abstract-syntax-trees-unlock-llms-code-understanding-5fa88877123a)  
4. cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree \- CMU School of Computer Science, accessed October 20, 2025, [https://www.cs.cmu.edu/\~sherryw/assets/pubs/2025-cast.pdf](https://www.cs.cmu.edu/~sherryw/assets/pubs/2025-cast.pdf)  
5. NL in the Middle: Code Translation with LLMs and Intermediate Representations \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2507.08627v2](https://arxiv.org/html/2507.08627v2)  
6. LLM generated code snippet merging into existing using ASTs : r/theprimeagen \- Reddit, accessed October 20, 2025, [https://www.reddit.com/r/theprimeagen/comments/1idtjp2/llm\_generated\_code\_snippet\_merging\_into\_existing/](https://www.reddit.com/r/theprimeagen/comments/1idtjp2/llm_generated_code_snippet_merging_into_existing/)  
7. Elevating code quality with LLM integration \- Adyen, accessed October 20, 2025, [https://www.adyen.com/knowledge-hub/elevating-code-quality-through-llm-integration](https://www.adyen.com/knowledge-hub/elevating-code-quality-through-llm-integration)  
8. Control-flow graph \- Wikipedia, accessed October 20, 2025, [https://en.wikipedia.org/wiki/Control-flow\_graph](https://en.wikipedia.org/wiki/Control-flow_graph)  
9. Control and Data Flow Analysis \- Semantic Designs, accessed October 20, 2025, [https://www.semanticdesigns.com/Products/DMS/FlowAnalysis.html](https://www.semanticdesigns.com/Products/DMS/FlowAnalysis.html)  
10. arxiv.org, accessed October 20, 2025, [https://arxiv.org/html/2310.02128v2](https://arxiv.org/html/2310.02128v2)  
11. (PDF) Semantic Code Graph—An Information Model to Facilitate ..., accessed October 20, 2025, [https://www.researchgate.net/publication/377287545\_Semantic\_Code\_Graph\_-\_an\_information\_model\_to\_facilitate\_software\_comprehension/download](https://www.researchgate.net/publication/377287545_Semantic_Code_Graph_-_an_information_model_to_facilitate_software_comprehension/download)  
12. How Accurately Do Large Language Models Understand Code? \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2504.04372v1](https://arxiv.org/html/2504.04372v1)  
13. Research \- How LLM Understand The Code | PDF | Cognitive Science \- Scribd, accessed October 20, 2025, [https://www.scribd.com/document/879104405/Research-how-Llm-Understand-the-Code](https://www.scribd.com/document/879104405/Research-how-Llm-Understand-the-Code)  
14. Building a Knowledge Graph of Your Codebase \- Daytona, accessed October 20, 2025, [https://www.daytona.io/dotfiles/building-a-knowledge-graph-of-your-codebase](https://www.daytona.io/dotfiles/building-a-knowledge-graph-of-your-codebase)  
15. Code Graph: From Visualization to Integration \- FalkorDB, accessed October 20, 2025, [https://www.falkordb.com/blog/code-graph/](https://www.falkordb.com/blog/code-graph/)  
16. Knowledge graph \- Wikipedia, accessed October 20, 2025, [https://en.wikipedia.org/wiki/Knowledge\_graph](https://en.wikipedia.org/wiki/Knowledge_graph)  
17. Knowledge Graph Based Repository-Level Code Generation \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2505.14394v1](https://arxiv.org/html/2505.14394v1)  
18. Knowledge Graphs. This is a tutorial based on this… | by Dr. Nimrita Koul \- Medium, accessed October 20, 2025, [https://medium.com/@nimritakoul01/knowledge-graphs-f51adb293401](https://medium.com/@nimritakoul01/knowledge-graphs-f51adb293401)  
19. Grounding Large Language Models with Knowledge Graphs \- DataWalk, accessed October 20, 2025, [https://datawalk.com/grounding-large-language-models-with-knowledge-graphs/](https://datawalk.com/grounding-large-language-models-with-knowledge-graphs/)  
20. Applications of Knowledge Graphs in LLMs: 3 Important Cases \- Data Science Dojo, accessed October 20, 2025, [https://datasciencedojo.com/blog/knowledge-graphs/](https://datasciencedojo.com/blog/knowledge-graphs/)  
21. Insights, Techniques, and Evaluation for LLM-Driven Knowledge Graphs | NVIDIA Technical Blog, accessed October 20, 2025, [https://developer.nvidia.com/blog/insights-techniques-and-evaluation-for-llm-driven-knowledge-graphs/](https://developer.nvidia.com/blog/insights-techniques-and-evaluation-for-llm-driven-knowledge-graphs/)  
22. Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data, accessed October 20, 2025, [https://www.promptlayer.com/research-papers/how-knowledge-graphs-can-supercharge-llm-reasoning](https://www.promptlayer.com/research-papers/how-knowledge-graphs-can-supercharge-llm-reasoning)  
23. Deep Dive into Knowledge Graph Components for LLM RAG Applications — With a Real World Example | by Gaurav Nigam | aingineer | Medium, accessed October 20, 2025, [https://medium.com/aingineer/deep-dive-into-knowledge-graph-components-for-llm-rag-applications-with-a-real-world-example-9f2a7c585015](https://medium.com/aingineer/deep-dive-into-knowledge-graph-components-for-llm-rag-applications-with-a-real-world-example-9f2a7c585015)  
24. Why we ditched embeddings for knowledge graphs (and why chunking is fundamentally broken) : r/LLMDevs \- Reddit, accessed October 20, 2025, [https://www.reddit.com/r/LLMDevs/comments/1n3iwrr/why\_we\_ditched\_embeddings\_for\_knowledge\_graphs/](https://www.reddit.com/r/LLMDevs/comments/1n3iwrr/why_we_ditched_embeddings_for_knowledge_graphs/)  
25. When Names Disappear: Revealing What LLMs Actually Understand About Code, accessed October 20, 2025, [https://www.researchgate.net/publication/396223852\_When\_Names\_Disappear\_Revealing\_What\_LLMs\_Actually\_Understand\_About\_Code](https://www.researchgate.net/publication/396223852_When_Names_Disappear_Revealing_What_LLMs_Actually_Understand_About_Code)  
26. How Accurately Do Large Language Models Understand ... \- arXiv, accessed October 20, 2025, [https://www.arxiv.org/pdf/2504.04372](https://www.arxiv.org/pdf/2504.04372)  
27. CWM: An Open-Weights LLM for Research on Code Generation with World Models \- arXiv, accessed October 20, 2025, [https://arxiv.org/abs/2510.02387](https://arxiv.org/abs/2510.02387)  
28. CWM: An Open-Weights LLM for Research on Code ... \- Rivista AI, accessed October 20, 2025, [https://www.rivista.ai/wp-content/uploads/2025/09/553592426\_661450129912484\_4072750821656455102\_n.pdf](https://www.rivista.ai/wp-content/uploads/2025/09/553592426_661450129912484_4072750821656455102_n.pdf)  
29. Code World Model: First Reactions to Meta's Release \- PromptLayer Blog, accessed October 20, 2025, [https://blog.promptlayer.com/code-world-model-first-reactions-to-metas-release/](https://blog.promptlayer.com/code-world-model-first-reactions-to-metas-release/)  
30. Code World Model: The Dawn of Self-Aware Software | by noailabs | Sep, 2025 \- Medium, accessed October 20, 2025, [https://noailabs.medium.com/code-world-model-the-dawn-of-self-aware-software-b07a37cfd600](https://noailabs.medium.com/code-world-model-the-dawn-of-self-aware-software-b07a37cfd600)  
31. CWM: An Open-Weights LLM for Research on Code Generation with World Models, accessed October 20, 2025, [https://chatpaper.com/paper/195780](https://chatpaper.com/paper/195780)  
32. World Models, accessed October 20, 2025, [https://worldmodels.github.io/](https://worldmodels.github.io/)  
33. \[2510.04542\] Code World Models for General Game Playing \- arXiv, accessed October 20, 2025, [https://arxiv.org/abs/2510.04542](https://arxiv.org/abs/2510.04542)  
34. CWM: An Open-Weights LLM for Research on Code Generation with World Models \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2510.02387v1](https://arxiv.org/html/2510.02387v1)  
35. LLM Agents \- Prompt Engineering Guide, accessed October 20, 2025, [https://www.promptingguide.ai/research/llm-agents](https://www.promptingguide.ai/research/llm-agents)  
36. Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data, accessed October 20, 2025, [https://arxiv.org/html/2412.10654v1](https://arxiv.org/html/2412.10654v1)  
37. Code Representation Learning \- IBM Research, accessed October 20, 2025, [https://research.ibm.com/projects/code-representation-learning](https://research.ibm.com/projects/code-representation-learning)  
38. Contrastive Code Representation Learning \- OpenReview, accessed October 20, 2025, [https://openreview.net/forum?id=uV7hcsjqM-](https://openreview.net/forum?id=uV7hcsjqM-)  
39. TECCD: A Tree Embedding Approach for Code Clone Detection \- TJU SAIL, accessed October 20, 2025, [https://tjusail.github.io/people/papers/TECCD-%20A%20Tree%20Embedding%20Approach%20for%20Code%20Clone%20Detection.pdf](https://tjusail.github.io/people/papers/TECCD-%20A%20Tree%20Embedding%20Approach%20for%20Code%20Clone%20Detection.pdf)  
40. Code Search with Vector Embeddings and Qdrant \- Hugging Face Open-Source AI Cookbook, accessed October 20, 2025, [https://huggingface.co/learn/cookbook/code\_search](https://huggingface.co/learn/cookbook/code_search)  
41. A Survey of Techniques, Key Components, Strategies, Challenges, and Student Perspectives on Prompt Engineering for Large Language Models (LLMs) in Education \- Preprints.org, accessed October 20, 2025, [https://www.preprints.org/manuscript/202503.1808/v1](https://www.preprints.org/manuscript/202503.1808/v1)  
42. Advanced Prompt Engineering Techniques \- Mercity AI, accessed October 20, 2025, [https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques](https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques)  
43. 17 Prompting Techniques to Supercharge Your LLMs \- Analytics Vidhya, accessed October 20, 2025, [https://www.analyticsvidhya.com/blog/2024/10/17-prompting-techniques-to-supercharge-your-llms/](https://www.analyticsvidhya.com/blog/2024/10/17-prompting-techniques-to-supercharge-your-llms/)  
44. Fine-Tuning LLMs: Expert Guide to Task-Specific AI Models \- Rapid Innovation, accessed October 20, 2025, [https://www.rapidinnovation.io/post/for-developers-step-by-step-guide-to-fine-tuning-llms-for-specific-tasks](https://www.rapidinnovation.io/post/for-developers-step-by-step-guide-to-fine-tuning-llms-for-specific-tasks)  
45. LLM Fine-Tuning—Overview with Code Example \- Nexla, accessed October 20, 2025, [https://nexla.com/enterprise-ai/llm-fine-tuning/](https://nexla.com/enterprise-ai/llm-fine-tuning/)  
46. Fine-Tuning LLMs is a Huge Waste of Time | by Devansh | Medium, accessed October 20, 2025, [https://machine-learning-made-simple.medium.com/fine-tuning-llms-is-a-huge-waste-of-time-bd0b98fcc282](https://machine-learning-made-simple.medium.com/fine-tuning-llms-is-a-huge-waste-of-time-bd0b98fcc282)  
47. A Systematic Survey on Large Language Models for Code Generation, accessed October 20, 2025, [https://aro.koyauniversity.org/index.php/aro/article/view/2159](https://aro.koyauniversity.org/index.php/aro/article/view/2159)  
48. Analyzing and Mitigating Surface Bias in Code Evaluation Metrics \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2509.15397v2](https://arxiv.org/html/2509.15397v2)  
49. GraphRAG: The Practical Guide for Cost-Effective Document Analysis with Knowledge Graphs \- LearnOpenCV, accessed October 20, 2025, [https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/](https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/)  
50. What is LLM? \- Large Language Models Explained \- AWS \- Updated 2025, accessed October 20, 2025, [https://aws.amazon.com/what-is/large-language-model/](https://aws.amazon.com/what-is/large-language-model/)  
51. Introduction to Large Language Models | Machine Learning \- Google for Developers, accessed October 20, 2025, [https://developers.google.com/machine-learning/resources/intro-llms](https://developers.google.com/machine-learning/resources/intro-llms)  
52. Code Comprehension: Review and Large Language Models Exploration \- UC Homepages, accessed October 20, 2025, [https://homepages.uc.edu/\~yuc5/files/Code\_Comprehension\_Review\_and\_Large\_Language\_Models\_Exploration.pdf](https://homepages.uc.edu/~yuc5/files/Code_Comprehension_Review_and_Large_Language_Models_Exploration.pdf)  
53. LLM-Based Detection of Tangled Code Changes for Higher-Quality Method-Level Bug Datasets \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2505.08263v2](https://arxiv.org/html/2505.08263v2)  
54. LLM-Based Detection of Tangled Code Changes for Higher-Quality Method-Level Bug Datasets \- arXiv, accessed October 20, 2025, [https://arxiv.org/html/2505.08263v1](https://arxiv.org/html/2505.08263v1)  
55. Building a Brilliant AI Copilot: Using Knowledge Graphs as a Codebase | by Daniel Avila, accessed October 20, 2025, [https://medium.com/@dan.avila7/building-a-brilliant-ai-copilot-using-knowledge-graphs-as-a-codebase-7b8c701b6763](https://medium.com/@dan.avila7/building-a-brilliant-ai-copilot-using-knowledge-graphs-as-a-codebase-7b8c701b6763)  
56. Knowledge graph for codebase : r/AskProgramming \- Reddit, accessed October 20, 2025, [https://www.reddit.com/r/AskProgramming/comments/1m255hi/knowledge\_graph\_for\_codebase/](https://www.reddit.com/r/AskProgramming/comments/1m255hi/knowledge_graph_for_codebase/)