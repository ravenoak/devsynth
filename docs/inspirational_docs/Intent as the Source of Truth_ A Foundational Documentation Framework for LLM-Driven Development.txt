Intent as the Source of Truth: A Foundational Documentation Framework for LLM-Driven Development




I. The Unified Framework for AI-Agent Collaboration


The advent of Large Language Model (LLM) agents as active participants in the software development lifecycle marks a paradigm shift, moving the industry from a code-first to an intent-first model. To effectively harness the capabilities of AI coding assistants like Cursor IDE, development teams must evolve beyond ad-hoc prompting and establish a rigorous framework that provides a solid, wide, and stable foundation for the AI. This requires a synthesis of two powerful methodologies: Spec-Driven Development (SDD), which provides the operational blueprint for the AI, and Behavior-Driven Development (BDD), which supplies the universal language of intent. Together, they form a cohesive strategy where human-defined behavior directly drives AI-generated implementation, ensuring that the resulting software is not only functionally correct but also perfectly aligned with business objectives.


Spec-Driven Development (SDD): The Operational Blueprint for LLM Agents


Spec-Driven Development emerges as a structured process designed to impose discipline on AI-assisted coding, moving beyond the unstructured, exploratory nature of "vibe coding".1 Its core philosophy is a radical departure from traditional practices: the specification is not merely documentation created after the fact, but an executable contract that serves as the primary source of truth for the entire project.1 In this model, the human developer's role transitions from a line-by-line author of code to a high-level "steerer" and verifier of intent, guiding the LLM agent through a structured, multi-step refinement process.3 This approach provides the essential guardrails needed to generate production-ready, enterprise-grade applications with AI.6
The SDD process is typically divided into four distinct phases, creating a clear workflow that ensures intent is translated into implementation with precision and verifiability.
1. Specify: The initial phase is dedicated to defining the "what" and the "why" of the project in natural language. This high-level description focuses exclusively on user journeys, experiences, and success criteria.1 Critically, it avoids technical details such as technology stacks or application design, allowing the team to establish a clear, shared understanding of the project's goals before any implementation decisions are made.2 The output of this phase is a detailed specification document that becomes a living artifact for the project.3
2. Plan: In this phase, the focus shifts from "what" to "how." Guided by the developer, the coding agent consumes the high-level specification and generates a comprehensive technical plan. This plan incorporates the desired technology stack, architectural patterns, and any organizational or enterprise constraints.1 A key advantage of this phase is the ability to explore and compare multiple implementation strategies or technology stacks, allowing for more informed architectural decisions early in the lifecycle.5
3. Tasks: Once the technical plan is approved, the LLM agent transforms the specification and plan into actionable work. It generates small, reviewable tasks, where each task addresses a specific component and is designed to be implementable and testable in isolation.1 This methodical breakdown mirrors the principles of Test-Driven Development (TDD), providing the AI agent with a clear path to validate its work and maintain focus.3 Instead of a broad directive like "build authentication," the agent receives precise tasks such as "create a user registration endpoint that validates email format".1
4. Implement: With a clear set of tasks, the agent executes them to generate production-ready code. The developer's role during this phase is not to write code but to evaluate focused, specific changes that address particular problems.1 This is a significant departure from reviewing massive, monolithic pull requests. The process includes deliberate checkpoints where the developer verifies the generated artifacts, identifies gaps, and corrects the agent's course before proceeding.3
The most profound consequence of adopting SDD is the fundamental shift in the source of truth. In traditional development, the code itself is the ultimate source of truth, and documentation often lags behind, becoming outdated and unreliable. In SDD, this is inverted: the specification becomes the definitive source of truth that determines what gets built.3 This is only possible because modern LLM agents make specifications executable, transforming them from static documents into dynamic blueprints that directly drive the creation and validation of code.3


Behavior-Driven Development (BDD): The Universal Language of Intent


Behavior-Driven Development provides the ideal methodology for authoring the high-level, human-readable specifications that are the cornerstone of the SDD Specify phase. BDD is a collaborative approach that centers on defining system behavior from the user's perspective, ensuring that development efforts are always aligned with business value.7 It is a refinement of TDD that shifts the focus from testing units of code to verifying system behavior.10
At the heart of BDD is the concept of a "ubiquitous language"—a shared, semi-formal language that can be understood by all project stakeholders, from business analysts to developers and QA engineers.10 This common language, typically expressed through a Domain-Specific Language (DSL) like Gherkin, is designed to close the communication gap between business interests and technical implementation, which is a primary source of risk and failure in software projects.10 By describing behavior in structured, natural-language constructs (e.g., English-like sentences), BDD ensures that everyone has a shared understanding of what the system should do.10
The primary artifacts of BDD are behavioral specifications, often captured in .feature files using Gherkin's Given-When-Then syntax.7 These are not static documents; they are "living documentation".8 Because these specifications are written in a structured format, they can be automated with tools like Cucumber or SpecFlow, which parse the Gherkin scenarios and execute corresponding test code.7 This creates a powerful feedback loop where the documentation is continuously checked against the actual behavior of the system, guaranteeing that it never becomes outdated.13 This principle of a continuously validated specification aligns perfectly with the SDD philosophy of the spec as the single, reliable source of truth.4


Synthesis: The SDD/BDD Hybrid Model for AI Collaboration


The true power of these methodologies in the context of AI-driven development is realized when they are combined into a unified framework. BDD serves as the ideal "front-end" for the SDD "back-end." The collaborative, human-centric process of BDD generates the precise, intent-driven artifacts required to kickstart the AI-centric, implementation-focused process of SDD.
The workflow integration is seamless and logical:
1. The BDD process begins with "Discovery" workshops, where the "Three Amigos"—representatives from business, development, and QA—collaborate to define requirements.8 Through structured conversations focused on concrete examples, they formulate user stories and write behavioral scenarios in Gherkin.13
2. The Gherkin .feature files produced in these workshops become the primary input for the SDD /specify command.3 These files perfectly capture the "user journeys, experiences, and success criteria" that the SDD process requires at its outset, providing the LLM agent with a clear and unambiguous definition of the desired behavior.1
3. The Given-When-Then scenarios within the Gherkin files serve a dual purpose. They not only define the functional requirements but also act as the concrete examples and acceptance criteria that the LLM agent will use to generate its own tests and validate its work during the Implement phase.16
This hybrid model establishes a powerful, closed-loop system. A human-readable BDD specification drives the SDD process. The LLM agent generates code and tests based on this specification. Automated test frameworks then execute tests that directly validate the original Gherkin scenarios. A test failure is no longer just a "bug"; it is a "spec violation." The Gherkin file becomes the immutable, auditable contract against which the AI's work is judged, fulfilling the promise of "living documentation" in a way that was previously unattainable.
Furthermore, the collaborative nature of BDD provides the ideal forum for establishing the foundational rules of the project. The SDD process relies on a constitution.md file to define project principles, technology stack choices, coding standards, and non-functional requirements.1 This document is the "law of the land" for the LLM agent. The BDD discovery workshop is not just about defining features; it is about defining the rules of the project. The output of these early, cross-functional conversations should be the constitution.md file. This elevates the constitution from a simple configuration file to a social contract agreed upon by all stakeholders. The LLM agent then becomes the first entity to be "onboarded" via this contract, and its ability to adhere to the constitution serves as the first and most critical test of the entire AI-driven development process.


Methodology
	Primary Goal
	Key Artifacts
	Role in LLM-Driven Dev
	Test-Driven Development (TDD)
	Ensures code correctness and design quality from a developer's perspective by writing unit tests before code.7
	Unit test files.
	A sub-process within the SDD Implement phase. The LLM agent should be instructed (via the constitution.md) to follow a TDD-like cycle for generating isolated, testable code blocks.1
	Acceptance TDD (ATDD)
	Aligns development with user requirements by driving the process with acceptance tests.7
	Acceptance test specifications.
	A precursor concept to BDD. BDD enhances ATDD by adding a stronger focus on a shared, ubiquitous language and collaborative discovery.18
	Behavior-Driven Dev (BDD)
	Creates a shared understanding of system behavior among all stakeholders using a common, non-technical language.7
	Gherkin .feature files containing user stories and Given-When-Then scenarios.
	The "front-end" of the framework. BDD provides the human-readable, executable specifications that serve as the primary input for the SDD Specify phase, defining the intent for the LLM agent.10
	Spec-Driven Development (SDD)
	Uses a formal specification as an executable blueprint to guide an AI agent in generating, testing, and validating code.1
	constitution.md, technical plans, task breakdowns, generated code.
	The "back-end" of the framework. SDD provides the structured, multi-phase process that translates the BDD-defined intent into production-ready code, ensuring quality and adherence to constraints.3
	

II. The Minimum Foundational Document Set


To provide an LLM agent with a solid, wide, and stable starting point, a minimum set of four foundational documents is required. These documents are not a flat list but rather a layered hierarchy of abstraction, moving from high-level project-wide rules to concrete technical contracts. This structure allows an LLM agent to process the project context logically, progressively constraining its solution space to ensure the generated code is correct, consistent, and aligned with all requirements.


Document Name
	Purpose
	Typical Format
	Role in SDD Lifecycle
	constitution.md (Project Constitution)
	Establishes the project's governing principles, technical constraints, and non-functional requirements. It is the "law of the land" for the LLM agent.
	Markdown (.md)
	A persistent, global input referenced across all phases (Specify, Plan, Tasks, Implement). It provides the foundational guardrails for every decision the agent makes.1
	.feature (Feature Specification)
	Defines functional requirements from a user's perspective using a human-readable, executable format. Articulates the "what" and "why."
	Gherkin syntax in a .feature file
	The primary input for the Specify phase. It provides the high-level description of desired behavior. Its scenarios also serve as acceptance criteria for the Implement phase.3
	openapi.yaml (API Contract)
	Provides a formal, machine-readable contract for how services and system components interact via APIs.
	OpenAPI Specification (YAML)
	A key input for the Plan phase, defining the technical boundaries for API implementation. It is used during the Implement phase to generate both API provider and consumer code.19
	schema.sql or schema.json (Data Schema)
	Provides the unambiguous structure of the data entities the application will manage, including fields, types, and relationships.
	SQL Data Definition Language (DDL) or JSON Schema
	A critical input for the Plan and Implement phases. It defines the data landscape, preventing the LLM from hallucinating database tables, columns, or document structures.21
	

The Project Constitution (constitution.md): Defining the Rules of Engagement


The Project Constitution is the most abstract and foundational layer of the documentation set. It serves as a persistent set of governing principles and constraints that the LLM agent must consult and adhere to throughout the entire development process.1 This document codifies the project's technical and quality standards, ensuring consistency and preventing the agent from making arbitrary or suboptimal decisions. It is the first document the agent should be "trained" on for a new project.
* Format: Markdown (.md) is the ideal format due to its human readability, ease of editing, and compatibility with version control systems like Git.
* Key Contents:
   * Technology Stack: This section must explicitly list all approved languages, frameworks, major libraries, and their versions. This removes ambiguity and directs the agent to use the standardized stack.
      * Example:

Technology Stack

   * Programming Language: Python 3.11
   * Backend Framework: FastAPI 0.104
   * Database: PostgreSQL 15
   * ORM: SQLAlchemy 2.0 with Alembic for migrations
   * Frontend Framework: React 18 with TypeScript
   * UI Component Library: Material-UI 5
   * Architectural Patterns: Define the high-level architectural style and key design patterns the agent must follow. This guides the agent in structuring the application code correctly and consistently.
   * Example:

Architectural Patterns

      * Overall Architecture: A microservices architecture where services communicate via RESTful APIs.
      * Data Access Layer: All database interactions must be abstracted through the Repository Pattern. Do not write raw SQL queries in business logic services.
      * Dependency Management: Use dependency injection for all services and repositories.
      * Coding Standards: Specify formatting rules, naming conventions, and documentation requirements. This ensures the AI-generated code is clean, readable, and maintainable.
      * Example:

Coding Standards

         * Formatting: All Python code must be formatted using the black code formatter.
         * Linting: All code must pass flake8 linting with zero errors.
         * Naming Conventions: Use snake_case for variables and functions, and PascalCase for classes.
         * Documentation: All public functions and classes must have Google-style docstrings.
         * Testing Methodology: State the required testing approach, frameworks, and quality gates. This instructs the agent to generate tests as an integral part of the implementation process.
         * Example:

Testing Methodology

            * Approach: A Test-Driven Development (TDD) approach is required for all new business logic.
            * Frameworks: Use pytest for unit and integration tests. Use Mockito for mocking dependencies.
            * Coverage: Unit test coverage for new code must exceed 80%, enforced by the CI pipeline.
            * Non-Functional Requirements (NFRs): This critical section defines the quality attributes of the system. It must translate abstract goals into concrete, measurable constraints for the agent. (This is explored in detail in Section 3.2).


The Feature Specification (.feature): Articulating Behavior as Executable Requirements


The Feature Specification defines the application's functional requirements from the end-user's perspective. It is the primary input for the SDD Specify phase and serves as the project's living documentation, bridging the gap between business stakeholders and the development process.8
            * Format: Gherkin syntax, stored in a .feature file. This plain-text format is designed to be easily understood by non-technical team members while being structured enough for automation tools and LLM agents to parse.14
            * Key Contents:
            * Feature Declaration: Each file begins with the Feature: keyword, followed by a short, descriptive name for the functionality.
            * User Story: Directly below the Feature line, a user story in the "As a..., I want..., So that..." format provides essential context, defining the user persona (Who), the goal (What), and the business value (Why).24 This context is invaluable for the LLM agent to understand the purpose behind the feature.
            * Scenarios: Each feature is broken down into one or more scenarios, each starting with the Scenario: keyword. A scenario describes a single, concrete example of the feature's behavior.14
            * Given-When-Then Steps: Scenarios are structured using Gherkin's keywords:
            * Given: Describes the initial context or preconditions of the system.27
            * When: Describes the action or event performed by the user.27
            * Then: Describes the expected, testable outcome.27
            * And/But: Used to add additional steps to any of the Given, When, or Then clauses to improve readability.14
            * Example (authentication.feature):
Gherkin
Feature: User Authentication
 As a registered user
 I want to log in to my account
 So that I can access my personalized dashboard

Scenario: Successful login with valid credentials
 Given I am on the login page
 And I have a registered account with email "user@example.com" and password "ValidPass123!"
 When I enter "user@example.com" in the email field and "ValidPass123!" in the password field
 And I click the "Log In" button
 Then I should be redirected to the dashboard page
 And I should see a welcome message containing "user@example.com"

Scenario: Failed login with invalid password
 Given I am on the login page
 And I have a registered account with email "user@example.com"
 When I enter "user@example.com" in the email field and "InvalidPassword" in the password field
 And I click the "Log In" button
 Then I should remain on the login page
 And I should see an error message "Invalid email or password"



The API Contract (openapi.yaml): Describing System Boundaries


For any application that exposes or consumes an API, particularly in a microservices or service-oriented architecture, the API Contract is an essential document. It provides a formal, language-agnostic, and machine-readable description of the API's surface, removing all ambiguity for the LLM agent when it needs to generate code for either an API provider or a client.19
               * Format: The OpenAPI Specification (OAS), preferably version 3.0 or higher, written in YAML for its superior readability compared to JSON.19
               * Key Contents:
               * Metadata (info): Contains the API's title, version, and a description of its purpose.20
               * Servers (servers): An array of base URLs for the API, allowing for definitions of different environments like development, staging, and production.20
               * Paths (paths): The core of the specification. This object defines all the available API endpoints (e.g., /users/{id}) and the HTTP methods (get, post, put, delete) supported by each endpoint.20
               * Parameters (parameters): Defines parameters that can be passed to an operation, including path parameters ({id}), query parameters, headers, and cookies, specifying their name, location, data type, and whether they are required.20
               * Request Bodies (requestBody): Describes the payload of an operation that accepts data, such as a POST or PUT request. It specifies the media types (e.g., application/json) and the schema of the payload.30
               * Responses (responses): Defines the possible responses for each operation, mapped by HTTP status code (e.g., 200, 404, 500). Each response definition includes a description and, if applicable, a schema for the response body.20
               * Reusable Components (components): A critical section for promoting a DRY (Don't Repeat Yourself) specification. It allows for the definition of reusable elements such as data schemas (schemas), parameters (parameters), and responses (responses) that can be referenced from multiple places within the API definition using $ref.20 This is highly effective for LLM consumption as it provides a single source of truth for common data models.


The Data Schema (schema.sql or schema.json): Defining the Data Landscape


The Data Schema provides the unambiguous structure of the data entities the application will persist and manage. Without a formal data schema, an LLM agent is highly likely to hallucinate table names, column names, data types, and relationships, leading to functionally incorrect code and significant rework.33 Providing the schema in a format native to the target system is the most effective way to ensure precision.
               * Format:
               * For Relational Databases (e.g., PostgreSQL, MySQL): SQL Data Definition Language (DDL) in a .sql file is the most precise and effective format. CREATE TABLE statements explicitly define table and column names, data types (e.g., VARCHAR(255), INT), constraints (PRIMARY KEY, FOREIGN KEY, NOT NULL), and indexes. This format leaves no room for misinterpretation by the agent.21
               * For NoSQL Databases (e.g., MongoDB) or JSON-based data structures: JSON Schema in a .json file is the industry standard. It allows for the definition of object properties, data types, required fields, and complex validation rules (e.g., patterns, min/max values).22
               * Best Practices for LLM Consumption:
               * Include Descriptive Comments: This is a crucial step that is often overlooked. The context provided by comments is invaluable for an LLM agent. For SQL DDL, use comments to explain the purpose of columns, especially foreign keys and columns with non-obvious names. This helps the agent understand the semantic meaning of the data and generate more intelligent queries and business logic.21
               * Example (schema.sql):
SQL
CREATE TABLE "Orders" (
   "OrderID" SERIAL PRIMARY KEY,
   "UserID" INT NOT NULL, -- Foreign key to the Users table
   "OrderDate" TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
   "Status" VARCHAR(50) NOT NULL, -- e.g., 'Pending', 'Shipped', 'Delivered'
   FOREIGN KEY ("UserID") REFERENCES "Users" ("UserID")
);
/*
Table: Orders
Purpose: Stores order information placed by users.
*/

                  * Specify Relationships Explicitly: While FOREIGN KEY constraints in SQL DDL are explicit, for JSON Schema or other formats, use the description fields to clearly state relationships between different data entities.
This hierarchical documentation set—from the global rules in the constitution, to the user behaviors in the feature file, down to the technical contracts in the API and data schemas—provides a comprehensive and logically structured context for an LLM agent. This top-down approach dramatically reduces the agent's solution space, minimizing the risk of hallucination and logical errors, and making the entire code generation process more reliable, predictable, and aligned with project intent.


III. The "Everything-as-Code" Repository: A Unified Knowledge Base


The principle of storing all project documentation within the repository transforms it from a simple code store into a comprehensive, version-controlled knowledge base. This "everything-as-code" approach is what's needed to provide an LLM agent with the rich context required to perform optimally.49


Benefits and Challenges of a Unified Repository


                  * Benefits:
                  * Maximum Context for LLMs: Exposing the LLM to the full project history—including requirements, architectural decisions, and their evolution—provides the necessary context to reduce ambiguity and "hallucinations".35 The agent doesn't have to guess at intent; it can retrieve it.
                  * Living Documentation: When specifications and requirements live alongside the code, they are more likely to be updated together, creating a "living documentation" system where the description of the system is always in sync with its implementation.3
                  * End-to-End Traceability: This model makes it possible to trace a requirement from its initial conception in a .feature file, through architectural decisions in ADRs, to the code itself, and finally to the tests that validate it.36
                  * Challenges:
                  * Repository Bloat: Storing large, non-text files can slow down Git performance. The solution is to use Git Large File Storage (LFS) for versioning large files or store them externally and link to them from within the repository.
                  * Information Overload: A well-defined directory structure is crucial to organize information logically, making it easier for both humans and AI to find relevant context.37


Expanding the Document Set for Complete Context


To build a complete knowledge base, the foundational documents should be supplemented with artifacts that capture the full lifecycle of requirements and decisions.
                  * Architectural Decision Records (ADRs): These documents are critical for explaining the why behind technical choices. An ADR captures a single architectural decision, its context, and its consequences in a lightweight Markdown file. The collection of ADRs forms a decision log that provides historical context, which is invaluable for an LLM agent when refactoring or extending the codebase.
                  * Diagrams as Code: Visual architecture diagrams provide high-level context that is difficult to glean from code alone. Storing them as code (using text-based languages like Mermaid or PlantUML) makes them versionable, easy to update, and consumable by LLMs.
                  * Requirements Traceability Matrix (RTM): The RTM is the linchpin that connects all other documents, creating an unbroken chain from business need to verified implementation.36 It maps each requirement to other project artifacts, including design documents, ADRs, source code, and test cases. AI agents can provide immense value by automatically updating the RTM, providing real-time, bidirectional traceability.


Recommended Repository Structure


A logical folder structure is key to making the repository's knowledge accessible.






/
├──.github/              # CI/CD workflows, PR templates
├── AGENTS.md             # High-level instructions for AI agents
├── constitution.md       # Project-wide rules and principles
├── docs/
│   ├── adr/              # Architectural Decision Records
│   │   ├── 001-use-postgresql-database.md
│   │   └── 002-adopt-rest-for-internal-apis.md
│   ├── architecture/     # Diagrams-as-code (C4, sequence, etc.)
│   │   ├── C1-system-context.md
│   │   └── C2-container-diagram.md
│   ├── requirements/
│   │   ├── features/     # BDD feature files
│   │   │   └── authentication.feature
│   │   └── rtm.md        # Requirements Traceability Matrix
│   └── data/
│       ├── schema.sql
│       └── openapi.yaml
└── src/                  # Application source code

The AGENTS.md file serves as a dedicated entry point for AI agents, containing instructions on build steps, testing conventions, and other details that might clutter a human-focused README.md.


Activating the Knowledge Base with Retrieval-Augmented Generation (RAG)


Storing documents is only useful if the LLM can access and reason over them effectively. This is achieved through Retrieval-Augmented Generation (RAG), a technique that connects the LLM to your repository as an external knowledge base.35
The RAG workflow involves:
                  1. Indexing: Your repository's content is processed and stored in a vector database, creating a searchable knowledge library.35
                  2. Retrieval: When the LLM agent receives a task, the system first searches the vector database for the most relevant documents.50
                  3. Augmentation: The content of these retrieved documents is automatically injected into the prompt sent to the LLM, providing rich, specific context.35
                  4. Generation: The LLM generates code, tests, or documentation based on this augmented prompt, resulting in a more accurate and context-aligned output.50
This "Index-Retrieve-Augment" cycle turns your repository into an active, intelligent partner in the development process, ensuring that every piece of documentation contributes directly to the quality and consistency of the final product.50


IV. Advanced Implementation and Best Practices


Defining the foundational documents is the first step. The second, equally critical step is authoring their content in a way that maximizes clarity and effectiveness for an LLM agent. This requires adopting specific writing styles and formats that translate human intent into unambiguous, machine-actionable instructions.


Authoring High-Clarity Gherkin for an LLM Audience


When writing Gherkin scenarios for an LLM, the primary goal is to communicate intent, not implementation details. This principle is best captured by adopting a declarative style over an imperative one.
                  * Declarative vs. Imperative Style:
                  * An imperative style describes the mechanics of an interaction—the specific clicks, keystrokes, and UI elements involved. This style is brittle, as minor UI changes can break the specification, and it overly constrains the LLM, preventing it from leveraging its knowledge of best practices for the given tech stack.41
                  * Imperative Example (Less Effective):
Gherkin
When I enter "user@example.com" in the "user-email" input field
And I enter "ValidPass123!" in the "user-password" input field
And I press the "login-button" button

                     * A declarative style describes the user's goal or intent, abstracting away the implementation details. This approach is more robust, readable, and empowers the LLM agent to determine the best way to achieve the goal based on the rules defined in the constitution.md (e.g., which UI components to use) and the openapi.yaml (e.g., which API endpoint to call).41
                     * Declarative Example (More Effective):
Gherkin
When I attempt to log in with the credentials "user@example.com" and "ValidPass123!"

This shift from imperative to declarative is more than just a testing best practice; it is a form of high-level prompt engineering. The declarative step acts as a statement of business intent. The LLM agent receives this intent and must then consult the other foundational documents—the constitution.md for the UI framework, the openapi.yaml for the authentication endpoint—to generate the correct series of implementation steps (the code). This creates a powerful separation of concerns where the human author operates at the level of business logic, and the LLM agent operates at the level of technical execution.
                        * Additional Best Practices for Gherkin:
                        * Focus on One Behavior Per Scenario: Each scenario should be atomic and test a single business rule or outcome. This simplifies the logic for the LLM and makes both the generated code and the resulting tests easier to debug and maintain.8
                        * Use the Background Keyword: For Given steps that are repeated across every scenario in a feature file (e.g., Given I am logged in as an administrator), use the Background keyword. This reduces repetition, improves readability, and provides a clear, consistent starting context for the LLM for all subsequent scenarios in the file.9
                        * Leverage Scenario Outline for Data-Driven Tests: To test multiple variations of a behavior with different data inputs, use a Scenario Outline with an Examples table. This is a highly structured and efficient way to communicate data variations to an LLM, allowing it to generate parameterized tests that cover numerous edge cases without redundant Gherkin code.27
                        * Example:
Gherkin
Scenario Outline: Password strength validation
 Given I am on the registration page
 When I enter the password "<password>"
 Then I should see the validation message "<message>"

 Examples:


| password | message |
| "weak" | "Password must be at least 8 characters" |
| "strongpass" | "Password must contain a number" |
| "StrongPass1" | "Password is valid" |
```


Specifying Non-Functional Requirements (NFRs) for Automated Enforcement


Non-functional requirements—such as performance, security, and scalability—are often expressed in abstract terms like "the system should be fast" or "the application must be secure." For an LLM agent, these vague statements are unactionable. NFRs must be translated into concrete, measurable, and testable constraints that can be codified within the constitution.md.45 This allows the agent to not only generate functional code but also to weave in the necessary optimizations, security measures, and architectural considerations to meet these quality attributes.47
The following table provides a template for translating common NFRs into a format suitable for an LLM agent.
NFR Category
	Vague Human-Centric Requirement
	Specific, LLM-Centric Constraint in constitution.md
	Example Implementation Directive for LLM
	Performance (Latency)
	"The user profile page should load quickly."
	"The API endpoint GET /api/v1/users/{id} must have a server response time of less than 200ms for the 95th percentile (P95) of requests under normal load."
	"When generating the code for the get_user_by_id endpoint and its corresponding repository method, you must implement a caching layer (e.g., Redis) for user profile data with a TTL of 5 minutes. Optimize the database query to use the primary key index and select only the required fields."
	Performance (Throughput)
	"The system should handle many users."
	"The order processing service must sustain a throughput of at least 500 transactions per second (TPS)."
	"Design the order processing logic to be asynchronous. Use a message queue (e.g., RabbitMQ) to decouple order submission from processing. The processing worker should be stateless to allow for horizontal scaling."
	Security (Authentication)
	"The API needs to be secure."
	"All API endpoints, except for /login and /register, must be protected using OAuth 2.0 Bearer Token authentication. The token must be validated on every request."
	"Generate middleware for the FastAPI application that intercepts all incoming requests. The middleware will extract the Bearer token from the Authorization header, validate its signature and expiration using the PyJWT library, and return a 401 Unauthorized error if the token is invalid or missing."
	Security (Data)
	"We need to prevent SQL injection."
	"All database queries that include user-provided input must use parameterized queries or an ORM that provides SQL injection protection. Raw SQL string formatting is strictly forbidden."
	"When implementing repository methods using SQLAlchemy, use the ORM's query methods (e.g., session.query(User).filter_by(id=user_id)) to construct all database queries. Do not use raw string execution methods like text() with un-sanitized user input."
	Scalability (Concurrency)
	"The app shouldn't crash on Black Friday."
	"The application must be able to handle 5,000 concurrent user sessions while maintaining all defined performance NFRs."
	"The application must be containerized using Docker and designed to run in a Kubernetes cluster. Ensure that all services are stateless so that they can be scaled horizontally by increasing the number of pods. Use a distributed database connection pool to manage connections efficiently under high load."
	

The Iterative Documentation Lifecycle


The foundational document set is not a static, one-time creation. It is the starting point for an iterative and evolving process. The artifacts generated by the LLM agent during the SDD Plan and Tasks phases—such as the detailed technical plan and the breakdown of work—provide valuable feedback that can and should be used to refine the initial specifications.
When a new feature is required, the cycle begins anew. A BDD discovery workshop is convened to produce a new .feature file. If this new feature introduces a new technology (e.g., a message queue), a new architectural pattern, or a new NFR, the constitution.md must be updated accordingly. This disciplined process ensures that the documentation remains a "living" and consistently accurate reflection of the system's intent, preventing the drift between specification and implementation that plagues traditional development projects.3 The specifications evolve with the codebase, guided by a continuous feedback loop between human intent and AI execution.


V. Conclusion and Strategic Recommendations


The integration of LLM agents into the software development process necessitates a fundamental shift from code-first to intent-first methodologies. A hybrid framework combining the collaborative, human-centric specification process of Behavior-Driven Development with the structured, AI-centric implementation process of Spec-Driven Development provides the necessary foundation for success. This approach relies on a minimum set of four foundational documents—the Project Constitution (constitution.md), the Feature Specification (.feature file), the API Contract (openapi.yaml), and the Data Schema (schema.sql or .json)—that form a cohesive, multi-layered system for guiding AI agents with clarity and precision.
This framework redefines the role of the human developer. The emphasis moves away from the mechanical act of writing boilerplate code and towards the higher-value activities of architectural design, clear communication, and strategic oversight. In this new paradigm, the most valuable engineering skills are the ability to articulate complex business logic in an unambiguous specification, to define robust technical and quality constraints, and to critically verify the output of an AI collaborator. The developer becomes an architect of intent, a partner to the AI, and the ultimate arbiter of quality.
For organizations seeking to adopt this powerful new way of working, the following strategic recommendations will facilitate a smooth and effective transition:
                           * Start with a Pilot Project: Rather than attempting a wholesale transformation, pilot this approach on a new, well-defined greenfield project or a single, isolated feature within an existing system. This allows the team to learn the workflow, refine the documentation templates, and demonstrate tangible value and efficiency gains before a broader rollout.4
                           * Invest in Methodological Training: Success with this framework depends more on a cultural shift than on the specific tools used. Invest in training the entire team—including product managers, developers, and QA engineers—on the core principles of BDD and SDD. A shared understanding of collaborative specification and intent-driven development is essential for the framework to function effectively.16
                           * Embrace the Human-in-the-Loop Model: It is critical to understand that the LLM agent is a powerful tool for augmentation, not a replacement for human expertise. The verify step at the end of each SDD phase is the most important part of the process.1 The developer's judgment, domain knowledge, and ability to identify subtle logical flaws or overlooked edge cases are irreplaceable. The human provides the critical oversight that ensures the final product is not just functional but robust, secure, and well-architected.
                           * Elevate Documentation to a First-Class Citizen: In this paradigm, the specification documents are no longer an afterthought or a chore to be completed after coding. They are the genesis of the product itself. They must be placed under version control, subjected to rigorous review, and maintained with the same discipline as the source code. When intent becomes the source of truth, the documents that capture that intent are the most valuable assets in the project.
Works cited
                           1. Spec Driven Development (SDD): The Evolution Beyond Vibe Coding | by Daniel Sogl, accessed October 6, 2025, https://danielsogl.medium.com/spec-driven-development-sdd-the-evolution-beyond-vibe-coding-1e431ae7d47b
                           2. Spec Driven Development (SDD) - A initial review - DEV Community, accessed October 6, 2025, https://dev.to/danielsogl/spec-driven-development-sdd-a-initial-review-2llp
                           3. Spec-driven development with AI: Get started with a new open source toolkit, accessed October 6, 2025, https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/
                           4. Complete Specification-Driven Development Guide | Specify Documentation, accessed October 6, 2025, https://specify.app/docs/specification-driven-development-guide
                           5. github/spec-kit: Toolkit to help you get started with Spec-Driven Development, accessed October 6, 2025, https://github.com/github/spec-kit
                           6. Spec-Driven Development in 2025: The Complete Guide to Using AI to Write Production Code - SoftwareSeni, accessed October 6, 2025, https://www.softwareseni.com/spec-driven-development-in-2025-the-complete-guide-to-using-ai-to-write-production-code/
                           7. TDD vs BDD vs ATDD : Key Differences - BrowserStack, accessed October 6, 2025, https://www.browserstack.com/guide/tdd-vs-bdd-vs-atdd
                           8. What Is Behavior-Driven Development (BDD)? - Built In, accessed October 6, 2025, https://builtin.com/articles/behaviour-driven-development-bdd
                           9. What is BDD? (Behavior-Driven Development) - BrowserStack, accessed October 6, 2025, https://www.browserstack.com/guide/what-is-bdd
                           10. Behavior-driven development - Wikipedia, accessed October 6, 2025, https://en.wikipedia.org/wiki/Behavior-driven_development
                           11. What is TDD and BDD? Which is better? : r/computerscience - Reddit, accessed October 6, 2025, https://www.reddit.com/r/computerscience/comments/1kh0548/what_is_tdd_and_bdd_which_is_better/
                           12. What is Behavior-Driven Development (BDD): A Complete Guide - LambdaTest, accessed October 6, 2025, https://www.lambdatest.com/learning-hub/behavior-driven-development
                           13. Behaviour-Driven Development - Cucumber, accessed October 6, 2025, https://cucumber.io/docs/bdd/
                           14. Gherkin Syntax: Format, Language & Gherkin Test in Cucumber - ACCELQ, accessed October 6, 2025, https://www.accelq.com/blog/gherkin-syntax/
                           15. What's Gherkin? How Do You Write Gherkin Tests? | TestQuaiity - TestQuality, accessed October 6, 2025, https://testquality.com/what-is-gherkin-how-do-you-write-gherkin-tests/
                           16. Behavior-driven Development (BDD) Testing: A Complete Tester's Guide - ACCELQ, accessed October 6, 2025, https://www.accelq.com/blog/bdd-behavior-driven-development/
                           17. Specification by Example versus Behaviour Driven Development | It's a Delivery Thing, accessed October 6, 2025, https://itsadeliverything.com/specification-by-example-versus-behaviour-driven-development
                           18. What is the difference between Behaviour Driven Development (BDD) and Acceptance Test Driven Development (ATDD)? - Stack Overflow, accessed October 6, 2025, https://stackoverflow.com/questions/11986187/what-is-the-difference-between-behaviour-driven-development-bdd-and-acceptance
                           19. OpenAPI Specification - Version 3.1.0 | Swagger, accessed October 6, 2025, https://swagger.io/specification/
                           20. OpenAPI 3.0 Tutorial | SwaggerHub Documentation, accessed October 6, 2025, https://support.smartbear.com/swaggerhub/docs/en/get-started/openapi-3-0-tutorial.html
                           21. Best practices for database schema in DDL and SQL query ..., accessed October 6, 2025, https://help.claris.com/en/pro-help/content/schema-best-practices-for-sql-generation.html
                           22. Schemas - LLM, accessed October 6, 2025, https://llm.datasette.io/en/stable/schemas.html
                           23. Cucumber (software) - Wikipedia, accessed October 6, 2025, https://en.wikipedia.org/wiki/Cucumber_(software)
                           24. How to Write Better User Stories With Gherkins (Templates Included!) - Userpilot, accessed October 6, 2025, https://userpilot.com/blog/user-stories-templates/
                           25. User story - Cucumber, accessed October 6, 2025, https://cucumber.io/docs/terms/user-story/
                           26. Mastering User Story Format in Gherkin: A Developer's Guide to Effective Communication, accessed October 6, 2025, https://ones.com/blog/mastering-user-story-format-gherkin-developers-guide/
                           27. Writing scenarios with Gherkin syntax - GeeksforGeeks, accessed October 6, 2025, https://www.geeksforgeeks.org/software-testing/writing-scenarios-with-gherkin-syntax/
                           28. en.wikipedia.org, accessed October 6, 2025, https://en.wikipedia.org/wiki/OpenAPI_Specification
                           29. OAI/OpenAPI-Specification - GitHub, accessed October 6, 2025, https://github.com/OAI/OpenAPI-Specification
                           30. RESTful APIs: Tutorial of OpenAPI Specification | by Amir Lavasani | Medium, accessed October 6, 2025, https://medium.com/@amirm.lavasani/restful-apis-tutorial-of-openapi-specification-eeada0e3901d
                           31. OpenAPI 3.0 Specification Best Practices - Light-4j, accessed October 6, 2025, https://doc.networknt.com/development/best-practices/openapi3/
                           32. What is Open API? Advantages, Disadvantages & Examples - Document360, accessed October 6, 2025, https://document360.com/blog/open-api/
                           33. Bridging Natural Language and Databases: Best Practices for LLM-Generated SQL, accessed October 6, 2025, https://medium.com/@vi.ha.engr/bridging-natural-language-and-databases-best-practices-for-llm-generated-sql-fcba0449d4e5
                           34. html - arXiv, accessed October 6, 2025, https://arxiv.org/html/2507.21056v1
                           35. What is RAG? - Retrieval-Augmented Generation AI Explained - AWS - Updated 2025, accessed October 6, 2025, https://aws.amazon.com/what-is/retrieval-augmented-generation/
                           36. The Ultimate Guide to (RTM) Requirements Traceability Matrix - Testomat.io, accessed October 6, 2025, https://testomat.io/blog/the-ultimate-guide-to-rtm-requirements-traceability-matrix/
                           37. Repository documentation guidelines - Bitcraze, accessed October 6, 2025, https://www.bitcraze.io/development/contribute/repo-doc-guidelines/
                           38. Documentation done right: A developer's guide - The GitHub Blog, accessed October 6, 2025, https://github.blog/developer-skills/documentation-done-right-a-developers-guide/
                           39. The Ultimate Guide to Requirements Traceability Matrix (RTM) - Ketryx, accessed October 6, 2025, https://www.ketryx.com/blog/the-ultimate-guide-to-requirements-traceability-matrix-rtm
                           40. What's a requirements traceability matrix? Explained - Notion, accessed October 6, 2025, https://www.notion.com/blog/requirements-traceability-matrix
                           41. Writing better Gherkin - Cucumber, accessed October 6, 2025, https://cucumber.io/docs/bdd/better-gherkin/
                           42. This is a guideline of best practices about Gherkin and BDD that you can apply to your projects. - GitHub, accessed October 6, 2025, https://github.com/andredesousa/gherkin-best-practices
                           43. Reference - Cucumber, accessed October 6, 2025, https://cucumber.io/docs/gherkin/reference/
                           44. BDD 101: Writing Good Gherkin | Automation Panda, accessed October 6, 2025, https://automationpanda.com/2017/01/30/bdd-101-writing-good-gherkin/
                           45. Non-Functional Requirements: Tips, Tools, and Examples | Perforce ..., accessed October 6, 2025, https://www.perforce.com/blog/alm/what-are-non-functional-requirements-examples
                           46. Non-Functional Requirements in Software Development: A Complete Guide, accessed October 6, 2025, https://dev.to/keploy/non-functional-requirements-in-software-development-a-complete-guide-1in5
                           47. AI Agents in Java: Automating Non-Functional Requirements for Secure, Scalable Apps | by Comviva MFS Engineering Tech Blog | Sep, 2025 | Medium, accessed October 6, 2025, https://medium.com/@dfs.techblog/ai-agents-in-java-automating-non-functional-requirements-for-secure-scalable-apps-9ea77f9b9485
                           48. Studying Non-Functional-Requirement-Aware Code Generation Using Large Language Models - OpenReview, accessed October 6, 2025, https://openreview.net/pdf?id=RDuhx3Kehn
                           49. The Specification Revolution: How AI is Flipping Software Development Upside Down, accessed October 6, 2025, https://www.ikangai.com/the-specification-revolution-how-ai-is-flipping-software-development-upside-down/
                           50. Enhancing software development with retrieval-augmented generation - GitHub, accessed October 6, 2025, https://github.com/resources/articles/ai/software-development-with-retrieval-augmentation-generation-rag
                           51. Retrieval-augmented generation - Wikipedia, accessed October 6, 2025, https://en.wikipedia.org/wiki/Retrieval-augmented_generation