===================================================== test session starts ======================================================
platform linux -- Python 3.12.10, pytest-8.4.2, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /workspace/devsynth
configfile: pytest.ini
plugins: Faker-37.11.0, html-4.1.1, mock-3.15.1, asyncio-1.2.0, benchmark-5.1.0, anyio-4.11.0, metadata-3.1.1, bdd-8.1.0, rerunfailures-16.0.1, langsmith-0.4.33, hypothesis-6.140.3, cov-7.0.0, xdist-3.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 199 items

tests/unit/testing/test_run_tests_additional_coverage.py .......F                                                        [  4%]
tests/unit/testing/test_run_tests_additional_error_paths.py FFF                                                          [  5%]
tests/unit/testing/test_run_tests_artifacts.py .......F.F                                                                [ 10%]
tests/unit/testing/test_run_tests_benchmark_warning.py F                                                                 [ 11%]
tests/unit/testing/test_run_tests_cache_prune_and_tips.py .F                                                             [ 12%]
tests/unit/testing/test_run_tests_cache_pruning.py F                                                                     [ 12%]
tests/unit/testing/test_run_tests_cli_helpers_focus.py FFFFF.                                                            [ 15%]
tests/unit/testing/test_run_tests_cli_invocation.py FFFFFFF..FFFF                                                        [ 22%]
tests/unit/testing/test_run_tests_collection_cache.py .                                                                  [ 22%]
tests/unit/testing/test_run_tests_coverage_artifacts.py ......                                                           [ 25%]
tests/unit/testing/test_run_tests_coverage_artifacts_fragments.py .                                                      [ 26%]
tests/unit/testing/test_run_tests_coverage_short_circuit.py .                                                            [ 26%]
tests/unit/testing/test_run_tests_coverage_status.py ......                                                              [ 29%]
tests/unit/testing/test_run_tests_coverage_uplift.py ...                                                                 [ 31%]
tests/unit/testing/test_run_tests_extra.py FF                                                                            [ 32%]
tests/unit/testing/test_run_tests_extra_marker.py FF                                                                     [ 33%]
tests/unit/testing/test_run_tests_extra_marker_passthrough.py F                                                          [ 33%]
tests/unit/testing/test_run_tests_extra_paths.py FFF                                                                     [ 35%]
tests/unit/testing/test_run_tests_failure_tips.py F                                                                      [ 35%]
tests/unit/testing/test_run_tests_keyword_exec.py F                                                                      [ 36%]
tests/unit/testing/test_run_tests_keyword_filter.py FF                                                                   [ 37%]
tests/unit/testing/test_run_tests_keyword_filter_empty.py F                                                              [ 37%]
tests/unit/testing/test_run_tests_logic.py ..FFFFF                                                                       [ 41%]
tests/unit/testing/test_run_tests_main_function.py ...........                                                           [ 46%]
tests/unit/testing/test_run_tests_main_logic.py ....FF..FF.FFFFF.FF                                                      [ 56%]
tests/unit/testing/test_run_tests_marker_fallback.py .                                                                   [ 56%]
tests/unit/testing/test_run_tests_marker_merge.py ..                                                                     [ 57%]
tests/unit/testing/test_run_tests_module.py .FFFFF..F..                                                                  [ 63%]
tests/unit/testing/test_run_tests_no_xdist_assertions.py F                                                               [ 63%]
tests/unit/testing/test_run_tests_option_parsing.py ...                                                                  [ 65%]
tests/unit/testing/test_run_tests_orchestration.py .FFFF..                                                               [ 68%]
tests/unit/testing/test_run_tests_parallel_flags.py F                                                                    [ 69%]
tests/unit/testing/test_run_tests_parallel_no_cov.py F                                                                   [ 69%]
tests/unit/testing/test_run_tests_plugin_env.py ....                                                                     [ 71%]
tests/unit/testing/test_run_tests_plugin_timeouts.py F.                                                                  [ 72%]
tests/unit/testing/test_run_tests_pytest_cov_plugin.py ........                                                          [ 76%]
tests/unit/testing/test_run_tests_pytest_plugins_bdd.py ......F                                                          [ 80%]
tests/unit/testing/test_run_tests_report.py F                                                                            [ 80%]
tests/unit/testing/test_run_tests_returncode5_success.py F                                                               [ 81%]
tests/unit/testing/test_run_tests_sanitize_node_ids.py ...                                                               [ 82%]
tests/unit/testing/test_run_tests_segmentation.py F                                                                      [ 83%]
tests/unit/testing/test_run_tests_segmentation_helpers.py .....F......                                                   [ 89%]
tests/unit/testing/test_run_tests_segmented.py FF.                                                                       [ 90%]
tests/unit/testing/test_run_tests_segmented_aggregate_fail_tips_once.py F                                                [ 91%]
tests/unit/testing/test_run_tests_segmented_aggregate_maxfail.py F                                                       [ 91%]
tests/unit/testing/test_run_tests_segmented_empty_node_ids.py F                                                          [ 92%]
tests/unit/testing/test_run_tests_segmented_failure_paths.py FF                                                          [ 93%]
tests/unit/testing/test_run_tests_segmented_failures.py ....                                                             [ 95%]
tests/unit/testing/test_run_tests_segmented_orchestration.py ...                                                         [ 96%]
tests/unit/testing/test_run_tests_segmented_report_flag.py .                                                             [ 97%]
tests/unit/testing/test_run_tests_speed_keyword_loop.py .                                                                [ 97%]
tests/unit/testing/test_run_tests_speed_selection.py ....                                                                [100%]

=========================================================== FAILURES ===========================================================
________________________________________ test_collect_tests_with_cache_handles_timeout _________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd49b560>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_0')

    def test_collect_tests_with_cache_handles_timeout(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """Timeouts during collection yield tips but no crash.
    
        ReqID: coverage-run-tests
        """
    
        monkeypatch.chdir(tmp_path)
        monkeypatch.setenv("DEVSYNTH_COLLECTION_CACHE_TTL_SECONDS", "1")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", "tests")
        (tmp_path / "tests").mkdir()
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            return SimpleNamespace(stdout="", stderr="", returncode=-1)
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
>       collected = rt.collect_tests_with_cache("unit-tests", speed_category="fast")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_additional_coverage.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_collect_tests_with_cache_handles_timeout.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
__________________________________ test_collect_tests_with_cache_handles_subprocess_exception __________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd49b5f0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_1')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dd694830>

    @pytest.mark.fast
    def test_collect_tests_with_cache_handles_subprocess_exception(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path, caplog: pytest.LogCaptureFixture
    ) -> None:
        """ReqID: RT-ERR-01 — Collection errors log tips and return empty list.
    
        Issue: issues/coverage-below-threshold.md
        """
    
        tests_dir = tmp_path / "tests_root"
        tests_dir.mkdir()
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
        caplog.set_level(logging.ERROR)
    
        def boom(*_args, **_kwargs):  # noqa: ANN002
            raise RuntimeError("collection failed")
    
        monkeypatch.setattr(rt.subprocess, "run", boom)
    
>       result = rt.collect_tests_with_cache("unit-tests", speed_category="fast")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_additional_error_paths.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_args = (['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_1/tests_root', '--collect-only', '-q', ...],)
_kwargs = {'capture_output': True, 'text': True, 'timeout': 300.0}

    def boom(*_args, **_kwargs):  # noqa: ANN002
>       raise RuntimeError("collection failed")
E       RuntimeError: collection failed

/workspace/devsynth/tests/unit/testing/test_run_tests_additional_error_paths.py:27: RuntimeError
______________________________________ test_run_tests_handles_unexpected_execution_error _______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8ee445430>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_handles_unexpec0')

    @pytest.mark.fast
    def test_run_tests_handles_unexpected_execution_error(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RT-ERR-02 — Unexpected execution errors surface troubleshooting tips.
    
        Issue: issues/coverage-below-threshold.md
        """
    
        tests_dir = tmp_path / "tests_exec"
        tests_dir.mkdir()
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
    
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
    
        def failing_popen(*_args, **_kwargs):  # noqa: ANN002
            raise RuntimeError("boom popen")
    
        monkeypatch.setattr(rt.subprocess, "Popen", failing_popen)
    
        success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=None,
        )
    
        assert success is False
        assert "boom popen" in output
>       assert "Troubleshooting tips" in output
E       AssertionError: assert 'Troubleshooting tips' in 'boom popen'

/workspace/devsynth/tests/unit/testing/test_run_tests_additional_error_paths.py:72: AssertionError
__________________________________________ test_run_tests_segment_merges_extra_marker __________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8ee445520>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segment_merges_0')

    @pytest.mark.fast
    def test_run_tests_segment_merges_extra_marker(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RT-ERR-03 — Segmented runs combine marker filters with extra expressions.
    
        Issue: issues/coverage-below-threshold.md
        """
    
        tests_dir = tmp_path / "tests_segment"
        tests_dir.mkdir()
        (tests_dir / "test_demo.py").write_text("def test_ok():\n    assert True\n")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
    
        node_ids = "test_demo.py::test_ok\n"
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            marker_index = len(cmd) - 1 - cmd[::-1].index("-m")
            expr = cmd[marker_index + 1]
            assert "fast" in expr and "not memory_intensive" in expr
            assert "not slow" in expr
            return SimpleNamespace(returncode=0, stdout=node_ids, stderr="")
    
        captured_batches: list[list[str]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                captured_batches.append(cmd)
                self.returncode = 0
    
            def communicate(self):
                return ("ok\n", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker="not slow",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_additional_error_paths.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_segment_merges_extra_marker.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
______________________________________ test_coverage_artifacts_status_detects_empty_html _______________________________________

coverage_paths = (PosixPath('/tmp/pytest-of-root/pytest-1/test_coverage_artifacts_status5/test_reports/coverage.json'), PosixPath('/tmp/pytest-of-root/pytest-1/test_coverage_artifacts_status5/htmlcov'))

    @pytest.mark.fast
    def test_coverage_artifacts_status_detects_empty_html(
        coverage_paths: tuple[Path, Path],
    ) -> None:
        """HTML reports that note missing data should trigger remediation."""
    
        coverage_json, html_dir = coverage_paths
        coverage_json.parent.mkdir(parents=True, exist_ok=True)
        coverage_json.write_text(json.dumps({"totals": {"percent_covered": 90.0}}))
        html_dir.mkdir(parents=True, exist_ok=True)
        (html_dir / "index.html").write_text("No coverage data available")
    
        ok, reason = run_tests_module.coverage_artifacts_status()
        assert ok is False
>       assert reason is not None and "No coverage data" in reason
E       AssertionError: assert ('Coverage HTML indicates no recorded data' is not None and 'No coverage data' in 'Coverage HTML indicates no recorded data')

/workspace/devsynth/tests/unit/testing/test_run_tests_artifacts.py:264: AssertionError
__________________________________________ test_failure_tips_includes_command_context __________________________________________

    @pytest.mark.fast
    def test_failure_tips_includes_command_context() -> None:
        """Failure tips prefix the command and retain segmentation guidance."""
    
        cmd = ["python", "-m", "pytest", "tests/unit"]
        tips = run_tests_module._failure_tips(2, cmd)
    
        assert tips.startswith(
            "\nPytest exited with code 2. Command: python -m pytest tests/unit"
        )
        assert "Troubleshooting tips:" in tips
        assert "Segment large suites" in tips
>       assert "Re-run failing segments" in tips
E       AssertionError: assert 'Re-run failing segments' in '\nPytest exited with code 2. Command: python -m pytest tests/unit\nTroubleshooting tips:\n- Smoke mode: reduce third-...HTML report for context (saved under test_reports/):\n  devsynth run-tests --target unit-tests --speed=fast --report\n'

/workspace/devsynth/tests/unit/testing/test_run_tests_artifacts.py:294: AssertionError
____________________________________ test_segmented_run_treats_benchmark_warning_as_success ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6da990>

    @pytest.mark.fast
    def test_segmented_run_treats_benchmark_warning_as_success(monkeypatch):
        """
        ReqID: FR-11.2
        When running in segmented mode, if a batch returns a nonzero exit code but
        stderr contains PytestBenchmarkWarning, the batch should be treated as
        successful. This test simulates that path deterministically.
        """
    
        # Simulate collection returning two node ids
        class DummyCompleted:
            def __init__(self, stdout: str = "", stderr: str = "") -> None:
                self.stdout = stdout
                self.stderr = stderr
                self.returncode = 0
    
        def fake_run(
            cmd: list[str], check: bool, capture_output: bool, text: bool
        ):  # type: ignore[override]
            # Return minimal collect-only output resembling pytest's -q --collect-only
            # Use python path style entries so _sanitize_node_ids accepts them
            out = "\n".join(
                [
                    "tests/unit/sample_test.py::test_one",
                    "tests/unit/sample_test.py::test_two",
                ]
            )
            return DummyCompleted(stdout=out, stderr="")
    
        monkeypatch.setattr("subprocess.run", fake_run)
    
        # Simulate pytest execution batches: nonzero returncode
        # but with a benchmark warning in stderr
        class DummyPopen:
            def __init__(
                self,
                cmd: list[str],
                stdout: Any,
                stderr: Any,
                text: bool,
                env: dict[str, str],
            ):  # noqa: D401
                # store for potential assertions/debug
                self.cmd = cmd
                # nonzero return code; handled as success due to warning in stderr
                self._returncode = 1
    
            def communicate(self):
                stdout = ""
                stderr = "PytestBenchmarkWarning: benchmark plugin present\n"
                return stdout, stderr
    
            @property
            def returncode(self) -> int:
                return self._returncode
    
        monkeypatch.setattr("subprocess.Popen", DummyPopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            segment=True,
            segment_size=1,  # force two batches
            parallel=False,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_benchmark_warning.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_run_treats_benchmark_warning_as_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________ test_collect_tests_with_cache_prunes_nonexistent_and_caches __________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_2')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6d99a0>

    @pytest.mark.fast
    def test_collect_tests_with_cache_prunes_nonexistent_and_caches(tmp_path, monkeypatch):
        # Direct cache into a temp directory
        import devsynth.testing.run_tests as rt
    
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", str(tmp_path / "cache"))
    
        # Simulate pytest --collect-only output with one non-existent and one existent file
        existing = "tests/unit/synthetic_test_file.py::test_ok"
        missing = "tests/unit/missing_test_file.py::test_missing"
    
        stdout = f"{missing}\n{existing}\n"
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            return SimpleNamespace(returncode=0, stdout=stdout, stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        # Make os.path.exists return True only for the existing path part
        real_exists = os.path.exists
    
        def fake_exists(path):  # noqa: ANN001
            if isinstance(path, str) and path.startswith(
                "tests/unit/synthetic_test_file.py"
            ):
                return True
            if isinstance(path, str) and path.startswith("tests/unit/missing_test_file.py"):
                return False
            return real_exists(path)
    
        monkeypatch.setattr(rt.os.path, "exists", fake_exists)
    
>       results = collect_tests_with_cache(target="unit-tests", speed_category=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_cache_prune_and_tips.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'unit-tests', speed_category = None

    def collect_tests_with_cache(
        target: str,
        speed_category: str | None = None,
        *,
        keyword_filter: str | None = None,
        _allow_all_target_decomposition: bool = True,
        _timeout_override: float | None = None,
        _propagate_timeout: bool = False,
    ) -> list[str]:
        """Collect tests for the given target and speed category.
    
        Args:
            target: Logical test target such as ``unit-tests`` or ``all-tests``.
            speed_category: Optional speed marker used to scope collection.
            keyword_filter: Optional ``-k`` expression applied during collection.
    
        Returns:
            A list of pytest node identifiers matching the requested filters.
        """
        test_path = TARGET_PATHS.get(target, TARGET_PATHS["all-tests"])
    
        # Build the marker expression we'll use and compute a simple fingerprint of
        # the test tree (latest mtime) to detect changes that should invalidate cache.
        marker_expr = "not memory_intensive"
        category_expr = marker_expr
        if speed_category:
            category_expr = f"{speed_category} and {marker_expr}"
    
        normalized_filter = _normalize_keyword_filter(keyword_filter)
        latest_mtime = _latest_mtime(test_path)
        base_cache_key = f"{target}_{speed_category or 'all'}"
        suffix = _cache_key_suffix(normalized_filter)
        cache_key = f"{base_cache_key}_{suffix}" if suffix else base_cache_key
        cache_file = (
>           COLLECTION_CACHE_DIR / f"{cache_key}_tests.json"
        )  # Use Path object for cache_file
E       TypeError: unsupported operand type(s) for /: 'str' and 'str'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1179: TypeError
_________________________________________ test_prunes_nonexistent_paths_and_uses_cache _________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_prunes_nonexistent_paths_0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6db0e0>

    @pytest.mark.fast
    def test_prunes_nonexistent_paths_and_uses_cache(tmp_path, monkeypatch):
        """ReqID: CACHE-PRUNE-1"""
        # Prepare a fake cache with a nonexistent test path and an existent one
        os.makedirs(COLLECTION_CACHE_DIR, exist_ok=True)
        cache_file = os.path.join(COLLECTION_CACHE_DIR, "unit-tests_all_tests.json")
        existent = "tests/unit/test_example.py::test_ok"
        nonexistent = "tests/unit/test_deleted.py::test_gone"
        # Ensure the existent path exists on filesystem for the pruning check
        exist_dir = Path("tests/unit")
        exist_dir.mkdir(parents=True, exist_ok=True)
        exist_file = exist_dir / "test_example.py"
        if not exist_file.exists():
            exist_file.write_text(
                "import pytest\n\n@pytest.mark.fast\ndef test_ok():\n    assert True\n"
            )
    
        cache_payload = {
            "timestamp": "2099-01-01T00:00:00",
            "tests": [existent, nonexistent],
            "fingerprint": {
                "latest_mtime": 0.0,
                "category_expr": "not memory_intensive",
                "test_path": "tests/",
                "node_set_hash": 123,
            },
        }
        with open(cache_file, "w") as f:
            json.dump(cache_payload, f)
    
        # Monkeypatch TTL to be huge so cache would be used if fingerprint matches
        monkeypatch.setenv("DEVSYNTH_COLLECTION_CACHE_TTL_SECONDS", "999999")
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            """Return the cached node ids without invoking pytest."""
    
            assert "--collect-only" in cmd, cmd
            return SimpleNamespace(
                returncode=0,
                stdout="\n".join([existent, nonexistent]),
                stderr="",
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        # Force fingerprint mismatch by changing latest_mtime via
        # monkeypatching os.path.getmtime
        original_getmtime = os.path.getmtime
    
        def fake_getmtime(path):
            return 1.0
    
        monkeypatch.setattr(os.path, "getmtime", fake_getmtime)
    
        # Now call collection; it should regenerate and prune the nonexistent path
>       out = collect_tests_with_cache(target="all-tests", speed_category=None)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_cache_pruning.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1255: in collect_tests_with_cache
    node_ids, dependency_timeouts = _collect_dependent_targets(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1122: in _collect_dependent_targets
    nodes = collect_tests_with_cache(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_prunes_nonexistent_paths_and_uses_cache.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_____________________________________ test_segmented_batches_inject_plugins_and_emit_tips ______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6dbad0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segmented_batches_inject_0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dea2f3e0>

    @pytest.mark.fast
    def test_segmented_batches_inject_plugins_and_emit_tips(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
        caplog: pytest.LogCaptureFixture,
    ) -> None:
        """ReqID: RUN-TESTS-SEGMENT-CLI-1 — Segmented runs inject plugins and tips."""
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
        monkeypatch.setenv("PYTEST_ADDOPTS", "")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_a = tmp_path / "test_alpha.py"
        test_b = tmp_path / "test_beta.py"
        test_a.write_text("def test_one():\n    assert True\n")
        test_b.write_text("def test_two():\n    assert True\n")
    
        collect_payload = "\n".join(
            [
                f"{test_a}::test_one",
                f"{test_b}::test_two",
            ]
        )
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(returncode=0, stdout=collect_payload, stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
    
        batch_plan = iter(
            [
                {
                    "returncode": 1,
                    "stdout": "",
                    "stderr": "FAIL Required test coverage of 90% not reached.",
                },
                {"returncode": 0, "stdout": "ok", "stderr": ""},
            ]
        )
    
        popen_envs: list[dict[str, str]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                popen_envs.append(dict(env or {}))
                try:
                    step = next(batch_plan)
                except StopIteration as exc:  # pragma: no cover - guards test integrity
                    raise AssertionError("Unexpected segmented batch invocation") from exc
                self.returncode = step["returncode"]
                self._stdout = step["stdout"]
                self._stderr = step["stderr"]
    
            def communicate(self):  # noqa: D401 - mimic subprocess API
                """Return the stubbed stdout/stderr pair."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
        caplog.set_level(logging.INFO, logger="devsynth.testing.run_tests")
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_helpers_focus.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_batches_inject_plugins_and_emit_tips.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     devsynth.testing.run_tests:logging_setup.py:600 Injected -p pytest_cov into PYTEST_ADDOPTS to preserve coverage instrumentation
INFO     devsynth.testing.run_tests:logging_setup.py:600 Injected -p pytest_bdd.plugin into PYTEST_ADDOPTS to preserve pytest-bdd hooks
INFO     devsynth.testing.run_tests:logging_setup.py:600 test collection cache miss for target=unit-tests (fast) — collecting via pytest
____________________________________ test_segmented_batch_exception_emits_tips_and_plugins _____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6db9e0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segmented_batch_exception0')

    @pytest.mark.fast
    def test_segmented_batch_exception_emits_tips_and_plugins(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
    ) -> None:
        """ReqID: RUN-TESTS-SEGMENT-CLI-2 — Exceptions surface tips and preserve plugins."""
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
        monkeypatch.setenv("PYTEST_ADDOPTS", "-q")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_segment.py"
        test_file.write_text("def test_fail():\n    assert True\n")
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            return SimpleNamespace(
                returncode=0, stdout=f"{test_file}::test_fail\n", stderr=""
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
    
        captured_envs: list[dict[str, str]] = []
    
        def exploding_batch(
            cmd, stdout=None, stderr=None, text=True, env=None
        ):  # noqa: ANN001
            captured_envs.append(dict(env or {}))
            raise RuntimeError("segmented batch crashed")
    
        monkeypatch.setattr(rt.subprocess, "Popen", exploding_batch)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=3,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_helpers_focus.py:162: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_batch_exception_emits_tips_and_plugins.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_______________________________________ test_segmented_batches_reinject_when_env_mutates _______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6db1d0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segmented_batches_reinjec0')

    @pytest.mark.fast
    def test_segmented_batches_reinject_when_env_mutates(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
    ) -> None:
        """Segments reapply plugin directives even if previous runs stripped them."""
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
        monkeypatch.setenv("PYTEST_ADDOPTS", "-q")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        first = tmp_path / "test_first.py"
        second = tmp_path / "test_second.py"
        first.write_text("def test_one():\n    assert True\n")
        second.write_text("def test_two():\n    assert True\n")
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(
                returncode=0,
                stdout="\n".join([f"{first}::test_one", f"{second}::test_two"]),
                stderr="",
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
    
        popen_envs: list[dict[str, str]] = []
    
        class MutatingPopen:
            call_index = 0
    
            def __init__(
                self,
                cmd,
                stdout=None,
                stderr=None,
                text=True,
                env=None,
            ):  # noqa: ANN001
                MutatingPopen.call_index += 1
                env_map = dict(env or {})
                popen_envs.append(env_map)
                _assert_plugins_in_env(env_map)
    
                if env is not None:
                    tokens = env.get("PYTEST_ADDOPTS", "").split()
                    filtered = [
                        token
                        for token in tokens
                        if token not in {"-p", "pytest_cov", "pytest_bdd.plugin"}
                    ]
                    env["PYTEST_ADDOPTS"] = " ".join(filtered)
    
                self.returncode = 0
                self._stdout = f"segment {MutatingPopen.call_index} ok"
                self._stderr = ""
    
            def communicate(self):  # noqa: D401 - subprocess API emulation
                """Return the stubbed stdout/stderr pair."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "Popen", MutatingPopen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_helpers_focus.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_batches_reinject_when_env_mutates.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________ test_run_tests_env_var_propagation_retains_existing_addopts __________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67d8e0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_env_var_propaga0')

    @pytest.mark.fast
    def test_run_tests_env_var_propagation_retains_existing_addopts(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
    ) -> None:
        """ReqID: RUN-TESTS-ENV-1 — CLI helper preserves existing PYTEST_ADDOPTS."""
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
        monkeypatch.setenv("PYTEST_ADDOPTS", "-q")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_env.py"
        test_file.write_text("def test_env():\n    assert True\n")
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(returncode=0, stdout=f"{test_file}::test_env", stderr="")
    
        recorded: list[tuple[list[str], dict[str, str]]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                recorded.append((list(cmd), dict(env or {})))
                self.returncode = 0
                self._stdout = "pass"
                self._stderr = ""
    
            def communicate(self):  # noqa: D401 - mimic subprocess API
                """Return deterministic stdout/stderr."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            maxfail=1,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_helpers_focus.py:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_env_var_propagation_retains_existing_addopts.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_____________________________________ test_run_tests_option_wiring_includes_expected_flags _____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67dd30>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_option_wiring_i0')

    @pytest.mark.fast
    def test_run_tests_option_wiring_includes_expected_flags(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
    ) -> None:
        """ReqID: RUN-TESTS-PYTEST-OPTS-1 — Command wiring emits coverage/report args."""
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_opts.py"
        test_file.write_text("def test_opts():\n    assert True\n")
    
        class FakeDT:
            @staticmethod
            def now() -> SimpleNamespace:
                return SimpleNamespace(strftime=lambda fmt: "20250102_000000")
    
        monkeypatch.setattr(rt, "datetime", FakeDT)
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(
                returncode=0, stdout=f"{test_file}::test_opts", stderr=""
            )
    
        recorded: list[list[str]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                recorded.append(list(cmd))
                self.returncode = 0
                self._stdout = "opts"
                self._stderr = ""
    
            def communicate(self):
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=True,
            report=True,
            parallel=False,
            segment=False,
            maxfail=3,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_helpers_focus.py:377: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_option_wiring_includes_expected_flags.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_______________________________________ test_cli_marker_expression_includes_extra_marker _______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67e3c0>

    @pytest.mark.fast
    def test_cli_marker_expression_includes_extra_marker(
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ARGS-1 — CLI marker flag augments default filters."""
    
        commands: list[list[str]] = []
    
        class DummyProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                commands.append(cmd)
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("collected 1 item", "")
    
        monkeypatch.setattr(rt.subprocess, "Popen", DummyProcess)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            extra_marker="custom_marker",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 300.0, check = False
popenargs = (['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout (seconds) is given and the process takes too long,
         a TimeoutExpired exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
>       with Popen(*popenargs, **kwargs) as process:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'DummyProcess' object does not support the context manager protocol

/root/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:548: TypeError
__________________________________________ test_cli_failure_surfaces_actionable_tips ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67d430>

    @pytest.mark.fast
    def test_cli_failure_surfaces_actionable_tips(
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ERROR-1 — CLI surfaces troubleshooting tips."""
    
        commands: list[list[str]] = []
    
        class FailingProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                commands.append(cmd)
                raise RuntimeError("simulated failure")
    
        monkeypatch.setattr(rt.subprocess, "Popen", FailingProcess)
    
        success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
        )
    
        assert success is False
        assert "simulated failure" in output
        assert commands, "Expected to capture the failing pytest command"
    
        expected_tips = rt._failure_tips(-1, commands[0])
>       assert expected_tips in output
E       AssertionError: assert '\nPytest exited with code -1. Command: /workspace/devsynth/.venv/bin/python -m pytest tests/unit/ --collect-only -q -...HTML report for context (saved under test_reports/):\n  devsynth run-tests --target unit-tests --speed=fast --report\n' in 'simulated failure'

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:121: AssertionError
_________________________________________ test_cli_segment_batches_follow_segment_size _________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67dca0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_segment_batches_follo0')

    @pytest.mark.fast
    def test_cli_segment_batches_follow_segment_size(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-SEGMENT-1 — Segmentation obeys CLI batch sizing."""
    
        # Point the unit-tests target to a temporary directory with synthetic tests
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        file_a = tmp_path / "test_alpha.py"
        file_b = tmp_path / "test_beta.py"
        file_a.write_text("def test_one():\n    assert True\n")
        file_b.write_text("def test_two():\n    assert True\n")
    
        node_ids = [
            f"{file_a}::test_one",
            f"{file_a}::test_two",
            f"{file_b}::test_three",
        ]
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            assert "--collect-only" in cmd
            return SimpleNamespace(stdout="\n".join(node_ids), stderr="", returncode=0)
    
        commands: list[list[str]] = []
    
        class BatchProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                commands.append(cmd)
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("ok", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", BatchProcess)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=2,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:174: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_segment_batches_follow_segment_size.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
________________________________________ test_cli_segment_failure_emits_aggregate_tips _________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67c920>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_segment_failure_emits0')

    @pytest.mark.fast
    def test_cli_segment_failure_emits_aggregate_tips(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-SEGMENT-2 — failing batch surfaces aggregate tips."""
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_segmented.py"
        test_file.write_text(
            "def test_batch_one():\n    assert True\n\n"
            "def test_batch_two():\n    assert True\n"
        )
    
        node_ids = [
            f"{test_file}::test_batch_one",
            f"{test_file}::test_batch_two",
        ]
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            return SimpleNamespace(stdout="\n".join(node_ids), stderr="", returncode=0)
    
        batch_commands: list[list[str]] = []
        responses = [
            ("batch one ok", "", 0),
            ("batch two fail", "collected errors", 2),
        ]
        tips_record: list[tuple[int, tuple[str, ...], str]] = []
    
        def fake_failure_tips(returncode: int, cmd: list[str]) -> str:
            tip = f"[tip {returncode} #{len(tips_record)}]"
            tips_record.append((returncode, tuple(cmd), tip))
            return tip
    
        call_index = {"value": 0}
    
        class DummyBatchProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                idx = call_index["value"]
                batch_commands.append(cmd)
                stdout_payload, stderr_payload, returncode = responses[idx]
                self._stdout = stdout_payload
                self._stderr = stderr_payload
                self.returncode = returncode
                call_index["value"] += 1
    
            def communicate(self) -> tuple[str, str]:
                return (self._stdout, self._stderr)
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", DummyBatchProcess)
        monkeypatch.setattr(rt, "_failure_tips", fake_failure_tips)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_segment_failure_emits_aggregate_tips.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_______________________________________ test_cli_keyword_filter_handles_resource_marker ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6764b0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_keyword_filter_handle0')

    @pytest.mark.fast
    def test_cli_keyword_filter_handles_resource_marker(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ARGS-2 — resource markers trigger keyword filtering."""
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_lmstudio.py"
        test_file.write_text("def test_stub():\n    assert True\n")
    
        collect_commands: list[list[str]] = []
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            collect_commands.append(cmd)
            return SimpleNamespace(
                stdout=f"{test_file.name}::test_stub\n", stderr="", returncode=0
            )
    
        run_commands: list[list[str]] = []
    
        class DummyProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                run_commands.append(cmd)
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("ok", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", DummyProcess)
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_keyword_filter_handles_resource_marker.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
__________________________________________ test_cli_marker_filters_merge_extra_marker __________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd676a20>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_marker_filters_merge_0')

    @pytest.mark.fast
    def test_cli_marker_filters_merge_extra_marker(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ARGS-3 — speed markers combine with extra filter."""
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_filters.py"
        test_file.write_text("def test_placeholder():\n    assert True\n")
    
        collect_invocations: list[list[str]] = []
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            collect_invocations.append(cmd)
            return SimpleNamespace(
                stdout=f"{test_file}::test_placeholder\n", stderr="", returncode=0
            )
    
        run_commands: list[list[str]] = []
    
        class DummyProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                run_commands.append(cmd)
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("ok", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", DummyProcess)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast", "slow"],
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            extra_marker="custom_marker",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:409: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_marker_filters_merge_extra_marker.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________________ test_cli_report_mode_adds_html_argument ____________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd677320>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_report_mode_adds_html0')

    @pytest.mark.fast
    def test_cli_report_mode_adds_html_argument(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-REPORT-1 — report flag appends HTML output options."""
    
        monkeypatch.chdir(tmp_path)
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        test_file = tmp_path / "test_report.py"
        test_file.write_text("def test_report():\n    assert True\n")
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            return SimpleNamespace(
                stdout=f"{test_file.name}::test_report\n", stderr="", returncode=0
            )
    
        run_commands: list[list[str]] = []
    
        class DummyProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                run_commands.append(cmd)
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("report ok", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", DummyProcess)
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=True,
            parallel=False,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:480: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_report_mode_adds_html_argument.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_______________________________________ test_cli_env_passthrough_and_coverage_lifecycle ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd677200>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_env_passthrough_and_c0')

    @pytest.mark.fast
    def test_cli_env_passthrough_and_coverage_lifecycle(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ENV-1 — env vars propagate and coverage lifecycle runs."""
    
        lifecycle: list[str] = []
    
        def fake_reset() -> None:
            lifecycle.append("reset")
    
        def fake_ensure() -> None:
            lifecycle.append("ensure")
    
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", fake_reset)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", fake_ensure)
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
        monkeypatch.setenv("DEVSYNTH_FEATURE_SAMPLE", "enabled")
    
        test_file = tmp_path / "test_env.py"
        test_file.write_text("def test_env_marker():\n    assert True\n")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            return SimpleNamespace(
                stdout=f"{test_file}::test_env_marker\n", stderr="", returncode=0
            )
    
        popen_calls: list[dict[str, object]] = []
    
        class DummyProcess:
            def __init__(
                self,
                cmd: list[str],
                stdout=None,
                stderr=None,
                text: bool = False,
                env: dict[str, str] | None = None,
            ) -> None:
                popen_calls.append({"cmd": cmd, "env": env})
                self.returncode = 0
    
            def communicate(self) -> tuple[str, str]:
                return ("done", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", DummyProcess)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:630: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_env_passthrough_and_coverage_lifecycle.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________ test_cli_keyword_filter_returns_success_when_no_matches ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd674170>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_cli_keyword_filter_return0')

    @pytest.mark.fast
    def test_cli_keyword_filter_returns_success_when_no_matches(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RUN-TESTS-CLI-ARGS-4 — keyword fallback exits cleanly when empty."""
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
    
        lifecycle: list[str] = []
    
        def fake_reset() -> None:
            lifecycle.append("reset")
    
        def fake_ensure() -> None:
            lifecycle.append("ensure")
    
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", fake_reset)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", fake_ensure)
    
        collect_commands: list[list[str]] = []
    
        def fake_collect(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ) -> SimpleNamespace:
            collect_commands.append(cmd)
            return SimpleNamespace(stdout="", stderr="", returncode=0)
    
        def fail_popen(*args, **kwargs):
            raise AssertionError("Popen should not be invoked when no tests match")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", fail_popen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_cli_keyword_filter_returns_success_when_no_matches.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
____________________________________ test_run_tests_generates_artifacts_for_normal_profile _____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67ddc0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_generates_artif0')

    @pytest.mark.fast
    def test_run_tests_generates_artifacts_for_normal_profile(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """Normal run writes `.coverage`, JSON, and HTML artifacts via the harness."""
    
        monkeypatch.chdir(tmp_path)
    
        coverage_json = tmp_path / "reports" / "coverage.json"
        html_dir = tmp_path / "htmlcov"
        monkeypatch.setattr(rt, "COVERAGE_JSON_PATH", coverage_json)
        monkeypatch.setattr(rt, "COVERAGE_HTML_DIR", html_dir)
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", "tests/unit")
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", "tests")
    
        monkeypatch.setattr(
            rt, "collect_tests_with_cache", lambda *_: ["tests/unit/test_ok.py::test_one"]
        )
    
        lifecycle: list[str] = []
        monkeypatch.setattr(
            rt, "_reset_coverage_artifacts", lambda: lifecycle.append("reset")
        )
        monkeypatch.setattr(
            rt, "_ensure_coverage_artifacts", lambda: lifecycle.append("ensure")
        )
    
        popen_envs: list[dict[str, str]] = []
    
        def fake_single_batch(
            config: rt.SingleBatchRequest,
        ) -> rt.BatchExecutionResult:
            popen_envs.append(dict(config.env))
            tmp_path.joinpath(".coverage").write_text("data")
            html_dir.mkdir(parents=True, exist_ok=True)
            (html_dir / "index.html").write_text("<html>ok</html>")
            coverage_json.parent.mkdir(parents=True, exist_ok=True)
            coverage_json.write_text(json.dumps({"totals": {"percent_covered": 98.7}}))
            return True, "batch ok", build_batch_metadata("batch-cli-artifacts")
    
        monkeypatch.setattr(rt, "_run_single_test_batch", fake_single_batch)
    
        success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=True,
            parallel=False,
        )
    
        assert success is True
>       assert output == "batch ok"
E       AssertionError: assert 'batch ok\n[k...hold=90.00%\n' == 'batch ok'
E         
E         - batch ok
E         + batch ok
E         ?         +
E         + [knowledge-graph] coverage gate pass → QualityGate c4edac8b-ad8d-40bc-823e-1583ecb6c43c (new), TestRun 4c6f7af3-6852-44b8-a395-d82eb98714e9 (new), Evidence [47f62c16-c3b7-481d-8b0c-264b2cf403cf (new), 8ef0f154-a981-431f-baf6-dd5f46735514 (new)] via networkx; coverage=98.70% threshold=90.00%

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:758: AssertionError
__________________________________ test_run_tests_generates_artifacts_with_autoload_disabled ___________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd67e570>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_generates_artif1')

    @pytest.mark.fast
    def test_run_tests_generates_artifacts_with_autoload_disabled(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """Smoke-style environments still create coverage artifacts with plugin injection."""
    
        monkeypatch.chdir(tmp_path)
    
        coverage_json = tmp_path / "reports" / "coverage.json"
        html_dir = tmp_path / "htmlcov"
        monkeypatch.setattr(rt, "COVERAGE_JSON_PATH", coverage_json)
        monkeypatch.setattr(rt, "COVERAGE_HTML_DIR", html_dir)
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", "tests/unit")
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", "tests")
    
        monkeypatch.setattr(
            rt, "collect_tests_with_cache", lambda *_: ["tests/unit/test_ok.py::test_one"]
        )
    
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        captured_envs: list[dict[str, str]] = []
    
        def fake_single_batch(
            config: rt.SingleBatchRequest,
        ) -> rt.BatchExecutionResult:
            captured_envs.append(dict(config.env))
            tmp_path.joinpath(".coverage").write_text("data")
            html_dir.mkdir(parents=True, exist_ok=True)
            (html_dir / "index.html").write_text("<html>smoke</html>")
            coverage_json.parent.mkdir(parents=True, exist_ok=True)
            coverage_json.write_text(json.dumps({"totals": {"percent_covered": 94.2}}))
            return True, "smoke ok", build_batch_metadata("batch-cli-smoke")
    
        monkeypatch.setattr(rt, "_run_single_test_batch", fake_single_batch)
    
        env = {"PYTEST_DISABLE_PLUGIN_AUTOLOAD": "1"}
        success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=True,
            report=True,
            parallel=True,
            env=env,
        )
    
        assert success is True
>       assert output == "smoke ok"
E       AssertionError: assert 'smoke ok\n[k...hold=90.00%\n' == 'smoke ok'
E         
E         - smoke ok
E         + smoke ok
E         ?         +
E         + [knowledge-graph] coverage gate pass → QualityGate d88f23d4-252a-417d-ab6d-e89869d8201e (new), TestRun b0c29e8d-80b2-4a79-8956-39477f9ce4b0 (new), Evidence [307d58ea-9e1a-4bb5-89af-cba91fe9960b (new), a4401f55-85bb-434f-9c31-04e642f9d7ba (new)] via networkx; coverage=94.20% threshold=90.00%

/workspace/devsynth/tests/unit/testing/test_run_tests_cli_invocation.py:817: AssertionError
________________________________________ test_keyword_filter_no_matches_returns_success ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6d9010>

    @pytest.mark.fast
    def test_keyword_filter_no_matches_returns_success(monkeypatch) -> None:
        """ReqID: RT-01 — keyword filter with no matches returns success and message."""
    
        # Simulate collect-only returning no matching node ids under keyword filter
        def fake_run(
            cmd,  # noqa: ANN001
            check: bool = False,
            capture_output: bool = False,
            text: bool = False,
        ):  # type: ignore[no-redef]
            class R:
                def __init__(self) -> None:
                    self.returncode = 0
                    # nothing that matches the node id regex
                    self.stdout = "\n"
                    self.stderr = ""
    
            return R()
    
        # Ensure Popen is not invoked if there are no node ids
        def fail_popen(*args, **kwargs):  # type: ignore[no-redef]
            pytest.fail("Popen should not be called when no node ids match")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", fail_popen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_keyword_filter_no_matches_returns_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________________ test_failure_tips_appended_on_nonzero_return _________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd677650>

    @pytest.mark.fast
    def test_failure_tips_appended_on_nonzero_return(monkeypatch) -> None:
        """ReqID: RT-02 — non-zero exit appends troubleshooting tips."""
    
        # Make the simple '-m not memory_intensive' path run and return a non-zero code
        class DummyProc:
            def __init__(self) -> None:
                self.returncode = 2
    
            def communicate(self) -> tuple[str, str]:
                return ("", "boom")
    
        def fake_popen(
            args,  # noqa: ANN001
            stdout=None,  # noqa: ANN001
            stderr=None,  # noqa: ANN001
            text=None,  # noqa: ANN001
            env=None,  # noqa: ANN001
        ):  # type: ignore[no-redef]
            return DummyProc()
    
        monkeypatch.setattr(rt.subprocess, "Popen", fake_popen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra.py:72: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 300.0, check = False
popenargs = (['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout (seconds) is given and the process takes too long,
         a TimeoutExpired exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
>       with Popen(*popenargs, **kwargs) as process:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'DummyProc' object does not support the context manager protocol

/root/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:548: TypeError
___________________________________ test_keyword_filter_lmstudio_no_matches_returns_success ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1503e0>

    @pytest.mark.fast
    def test_keyword_filter_lmstudio_no_matches_returns_success(monkeypatch):
        """ReqID: TR-RT-08 — Keyword 'lmstudio' no-match returns success.
    
        When extra_marker includes requires_resource('lmstudio') and collection
        yields no matching node ids, run_tests should return success=True with a
        helpful message without attempting to execute pytest on any node ids.
        """
    
        class DummyRunResult:
            def __init__(self):
                self.stdout = ""  # no node ids collected
                self.stderr = ""
                self.returncode = 0
    
        calls = {
            "run": [],
            "popen": [],
        }
    
        def fake_run(
            cmd, check=False, capture_output=True, text=True
        ):  # type: ignore[override]
            calls["run"].append(cmd)
            return DummyRunResult()
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # type: ignore[no-redef]
                calls["popen"].append(cmd)
                # This path should not be reached because no node ids => early return
                self._stdout = ""
                self._stderr = ""
                self.returncode = 0
    
            def communicate(self):
                return self._stdout, self._stderr
    
        import subprocess
    
        monkeypatch.setattr(subprocess, "run", fake_run)
        monkeypatch.setattr(subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_marker.py:50: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_keyword_filter_lmstudio_no_matches_returns_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
__________________________________________ test_extra_marker_merges_into_m_expression __________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd152210>

    @pytest.mark.fast
    def test_extra_marker_merges_into_m_expression(monkeypatch):
        """ReqID: TR-RT-09 — Non-keyword extra_marker merges into -m expression."""
        """
        When extra_marker does not invoke the keyword fallback, ensure it is merged
        into the -m expression and subprocess.Popen is called once; run_tests returns
        success if the process returncode is 0.
        """
    
        class FakePopen:
            last_cmd = None
    
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # type: ignore[no-redef]
                FakePopen.last_cmd = cmd
                self.returncode = 0
                self._stdout = "pytest ok\n"
                self._stderr = ""
    
            def communicate(self):
                return self._stdout, self._stderr
    
        import subprocess
    
        def fake_run(
            cmd, check=False, capture_output=True, text=True
        ):  # type: ignore[override]
            # Not used in this path; ensure it's not called unnecessarily
            raise AssertionError("subprocess.run should not be called for non-keyword path")
    
        monkeypatch.setattr(subprocess, "Popen", FakePopen)
        monkeypatch.setattr(subprocess, "run", fake_run)
    
        extra = "slow or (requires_resource('codebase'))"
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=extra,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_marker.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_extra_marker_merges_into_m_expression.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________ test_run_tests_merges_extra_marker_into_category_expression __________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd152150>

    @pytest.mark.fast
    def test_run_tests_merges_extra_marker_into_category_expression(monkeypatch):
        """ReqID: TR-RT-09 — Merge extra_marker into -m expression.
    
        When speed_categories is None and extra_marker is a normal expression
        (not a requires_resource('lmstudio') keyword case), run_tests should pass
        a combined -m expression that includes both the base filter and the extra
        marker.
        """
        import devsynth.testing.run_tests as rt
    
        captured_cmd = {}
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                # The command should include '-m' with the merged expression
                assert "-m" in cmd, f"-m missing in: {cmd}"
                # There are two '-m' flags: Python module and pytest marker; use the last
                idx = len(cmd) - 1 - cmd[::-1].index("-m")
                expr = cmd[idx + 1]
                assert "not memory_intensive" in expr
                assert "(not slow)" in expr or "not slow" in expr
                captured_cmd["cmd"] = cmd
                self.returncode = 0
    
            def communicate(self):
                return ("ok\n", "")
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker="not slow",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_marker_passthrough.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
/root/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:548: in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.unit.testing.test_run_tests_extra_marker_passthrough.test_run_tests_merges_extra_marker_into_category_expression.<locals>.FakePopen object at 0x7ff8dd1b2d20>
cmd = ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...], stdout = -1
stderr = -1, text = True, env = None

    def __init__(
        self, cmd, stdout=None, stderr=None, text=False, env=None
    ):  # noqa: ANN001
        # The command should include '-m' with the merged expression
        assert "-m" in cmd, f"-m missing in: {cmd}"
        # There are two '-m' flags: Python module and pytest marker; use the last
        idx = len(cmd) - 1 - cmd[::-1].index("-m")
        expr = cmd[idx + 1]
        assert "not memory_intensive" in expr
>       assert "(not slow)" in expr or "not slow" in expr
E       AssertionError: assert ('(not slow)' in 'fast and not memory_intensive' or 'not slow' in 'fast and not memory_intensive')

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_marker_passthrough.py:29: AssertionError
_______________________________________ test_collect_fallback_on_behavior_speed_no_tests _______________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_fallback_on_behav0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd150350>

    @pytest.mark.fast
    def test_collect_fallback_on_behavior_speed_no_tests(tmp_path, monkeypatch):
        """When behavior-tests with a speed filter yields no tests, fallback to marker_expr.
    
        We simulate the preliminary check returning a 'no tests ran' message and assert that
        the second collection call (fallback) is invoked and its items are returned.
        ReqID: C3 (coverage of fallback branch)
        """
        # Arrange
        from devsynth.testing import run_tests as rt
    
        # Redirect cache dir and target path to isolated temp locations
        cache_dir = tmp_path / ".cache"
        cache_dir.mkdir()
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", str(cache_dir))
        monkeypatch.setitem(rt.TARGET_PATHS, "behavior-tests", str(tmp_path))
        # Create a real file that the pruning check will accept
        real_file = tmp_path / "test_example.py"
        real_file.write_text(
            "import pytest\n\n@pytest.mark.fast\ndef test_ok():\n    assert True\n"
        )
    
        # Prepare fake subprocess.run that returns two different responses:
        calls = {"invocations": []}
    
        class FakeCompleted:
            def __init__(self, stdout: str, returncode: int = 0, stderr: str = ""):
                self.stdout = stdout
                self.returncode = returncode
                self.stderr = stderr
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            calls["invocations"].append(cmd)
            # First invocation is the preliminary check (with same category_expr)
            if len(calls["invocations"]) == 1:
                return FakeCompleted(stdout="no tests ran\n", returncode=0)
            # Second invocation should be the fallback collection using marker_expr only
            # Return a couple of node ids
            return FakeCompleted(stdout=f"{real_file}::test_ok\n")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        # Act
>       out = rt.collect_tests_with_cache(target="behavior-tests", speed_category="fast")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_paths.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'behavior-tests', speed_category = 'fast'

    def collect_tests_with_cache(
        target: str,
        speed_category: str | None = None,
        *,
        keyword_filter: str | None = None,
        _allow_all_target_decomposition: bool = True,
        _timeout_override: float | None = None,
        _propagate_timeout: bool = False,
    ) -> list[str]:
        """Collect tests for the given target and speed category.
    
        Args:
            target: Logical test target such as ``unit-tests`` or ``all-tests``.
            speed_category: Optional speed marker used to scope collection.
            keyword_filter: Optional ``-k`` expression applied during collection.
    
        Returns:
            A list of pytest node identifiers matching the requested filters.
        """
        test_path = TARGET_PATHS.get(target, TARGET_PATHS["all-tests"])
    
        # Build the marker expression we'll use and compute a simple fingerprint of
        # the test tree (latest mtime) to detect changes that should invalidate cache.
        marker_expr = "not memory_intensive"
        category_expr = marker_expr
        if speed_category:
            category_expr = f"{speed_category} and {marker_expr}"
    
        normalized_filter = _normalize_keyword_filter(keyword_filter)
        latest_mtime = _latest_mtime(test_path)
        base_cache_key = f"{target}_{speed_category or 'all'}"
        suffix = _cache_key_suffix(normalized_filter)
        cache_key = f"{base_cache_key}_{suffix}" if suffix else base_cache_key
        cache_file = (
>           COLLECTION_CACHE_DIR / f"{cache_key}_tests.json"
        )  # Use Path object for cache_file
E       TypeError: unsupported operand type(s) for /: 'str' and 'str'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1179: TypeError
___________________________________________ test_collect_malformed_cache_regenerates ___________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_malformed_cache_r0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd151e20>

    @pytest.mark.fast
    def test_collect_malformed_cache_regenerates(tmp_path, monkeypatch):
        """Malformed JSON cache should be ignored and collection regenerated.
    
        ReqID: C3 (coverage of malformed cache read path)
        """
        from devsynth.testing import run_tests as rt
    
        # Point cache dir and target path
        cache_dir = tmp_path / ".cache"
        cache_dir.mkdir()
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", str(cache_dir))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
        # Create a real file for existence pruning
        real2 = tmp_path / "test_a.py"
        real2.write_text(
            "import pytest\n\n@pytest.mark.fast\ndef test_b():\n    assert True\n"
        )
    
        # Write malformed JSON to the expected cache file for key all-tests_all
        cache_file = cache_dir / "all-tests_all_tests.json"
        cache_file.write_text("{ not-json }")
    
        # Fake subprocess.run to return one id
        class FakeCompleted:
            def __init__(self, stdout: str, returncode: int = 0, stderr: str = ""):
                self.stdout = stdout
                self.returncode = returncode
                self.stderr = stderr
    
        monkeypatch.setattr(
            rt.subprocess,
            "run",
            lambda *a, **k: FakeCompleted(stdout=f"{real2}::test_b\n"),
        )
    
>       out = rt.collect_tests_with_cache(target="all-tests", speed_category=None)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_paths.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'all-tests', speed_category = None

    def collect_tests_with_cache(
        target: str,
        speed_category: str | None = None,
        *,
        keyword_filter: str | None = None,
        _allow_all_target_decomposition: bool = True,
        _timeout_override: float | None = None,
        _propagate_timeout: bool = False,
    ) -> list[str]:
        """Collect tests for the given target and speed category.
    
        Args:
            target: Logical test target such as ``unit-tests`` or ``all-tests``.
            speed_category: Optional speed marker used to scope collection.
            keyword_filter: Optional ``-k`` expression applied during collection.
    
        Returns:
            A list of pytest node identifiers matching the requested filters.
        """
        test_path = TARGET_PATHS.get(target, TARGET_PATHS["all-tests"])
    
        # Build the marker expression we'll use and compute a simple fingerprint of
        # the test tree (latest mtime) to detect changes that should invalidate cache.
        marker_expr = "not memory_intensive"
        category_expr = marker_expr
        if speed_category:
            category_expr = f"{speed_category} and {marker_expr}"
    
        normalized_filter = _normalize_keyword_filter(keyword_filter)
        latest_mtime = _latest_mtime(test_path)
        base_cache_key = f"{target}_{speed_category or 'all'}"
        suffix = _cache_key_suffix(normalized_filter)
        cache_key = f"{base_cache_key}_{suffix}" if suffix else base_cache_key
        cache_file = (
>           COLLECTION_CACHE_DIR / f"{cache_key}_tests.json"
        )  # Use Path object for cache_file
E       TypeError: unsupported operand type(s) for /: 'str' and 'str'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1179: TypeError
__________________________________ test_run_tests_lmstudio_extra_marker_keyword_early_success __________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_lmstudio_extra_0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b2090>

    @pytest.mark.fast
    def test_run_tests_lmstudio_extra_marker_keyword_early_success(tmp_path, monkeypatch):
        """With extra_marker requires_resource('lmstudio') and no matches, run_tests should
        perform keyword-based collection and return success with a friendly message.
    
        ReqID: C3 (coverage of extra_marker keyword path with early success)
        """
        from devsynth.testing import run_tests as rt
    
        # Point the unit-tests target to an isolated path (not used directly here)
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
    
        # Fake subprocess.run for the collect-only path to return no matching node IDs
        class FakeCompleted:
            def __init__(self, stdout: str, returncode: int = 0, stderr: str = ""):
                self.stdout = stdout
                self.returncode = returncode
                self.stderr = stderr
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            # Simulate collect-only returning nothing for '-k lmstudio'
            return FakeCompleted(stdout="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            parallel=False,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_extra_paths.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_lmstudio_extra_marker_keyword_early_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
____________________________________________ test_failure_tips_include_common_flags ____________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_failure_tips_include_comm0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b09e0>

    @pytest.mark.fast
    def test_failure_tips_include_common_flags(tmp_path, monkeypatch):
        """ReqID: FR-59 Ensure failure tips include common flags examples.
    
        We create a minimal failing test and assert that the output contains
        actionable hints for --smoke, --segment/--segment-size, --maxfail,
        --no-parallel, and --report.
        """
        test_file = tmp_path / "test_fails.py"
        test_file.write_text(
            """
    import pytest
    
    @pytest.mark.fast
    def test_will_fail():
        assert False
    """
        )
        # Point unit-tests target to our tmp_path
        monkeypatch.setitem(TARGET_PATHS, "unit-tests", str(tmp_path))
    
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(
                returncode=0,
                stdout=f"{test_file}::test_will_fail",
                stderr="",
            )
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                self.cmd = list(cmd)
                self.returncode = 1
                self._stdout = ""
                self._stderr = "FAIL Required test coverage of 90% not reached."
    
            def communicate(self):  # noqa: D401 - mimic subprocess signature
                """Return predetermined stdout/stderr."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests("unit-tests", ["fast"], parallel=False)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_failure_tips.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_failure_tips_include_common_flags.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
________________________________________ test_keyword_marker_executes_matching_node_ids ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b0ad0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_keyword_marker_executes_m0')

    @pytest.mark.fast
    def test_keyword_marker_executes_matching_node_ids(monkeypatch, tmp_path: Path) -> None:
        """ReqID: TR-RT-07 — Keyword-based exec path runs collected node ids."""
        # Prepare collection output with two node ids
        collect_stdout = "\n".join(
            [
                "tests/unit/test_sample.py::test_a",
                "tests/unit/test_sample.py::test_b",
            ]
        )
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            # Simulate the '--collect-only' run
            return DummyCompleted(stdout=collect_stdout, returncode=0)
    
        def fake_popen(cmd, stdout=None, stderr=None, text=True, env=None):  # noqa: ANN001
            # Ensure that the selected node ids appear in the run command
            assert any("test_sample.py::test_a" in s for s in cmd), cmd
            assert any("test_sample.py::test_b" in s for s in cmd), cmd
            return DummyPopen(returncode=0, stdout="passed", stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", fake_popen)
    
>       ok, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_keyword_exec.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_keyword_marker_executes_matching_node_ids.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
____________________________________ test_keyword_filter_no_matches_returns_success_message ____________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_keyword_filter_no_matches1')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b07d0>

    @pytest.mark.fast
    def test_keyword_filter_no_matches_returns_success_message(tmp_path, monkeypatch):
        """ReqID: FR-11.2 — Keyword filter path returns success when no matches.
    
        Triggers the lmstudio keyword path and expects a friendly message.
        """
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            assert "-k" in cmd and "lmstudio" in cmd
            return SimpleNamespace(returncode=0, stdout="", stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
    
        # Use a very specific marker expression to trigger keyword path.
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_keyword_filter.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_keyword_filter_no_matches_returns_success_message.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
________________________________ test_keyword_filter_honors_report_flag_and_creates_report_dir _________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b1d90>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_keyword_filter_honors_rep0')

    @pytest.mark.fast
    def test_keyword_filter_honors_report_flag_and_creates_report_dir(
        monkeypatch, tmp_path
    ):
        """ReqID: FR-11.2 — Report flag creates deterministic report directory.
    
        Use keyword path with report=True and patch datetime to assert directory path.
        """
    
        class FakeDT:
            @staticmethod
            def now():
                # Fixed timestamp for stable directory path
                class _DT:
                    def strftime(self, fmt: str) -> str:
                        return "20250101_000000"
    
                return _DT()
    
        monkeypatch.setattr(rt, "datetime", FakeDT)
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        test_file = tmp_path / "test_lmstudio.py"
        test_file.write_text("def test_placeholder():\n    assert True\n")
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            assert "-k" in cmd and "lmstudio" in cmd
            return SimpleNamespace(
                returncode=0,
                stdout=f"{test_file}::test_placeholder",
                stderr="",
            )
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                self.cmd = list(cmd)
                self.returncode = 0
                self._stdout = "ok"
                self._stderr = ""
    
            def communicate(self):  # noqa: D401 - mimic subprocess API
                """Return deterministic stdout/stderr."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=True,
            parallel=False,
            segment=False,
            extra_marker='requires_resource("lmstudio")',
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_keyword_filter.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_keyword_filter_honors_report_flag_and_creates_report_dir.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
____________________________ test_run_tests_lmstudio_keyword_filter_with_no_matches_returns_success ____________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd1b3440>

    @pytest.mark.fast
    def test_run_tests_lmstudio_keyword_filter_with_no_matches_returns_success(monkeypatch):
        """
        ReqID: C3-05
        When extra_marker requires_resource('lmstudio') is provided and the keyword-filtered
        collection yields no tests, run_tests should short-circuit and return success=True
        with a friendly message instead of attempting to invoke pytest with empty args.
        """
    
        # Simulate `pytest --collect-only -q -m <expr> -k lmstudio` returning no node IDs.
        class DummyCompleted:
            def __init__(self, stdout: str = "", returncode: int = 0):
                self.stdout = stdout
                self.stderr = ""
                self.returncode = returncode
    
        def fake_run(
            cmd: list[str],
            check: bool = False,
            capture_output: bool = True,
            text: bool = True,
        ):  # type: ignore[no-redef]
            # Ensure we're calling a python -m pytest command with '--collect-only'
            assert cmd[:3] == [sys.executable, "-m", "pytest"], cmd
            assert "--collect-only" in cmd
            # Return empty stdout to indicate no matched tests
            return DummyCompleted(stdout="", returncode=0)
    
        monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")  # keep hermetic and fast
        monkeypatch.setenv("DEVSYNTH_OFFLINE", "true")
    
        monkeypatch.setattr("subprocess.run", fake_run)
    
        # Call run_tests with an lmstudio resource marker expression
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,  # triggers the single-pass branch
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_keyword_filter_empty.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_lmstudio_keyword_filter_with_no_matches_returns_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________________ test_collect_tests_with_cache_uses_cache ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd540380>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_3')

    @typed_freeze_time("2025-01-01")
    @pytest.mark.fast
    def test_collect_tests_with_cache_uses_cache(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-COLL-1 — collect_tests_with_cache uses the cache."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        cache_dir = tmp_path / rt.COLLECTION_CACHE_DIR
        cache_dir.mkdir()
        cache_file = cache_dir / "unit-tests_fast_tests.json"
        cached_data = {
            "timestamp": "2025-01-01T00:00:00.000000",
            "tests": [os.path.join(str(tmp_path), "test_file.py")],
            "fingerprint": {
                "latest_mtime": 1.0,
                "category_expr": "fast and not memory_intensive",
                "test_path": str(tmp_path),
            },
        }
        with open(cache_file, "w") as f:
            json.dump(cached_data, f)
    
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
        with (
            patch.object(rt.os.path, "getmtime", return_value=1.0),
            patch.object(rt.subprocess, "run") as mock_run,
            patch.object(rt, "COLLECTION_CACHE_TTL_SECONDS", 999999),
        ):
>           tests = rt.collect_tests_with_cache("unit-tests", "fast")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_logic.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
        result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
        if result.returncode != 0:
            error_message = f"Test collection failed: {result.stderr}"
            logger.warning(
                error_message,
                extra={
                    "event": "test_collection_failed",
                    "target": target,
                    "speed_category": category_expr,
                },
            )
>           raise RuntimeError(error_message)
E           RuntimeError: Test collection failed: <MagicMock name='run().stderr' id='140706836769168'>

/workspace/devsynth/src/devsynth/testing/run_tests.py:1096: RuntimeError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection failed: <MagicMock name='run().stderr' id='140706836769168'>
____________________________________ test_collect_tests_with_cache_regenerates_when_expired ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd543a70>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_4')

    @typed_freeze_time("2025-01-02")
    @pytest.mark.fast
    def test_collect_tests_with_cache_regenerates_when_expired(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-COLL-2 — collect_tests_with_cache regenerates when expired."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        cache_dir = tmp_path / rt.COLLECTION_CACHE_DIR
        cache_dir.mkdir()
        cache_file = cache_dir / "unit-tests_fast_tests.json"
        cached_data = {
            "timestamp": "2025-01-01T00:00:00.000000",
            "tests": [os.path.join(str(tmp_path), "test_file.py")],
            "fingerprint": {
                "latest_mtime": 0.5,
                "category_expr": "fast and not memory_intensive",
                "test_path": str(tmp_path),
            },
        }
        with open(cache_file, "w") as f:
            json.dump(cached_data, f)
    
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
        with (
            patch.object(rt.os.path, "getmtime", return_value=1.0),
            patch.object(rt.subprocess, "run") as mock_run,
            patch.object(rt, "COLLECTION_CACHE_TTL_SECONDS", 999999),
        ):
            mock_run.return_value = SimpleNamespace(
                stdout=os.path.join(str(tmp_path), "new_test.py") + "\n",
                returncode=0,
                stderr="",
            )
            tests = rt.collect_tests_with_cache("unit-tests", "fast")
    
>       assert tests == [os.path.join(tmp_path, "new_test.py")]
E       AssertionError: assert [] == ['/tmp/pytest.../new_test.py']
E         
E         Right contains one more item: '/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_4/new_test.py'
E         Use -v to get more diff

/workspace/devsynth/tests/unit/testing/test_run_tests_logic.py:118: AssertionError
______________________________________________ test_collect_tests_with_cache_miss ______________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd542330>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_5')

    @typed_freeze_time("2025-01-01")
    @pytest.mark.fast
    def test_collect_tests_with_cache_miss(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-COLL-3 — collect_tests_with_cache handles a cache miss."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
    
        with (
            patch.object(rt.os.path, "getmtime", return_value=1.0),
            patch.object(rt.subprocess, "run") as mock_run,
            patch.object(rt, "COLLECTION_CACHE_TTL_SECONDS", 999999),
        ):
            mock_run.return_value = SimpleNamespace(
                stdout=os.path.join(str(tmp_path), "test_file.py") + "\n",
                returncode=0,
                stderr="",
            )
            tests = rt.collect_tests_with_cache("unit-tests", "fast")
    
>       assert tests == [os.path.join(tmp_path, "test_file.py")]
E       AssertionError: assert [] == ['/tmp/pytest...test_file.py']
E         
E         Right contains one more item: '/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_5/test_file.py'
E         Use -v to get more diff

/workspace/devsynth/tests/unit/testing/test_run_tests_logic.py:143: AssertionError
______________________________________ test_collect_tests_with_cache_invalidated_by_mtime ______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd542b40>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_6')

    @typed_freeze_time("2025-01-01")
    @pytest.mark.fast
    def test_collect_tests_with_cache_invalidated_by_mtime(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-COLL-4 — collect_tests_with_cache is invalidated by mtime."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        cache_dir = tmp_path / rt.COLLECTION_CACHE_DIR
        cache_dir.mkdir()
        cache_file = cache_dir / "unit-tests_fast_tests.json"
        cached_data = {
            "timestamp": "2025-01-01T00:00:00.000000",
            "tests": [os.path.join(str(tmp_path), "test_file.py")],
            "fingerprint": {
                "latest_mtime": 0.5,
                "category_expr": "fast and not memory_intensive",
                "test_path": str(tmp_path),
            },
        }
        with open(cache_file, "w") as f:
            json.dump(cached_data, f)
    
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
        with (
            patch.object(rt.os.path, "getmtime", return_value=1.0),
            patch.object(rt.subprocess, "run") as mock_run,
            patch.object(rt, "COLLECTION_CACHE_TTL_SECONDS", 999999),
        ):
            mock_run.return_value = SimpleNamespace(
                stdout=os.path.join(str(tmp_path), "new_test.py") + "\n",
                returncode=0,
                stderr="",
            )
            with freeze_time("2025-01-02"):
                tests = rt.collect_tests_with_cache("unit-tests", "fast")
    
>       assert tests == [os.path.join(tmp_path, "new_test.py")]
E       AssertionError: assert [] == ['/tmp/pytest.../new_test.py']
E         
E         Right contains one more item: '/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_6/new_test.py'
E         Use -v to get more diff

/workspace/devsynth/tests/unit/testing/test_run_tests_logic.py:183: AssertionError
_____________________________________ test_collect_tests_with_cache_invalidated_by_marker ______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd543530>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_7')

    @typed_freeze_time("2025-01-01")
    @pytest.mark.fast
    def test_collect_tests_with_cache_invalidated_by_marker(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-COLL-5 — collect_tests_with_cache is invalidated by marker."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        cache_dir = tmp_path / rt.COLLECTION_CACHE_DIR
        cache_dir.mkdir()
        cache_file = cache_dir / "unit-tests_fast_tests.json"
        cached_data = {
            "timestamp": "2025-01-01T00:00:00.000000",
            "tests": [os.path.join(str(tmp_path), "test_file.py")],
            "fingerprint": {
                "latest_mtime": 1.0,
                "category_expr": "fast and not memory_intensive",
                "test_path": str(tmp_path),
            },
        }
        with open(cache_file, "w") as f:
            json.dump(cached_data, f)
    
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
        with (
            patch.object(rt.os.path, "getmtime", return_value=1.0),
            patch.object(rt.subprocess, "run") as mock_run,
            patch.object(rt, "COLLECTION_CACHE_TTL_SECONDS", 999999),
        ):
            mock_run.return_value = SimpleNamespace(
                stdout=os.path.join(str(tmp_path), "new_test.py") + "\n",
                returncode=0,
                stderr="",
            )
            with freeze_time("2025-01-01"):
                tests = rt.collect_tests_with_cache("unit-tests", "slow")
    
>       assert tests == [os.path.join(tmp_path, "new_test.py")]
E       AssertionError: assert [] == ['/tmp/pytest.../new_test.py']
E         
E         Right contains one more item: '/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_7/new_test.py'
E         Use -v to get more diff

/workspace/devsynth/tests/unit/testing/test_run_tests_logic.py:223: AssertionError
______________________________________________ test_run_tests_verbose_and_report _______________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_verbose_and_rep0'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_verbose_and_re...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce192b0>

    @pytest.mark.fast
    def test_run_tests_verbose_and_report(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests with verbose and report flags."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_file = tmp_path / "test_example.py"
        test_file.write_text("def test_pass(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
        monkeypatch.setattr(
            rt, "_ensure_coverage_artifacts", lambda: None
        )  # Prevent actual artifact generation
        monkeypatch.setattr(
            rt, "enforce_coverage_threshold", lambda *args, **kwargs: 90.0
        )  # Mock coverage enforcement
        custom_env = {"PYTEST_DISABLE_PLUGIN_AUTOLOAD": "1"}  # Enable plugin injection
        success, output = rt.run_tests(
            target="unit-tests", verbose=True, report=True, env=custom_env
        )
    
        assert success is True
        assert len(mock_subprocess_popen) == 1
        cmd, env = mock_subprocess_popen[0]
        assert "-v" in cmd
        assert f"--cov={rt.COVERAGE_TARGET}" in cmd
        assert f"--cov-report=json:{rt.COVERAGE_JSON_PATH}" in cmd
        assert f"--cov-report=html:{rt.COVERAGE_HTML_DIR}" in cmd
        assert "--cov-append" in cmd
        assert "PYTEST_ADDOPTS" in env  # Should contain plugin injection
>       del os.environ["PYTEST_DISABLE_PLUGIN_AUTOLOAD"]  # Clean up env
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...E': '/tmp/pytest-of-root/pytest-1/test_run_tests_verbose_and_rep0/home/.local/share', 'DEVSYNTH_NO_FILE_LOGGING': '1'})
key = 'PYTEST_DISABLE_PLUGIN_AUTOLOAD'

>   ???
E   KeyError: 'PYTEST_DISABLE_PLUGIN_AUTOLOAD'

<frozen os>:730: KeyError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Skipping release graph publication: Coverage JSON missing at test_reports/coverage.json
________________________________________ test_run_tests_with_markers_and_keyword_filter ________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_with_markers_an0'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_with_markers_a...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcdf4140>

    @pytest.mark.fast
    def test_run_tests_with_markers_and_keyword_filter(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests with extra_marker and keyword_filter."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_file = tmp_path / "test_example.py"
        test_file.write_text("def test_pass(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
        success, output = rt.run_tests(
            target="unit-tests", extra_marker="slow", keyword_filter="example"
        )
    
        assert success is True
        assert len(mock_subprocess_popen) == 1
        cmd, env = mock_subprocess_popen[0]
        assert "-m" in cmd
>       assert "not memory_intensive and (slow)" in cmd
E       AssertionError: assert 'not memory_intensive and (slow)' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_with_markers_an0/test_example.py::test_pass', '-m', 'not memory_intensive and (fast or medium) and (slow) and not gui', ...]

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:257: AssertionError
_______________________________________ test_run_tests_collection_failure_returns_false ________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_collection_fail0'), mock_subprocess_run = []
mock_subprocess_popen = [], monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce1b290>

    @pytest.mark.fast
    def test_run_tests_collection_failure_returns_false(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests returns False on test collection failure."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
    
        def failing_collect(target, speed_category):
            raise RuntimeError("Collection failed")
    
        monkeypatch.setattr(rt, "collect_tests_with_cache", failing_collect)
    
        success, output = rt.run_tests(target="unit-tests")
    
        assert success is False
>       assert output == "Test collection failed"
E       AssertionError: assert 'Collection failed' == 'Test collection failed'
E         
E         - Test collection failed
E         ? ^^^^^^
E         + Collection failed
E         ? ^

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:341: AssertionError
_________________________________ test_run_tests_no_tests_collected_returns_true_with_message __________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_no_tests_collec0'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_no_tests_colle...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfc8290>

    @pytest.mark.fast
    def test_run_tests_no_tests_collected_returns_true_with_message(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests returns True and message when no tests are collected."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
    
        monkeypatch.setattr(
            rt, "collect_tests_with_cache", lambda target, speed_category: []
        )
    
        success, output = rt.run_tests(target="unit-tests")
    
        assert success is True
>       assert "No tests collected" in output
E       AssertionError: assert 'No tests collected' in 'Marker fallback executed.\n'

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:362: AssertionError
______________________________________________ test_run_tests_segmented_execution ______________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_execu1'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_exec...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfcaa50>

    @pytest.mark.fast
    def test_run_tests_segmented_execution(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests with segmented execution."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_a = tmp_path / "test_a.py"
        test_b = tmp_path / "test_b.py"
        test_c = tmp_path / "test_c.py"
        test_a.write_text("def test_a(): pass")
        test_b.write_text("def test_b(): pass")
        test_c.write_text("def test_c(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [
                f"{test_a}::test_a",
                f"{test_b}::test_b",
                f"{test_c}::test_c",
            ],
        )
    
        # Mock Popen to return success for all batches
        class FakePopenSuccess(rt.subprocess.Popen):
            def __init__(self, *args: Any, **kwargs: Any) -> None:
                # Append to the fixture's recorded_calls
                mock_subprocess_popen.append((args[0], kwargs.get("env", {})))
                super().__init__(*args, **kwargs)
                self.returncode = 0
                self._stdout = "ok"
                self._stderr = ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopenSuccess)
    
        success, output = rt.run_tests(target="unit-tests", segment=True, segment_size=1)
    
        assert success is True
>       assert len(mock_subprocess_popen) == 3  # Three batches
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert 6 == 3
E        +  where 6 = len([(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_exec...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})])

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:439: AssertionError
_______________________________________ test_run_tests_segmented_execution_with_failure ________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_execu2'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_exec...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6d8e30>

    @pytest.mark.fast
    def test_run_tests_segmented_execution_with_failure(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests with segmented execution where one batch fails."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_a = tmp_path / "test_a.py"
        test_b = tmp_path / "test_b.py"
        test_a.write_text("def test_a(): pass")
        test_b.write_text("def test_b(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [
                f"{test_a}::test_a",
                f"{test_b}::test_b",
            ],
        )
    
        # Mock Popen to simulate failure in the first batch
        class FakePopenMixed(rt.subprocess.Popen):
            call_count = 0
    
            def __init__(self, *args: Any, **kwargs: Any) -> None:
                # Append to the fixture's recorded_calls
                mock_subprocess_popen.append((args[0], kwargs.get("env", {})))
                super().__init__(*args, **kwargs)
                FakePopenMixed.call_count += 1
                if FakePopenMixed.call_count == 1:
                    self.returncode = 1  # Fail first batch
                    self._stdout = "fail"
                    self._stderr = "error"
                else:
                    self.returncode = 0
                    self._stdout = "ok"
                    self._stderr = ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopenMixed)
    
        success, output = rt.run_tests(target="unit-tests", segment=True, segment_size=1)
    
        assert success is False
        assert "Troubleshooting tips" in output  # Should include failure tips
>       assert len(mock_subprocess_popen) == 2  # Both batches should run
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert 4 == 2
E        +  where 4 = len([(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_exec...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})])

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:492: AssertionError
______________________________________________ test_run_tests_parallel_execution _______________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_parallel_execut0'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_parallel_execu...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd09a840>

    @pytest.mark.fast
    def test_run_tests_parallel_execution(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test run_tests with parallel execution."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_file = tmp_path / "test_example.py"
        test_file.write_text("def test_pass(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
        success, output = rt.run_tests(target="unit-tests", parallel=True)
    
        assert success is True
        assert len(mock_subprocess_popen) == 1
        cmd, env = mock_subprocess_popen[0]
>       assert "-n auto" in cmd  # Should add parallel flag
        ^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert '-n auto' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_parallel_execut0/test_example.py::test_pass', '-m', 'not memory_intensive and (fast or medium) and not gui', ...]

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:520: AssertionError
____________________________________ test_run_tests_parallel_execution_disabled_by_segment _____________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_parallel_execut1'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_parallel_execu...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd09a4e0>

    @pytest.mark.fast
    def test_run_tests_parallel_execution_disabled_by_segment(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test parallel execution is disabled when segment is True."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_file = tmp_path / "test_example.py"
        test_file.write_text("def test_pass(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
        success, output = rt.run_tests(target="unit-tests", parallel=True, segment=True)
    
        assert success is True
        assert len(mock_subprocess_popen) == 1  # Only one batch due to segment=True
        cmd, env = mock_subprocess_popen[0]
        assert "-n auto" not in cmd  # Parallel should be disabled
>       assert [f"{test_file}::test_pass"] == cmd[
            3:
        ]  # Check if node_ids are correctly passed
E       AssertionError: assert ['/tmp/pytest...y::test_pass'] == ['/tmp/pytest...htmlcov', ...]
E         
E         Right contains 8 more items, first extra item: '-m'
E         Use -v to get more diff

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:548: AssertionError
___________________________________________ test_run_tests_with_env_var_propagation ____________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_with_env_var_pr0'), mock_subprocess_run = []
mock_subprocess_popen = [], monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce06150>

    @pytest.mark.fast
    def test_run_tests_with_env_var_propagation(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        # Set some initial environment variables
        os.environ["EXISTING_VAR"] = "initial_value"
        os.environ["PYTEST_ADDOPTS"] = "-q"
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
        custom_env = {"NEW_VAR": "new_value", "PYTEST_ADDOPTS": "--strict-markers"}
    
>       success, output = rt.run_tests(target="unit-tests", env=custom_env)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:572: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1457: in run_tests
    nodes = collect_callable(target, category)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'unit-tests', speed_category = 'fast'

>       lambda target, speed_category: [f"{test_file}::test_pass"],
                                           ^^^^^^^^^
    )
E   NameError: name 'test_file' is not defined

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:567: NameError
_____________________________________ test_run_tests_with_empty_speed_categories_uses_all ______________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_with_empty_spee0'), mock_subprocess_run = []
mock_subprocess_popen = [], monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce05850>

    @pytest.mark.fast
    def test_run_tests_with_empty_speed_categories_uses_all(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
>       success, output = rt.run_tests(target="unit-tests", speed_categories=[])
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:617: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1457: in run_tests
    nodes = collect_callable(target, category)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'unit-tests', speed_category = 'fast'

>       lambda target, speed_category: [f"{test_file}::test_pass"],
                                           ^^^^^^^^^
    )
E   NameError: name 'test_file' is not defined

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:614: NameError
________________________________________ test_run_tests_with_specific_speed_categories _________________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_with_specific_s0'), mock_subprocess_run = []
mock_subprocess_popen = [(['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_with_specific_...8', 'COMPOSER_HOME': '/root/.local/share/mise/installs/php/8.4.12/.composer', 'COREPACK_DEFAULT_TO_LATEST': '0', ...})]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce05bb0>

    @pytest.mark.fast
    def test_run_tests_with_specific_speed_categories(
        tmp_path: Path,
        mock_subprocess_run: list[list[str]],
        mock_subprocess_popen: list[tuple[list[str], dict[str, str]]],
        monkeypatch: pytest.MonkeyPatch,
    ) -> None:
        """Test that specific speed_categories are correctly applied."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        test_file = tmp_path / "test_example.py"
        test_file.write_text("def test_pass(): pass")
    
        monkeypatch.setattr(
            rt,
            "collect_tests_with_cache",
            lambda target, speed_category: [f"{test_file}::test_pass"],
        )
    
        success, output = rt.run_tests(
            target="unit-tests", speed_categories=["fast", "medium"]
        )
    
        assert success is True
        assert len(mock_subprocess_popen) == 1
        cmd, env = mock_subprocess_popen[0]
        assert "-m" in cmd
>       assert "not memory_intensive and (fast or medium)" in cmd
E       AssertionError: assert 'not memory_intensive and (fast or medium)' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_with_specific_s0/test_example.py::test_pass', '-m', 'not memory_intensive and (fast or medium) and not gui', ...]

/workspace/devsynth/tests/unit/testing/test_run_tests_main_logic.py:654: AssertionError
__________________________________ test_collect_tests_with_cache_uses_cache_and_respects_ttl ___________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce07530>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_11')

    @pytest.mark.fast
    def test_collect_tests_with_cache_uses_cache_and_respects_ttl(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ):
        """ReqID: RTM-02 — collect_tests_with_cache caches and reuses results
        respecting TTL and fingerprint."""
        # Point TARGET_PATHS to tmp tests dir
        tests_dir = tmp_path / "tests" / "unit"
        tests_dir.mkdir(parents=True)
        (tests_dir / "test_sample.py").write_text("def test_ok():\n    assert True\n")
    
        # Monkeypatch TARGET_PATHS and subprocess to avoid invoking real pytest
        monkeypatch.setattr(
            rt, "TARGET_PATHS", {"unit-tests": str(tests_dir), "all-tests": str(tests_dir)}
        )
    
        class DummyProc:
            def __init__(self, out: str):
                self.stdout = out
                self.returncode = 0
    
        def fake_run(
            cmd: list[str], check: bool, capture_output: bool, text: bool
        ):  # type: ignore[override]
            assert "--collect-only" in cmd
            # emulate -q output: one per line
            return DummyProc(out=f"{tests_dir}/test_sample.py\n")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        # Speed None path
>       ids1 = rt.collect_tests_with_cache("unit-tests", speed_category=None)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_collect_tests_with_cache_uses_cache_and_respects_ttl.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________ test_run_tests_translates_args_and_handles_return_codes ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce06de0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_translates_args0')

    @pytest.mark.fast
    def test_run_tests_translates_args_and_handles_return_codes(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ):
        """ReqID: RTM-03 — run_tests translates args, treats code 0/5 as success,
        and omits -n when parallel=False."""
        # Arrange base to avoid plugin interactions and filesystem writes
        tests_dir = tmp_path / "tests"
        tests_dir.mkdir()
        (tests_dir / "test_x.py").write_text("def test_one():\n    assert True\n")
        monkeypatch.setattr(
            rt, "TARGET_PATHS", {"unit-tests": str(tests_dir), "all-tests": str(tests_dir)}
        )
    
        # Capture the command built for the run path (no speed_categories provided)
        captured = {"cmd": None, "env": None}
    
        class CollectResult:
            def __init__(self, out: str) -> None:
                self.stdout = out
                self.stderr = ""
                self.returncode = 0
    
        def fake_run(
            cmd: list[str],
            check: bool,
            capture_output: bool,
            text: bool,
        ) -> CollectResult:  # type: ignore[override]
            assert "--collect-only" in cmd
            return CollectResult(f"{tests_dir}/test_x.py::test_one\n")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        class P:
            def __init__(self, cmd: list[str], code: int, out: str = "ok\n", err: str = ""):
                self.args = cmd
                self._code = code
                self._out = out
                self._err = err
    
            def communicate(self, *_args: Any, **_kwargs: Any):
                return self._out, self._err
    
            @property
            def returncode(self) -> int:
                return self._code
    
            def __enter__(self) -> "P":
                return self
    
            def __exit__(
                self,
                _exc_type: Any,
                _exc: Any,
                _tb: Any,
            ) -> bool:
                return False
    
            def kill(self) -> None:  # pragma: no cover - subprocess.run compatibility
                pass
    
            def wait(self) -> int:  # pragma: no cover - subprocess.run compatibility
                return self._code
    
            def poll(self) -> int:  # pragma: no cover - subprocess.run compatibility
                return self._code
    
        def fake_popen(
            cmd: list[str],
            stdout,
            stderr,
            text: bool,
            env: dict[str, str] | None = None,
        ):  # type: ignore[override]
            captured["cmd"] = cmd
            captured["env"] = env
            # Succeed with code 0 first
            return P(cmd, 0)
    
        monkeypatch.setattr(rt.subprocess, "Popen", fake_popen)
    
>       ok, output = rt.run_tests(
            target="unit-tests", speed_categories=["fast"], parallel=False
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:174: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_translates_args_and_handles_return_codes.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________ test_run_tests_keyword_filter_for_extra_marker_lmstudio ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dce06d20>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_keyword_filter_0')

    @pytest.mark.fast
    def test_run_tests_keyword_filter_for_extra_marker_lmstudio(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ):
        """ReqID: RTM-04 — extra_marker 'requires_resource("lmstudio")' uses
        keyword filter and early success on no matches."""
        # Arrange: ensure keyword narrowing path is exercised with no matches ->
        # early success
        tests_dir = tmp_path / "tests"
        tests_dir.mkdir()
        monkeypatch.setattr(
            rt, "TARGET_PATHS", {"unit-tests": str(tests_dir), "all-tests": str(tests_dir)}
        )
    
        class Dummy:
            def __init__(self, stdout: str, returncode: int = 0):
                self.stdout = stdout
                self.returncode = returncode
    
        def fake_run(
            cmd, check: bool, capture_output: bool, text: bool
        ):  # type: ignore[override]
            # '--collect-only' path with '-k lmstudio' produces no items
            assert "--collect-only" in cmd
            return Dummy(stdout="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
>       ok, msg = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_keyword_filter_for_extra_marker_lmstudio.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________ test_run_tests_handles_popen_exception_without_speed_filters _________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd677a70>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_handles_popen_e0')

    @pytest.mark.fast
    def test_run_tests_handles_popen_exception_without_speed_filters(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RTM-05 — run_tests surfaces subprocess errors with guidance."""
    
        tests_dir = tmp_path / "tests"
        tests_dir.mkdir()
        monkeypatch.setattr(
            rt, "TARGET_PATHS", {"unit-tests": str(tests_dir), "all-tests": str(tests_dir)}
        )
    
        # ``run_tests`` should not perform collection when no speed categories are
        # provided. Guard against unexpected subprocess.run usage.
        def fail_run(*_args: Any, **_kwargs: Any) -> None:  # pragma: no cover - safety
            raise AssertionError("subprocess.run should not be invoked in this branch")
    
        monkeypatch.setattr(rt.subprocess, "run", fail_run)
    
        captured: dict[str, list[str]] = {}
    
        def boom_popen(
            cmd: list[str],
            stdout: Any = None,
            stderr: Any = None,
            text: bool = True,
            env: dict[str, str] | None = None,
        ) -> Any:  # pragma: no cover - behavior exercised via exception path
            captured["cmd"] = cmd
            raise RuntimeError("intentional popen failure")
    
        monkeypatch.setattr(rt.subprocess, "Popen", boom_popen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_args = (['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_run_tests_handles_popen_e0/tests', '--collect-only', '-q', ...],)
_kwargs = {'capture_output': True, 'text': True, 'timeout': 300.0}

    def fail_run(*_args: Any, **_kwargs: Any) -> None:  # pragma: no cover - safety
>       raise AssertionError("subprocess.run should not be invoked in this branch")
E       AssertionError: subprocess.run should not be invoked in this branch

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:260: AssertionError
_______________________________________ test_collect_unknown_target_uses_all_tests_path ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd675c10>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_unknown_target_us0')

    @pytest.mark.fast
    def test_collect_unknown_target_uses_all_tests_path(monkeypatch, tmp_path):
        """ReqID: RTM-06 — Unknown target falls back to all-tests mapping."""
    
        tests_dir = tmp_path / "some_tests"
        tests_dir.mkdir()
        cache_dir = tmp_path / "cache"
        cache_dir.mkdir()
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", str(cache_dir))
        monkeypatch.setattr(rt, "TARGET_PATHS", {"all-tests": str(tests_dir)})
    
        observed: list[list[str]] = []
    
        def fake_run(cmd, check=False, capture_output=False, text=False):  # noqa: ANN001
            observed.append(cmd[:])
            return SimpleNamespace(
                stdout="test_sample.py::test_ok\n",
                stderr="",
                returncode=0,
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        original_isdir = rt.os.path.isdir
    
        def fake_isdir(path: str) -> bool:
            if path == str(tests_dir):
                return False
            return original_isdir(path)
    
        monkeypatch.setattr(rt.os.path, "isdir", fake_isdir)
    
        original_exists = rt.os.path.exists
    
        def fake_exists(path: str) -> bool:
            if path == "test_sample.py":
                return True
            return original_exists(path)
    
        monkeypatch.setattr(rt.os.path, "exists", fake_exists)
    
>       result = rt.collect_tests_with_cache("custom-target", speed_category=None)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:338: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'custom-target', speed_category = None

    def collect_tests_with_cache(
        target: str,
        speed_category: str | None = None,
        *,
        keyword_filter: str | None = None,
        _allow_all_target_decomposition: bool = True,
        _timeout_override: float | None = None,
        _propagate_timeout: bool = False,
    ) -> list[str]:
        """Collect tests for the given target and speed category.
    
        Args:
            target: Logical test target such as ``unit-tests`` or ``all-tests``.
            speed_category: Optional speed marker used to scope collection.
            keyword_filter: Optional ``-k`` expression applied during collection.
    
        Returns:
            A list of pytest node identifiers matching the requested filters.
        """
        test_path = TARGET_PATHS.get(target, TARGET_PATHS["all-tests"])
    
        # Build the marker expression we'll use and compute a simple fingerprint of
        # the test tree (latest mtime) to detect changes that should invalidate cache.
        marker_expr = "not memory_intensive"
        category_expr = marker_expr
        if speed_category:
            category_expr = f"{speed_category} and {marker_expr}"
    
        normalized_filter = _normalize_keyword_filter(keyword_filter)
        latest_mtime = _latest_mtime(test_path)
        base_cache_key = f"{target}_{speed_category or 'all'}"
        suffix = _cache_key_suffix(normalized_filter)
        cache_key = f"{base_cache_key}_{suffix}" if suffix else base_cache_key
        cache_file = (
>           COLLECTION_CACHE_DIR / f"{cache_key}_tests.json"
        )  # Use Path object for cache_file
E       TypeError: unsupported operand type(s) for /: 'str' and 'str'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1179: TypeError
_______________________________________ test_run_tests_segment_appends_aggregation_tips ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd675880>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segment_appends0')

    @pytest.mark.fast
    def test_run_tests_segment_appends_aggregation_tips(
        monkeypatch: pytest.MonkeyPatch, tmp_path
    ) -> None:
        """ReqID: RTM-07 — Segmented failures append aggregate troubleshooting tips."""
    
        tests_dir = tmp_path / "segmented"
        tests_dir.mkdir()
        (tests_dir / "test_one.py").write_text("def test_one():\n    assert True\n")
        (tests_dir / "test_two.py").write_text("def test_two():\n    assert True\n")
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        class CollectProc:
            def __init__(self, out: str) -> None:
                self.stdout = out
                self.stderr = ""
                self.returncode = 0
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            stdout = "\n".join(["test_one.py::test_one", "test_two.py::test_two"])
            return CollectProc(stdout)
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        batch_calls: list[list[str]] = []
    
        class FakeBatchProcess:
            def __init__(
                self,
                cmd,
                stdout=None,
                stderr=None,
                text=False,
                env=None,
            ) -> None:  # noqa: ANN001
                batch_calls.append(cmd)
                self.args = cmd
                index = len(batch_calls) - 1
                if index == 0:
                    self._stdout = "batch-1\n"
                    self._stderr = ""
                    self._returncode = 0
                else:
                    self._stdout = "batch-2\n"
                    self._stderr = "boom"
                    self._returncode = 1
    
            def communicate(self):  # noqa: D401 - simple stub
                return self._stdout, self._stderr
    
            @property
            def returncode(self) -> int:
                return self._returncode
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakeBatchProcess)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_module.py:440: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_segment_appends_aggregation_tips.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
______________________________________ test_run_tests_completes_without_xdist_assertions _______________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_completes_witho0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd6758b0>

    @pytest.mark.fast
    def test_run_tests_completes_without_xdist_assertions(tmp_path, monkeypatch):
        """run_tests completes without INTERNALERROR when run in parallel. ReqID: FR-22"""
        test_file = tmp_path / "test_dummy.py"
        test_file.write_text(
            "import pytest\n\n@pytest.mark.fast\ndef test_ok():\n    assert True\n"
        )
        monkeypatch.setitem(TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(
                returncode=0,
                stdout=f"{test_file}::test_ok",
                stderr="",
            )
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                assert "-n" in cmd and "auto" in cmd
                self.returncode = 0
                self._stdout = "passed"
                self._stderr = ""
    
            def communicate(self):  # noqa: D401 - mimic subprocess API
                """Return deterministic stdout/stderr."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests("unit-tests", ["fast"], parallel=True)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/devsynth/tests/unit/testing/test_run_tests_no_xdist_assertions.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_completes_without_xdist_assertions.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_________________________________________ test_report_flag_adds_html_report_to_command _________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcdedd30>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_report_flag_adds_html_rep0')

    @pytest.mark.fast
    def test_report_flag_adds_html_report_to_command(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-ORCH-2 — report=True adds --html to the pytest command."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
    
        recorded_cmds: list[list[str]] = []
    
        class FakePopen:
            def __init__(self, cmd, *args, **kwargs):
                recorded_cmds.append(list(cmd))
                self.returncode = 0
    
            def communicate(self):
                return "ok", ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        with (
            patch.object(rt, "collect_tests_with_cache", return_value=["test_file.py"]),
            patch.object(rt, "datetime") as mock_dt,
        ):
            mock_dt.now.return_value.strftime.return_value = "20250101_000000"
            rt.run_tests(
                target="unit-tests",
                speed_categories=["fast"],
                verbose=False,
                report=True,
                parallel=False,
                segment=False,
                maxfail=None,
                extra_marker=None,
            )
    
        assert recorded_cmds, "run_tests should have invoked Popen"
        pytest_cmd = recorded_cmds[0]
>       assert any(arg.startswith("--html=") for arg in pytest_cmd)
E       assert False
E        +  where False = any(<generator object test_report_flag_adds_html_report_to_command.<locals>.<genexpr> at 0x7ff8dd8fe4d0>)

/workspace/devsynth/tests/unit/testing/test_run_tests_orchestration.py:101: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Skipping release graph publication: Coverage JSON missing at test_reports/coverage.json
___________________________________________ test_no_parallel_flag_adds_n0_to_command ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd172390>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_no_parallel_flag_adds_n0_0')

    @pytest.mark.fast
    def test_no_parallel_flag_adds_n0_to_command(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-ORCH-3 — parallel=False adds -n0 to the pytest command."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
    
        recorded_cmds: list[list[str]] = []
    
        class FakePopen:
            def __init__(self, cmd, *args, **kwargs):
                recorded_cmds.append(list(cmd))
                self.returncode = 0
    
            def communicate(self):
                return "ok", ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        with patch.object(rt, "collect_tests_with_cache", return_value=["test_file.py"]):
            rt.run_tests(
                target="unit-tests",
                speed_categories=["fast"],
                verbose=False,
                report=False,
                parallel=False,
                segment=False,
                maxfail=None,
                extra_marker=None,
            )
    
        assert recorded_cmds, "run_tests should have invoked Popen"
        pytest_cmd = recorded_cmds[0]
>       assert "-n0" in pytest_cmd
E       AssertionError: assert '-n0' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'test_file.py', '-m', 'not memory_intensive and fast and not gui', ...]

/workspace/devsynth/tests/unit/testing/test_run_tests_orchestration.py:138: AssertionError
__________________________________________ test_maxfail_flag_adds_maxfail_to_command ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05f9e0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_maxfail_flag_adds_maxfail0')

    @pytest.mark.fast
    def test_maxfail_flag_adds_maxfail_to_command(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-ORCH-4 — maxfail=N adds --maxfail=N to the pytest command."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
    
        recorded_cmds: list[list[str]] = []
    
        class FakePopen:
            def __init__(self, cmd, *args, **kwargs):
                recorded_cmds.append(list(cmd))
                self.returncode = 0
    
            def communicate(self):
                return "ok", ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        with patch.object(rt, "collect_tests_with_cache", return_value=["test_file.py"]):
            rt.run_tests(
                target="unit-tests",
                speed_categories=["fast"],
                verbose=False,
                report=False,
                parallel=False,
                segment=False,
                maxfail=5,
                extra_marker=None,
            )
    
        assert recorded_cmds, "run_tests should have invoked Popen"
        pytest_cmd = recorded_cmds[0]
>       assert "--maxfail=5" in pytest_cmd
E       AssertionError: assert '--maxfail=5' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'test_file.py', '-m', 'not memory_intensive and fast and not gui', ...]

/workspace/devsynth/tests/unit/testing/test_run_tests_orchestration.py:175: AssertionError
___________________________________________ test_segment_flags_trigger_segmented_run ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05e1b0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segment_flags_trigger_seg0')

    @pytest.mark.fast
    def test_segment_flags_trigger_segmented_run(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path
    ) -> None:
        """ReqID: RUN-TESTS-ORCH-5 — segment=True triggers a segmented run."""
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "test_file.py").write_text("def test_example(): pass")
    
        recorded_cmds: list[list[str]] = []
    
        class FakePopen:
            def __init__(self, cmd, *args, **kwargs):
                recorded_cmds.append(list(cmd))
                self.returncode = 0
    
            def communicate(self):
                return "ok", ""
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        with patch.object(rt.subprocess, "run") as mock_run:
            mock_run.return_value.stdout = "test_file.py\ntest_file2.py"
            mock_run.return_value.returncode = 0
            rt.run_tests(
                target="unit-tests",
                speed_categories=["fast"],
                verbose=False,
                report=False,
                parallel=False,
                segment=True,
                segment_size=1,
                maxfail=None,
                extra_marker=None,
            )
    
>       assert len(recorded_cmds) == 2, "Expected two Popen calls for a segmented run"
E       AssertionError: Expected two Popen calls for a segmented run
E       assert 1 == 2
E        +  where 1 = len([['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', '/tmp/pytest-of-root/pytest-1/test_segment_flags_trigger_seg0', '-m', 'not memory_intensive and fast and not gui', ...]])

/workspace/devsynth/tests/unit/testing/test_run_tests_orchestration.py:213: AssertionError
_______________________________________ test_run_tests_parallel_includes_cov_and_n_auto ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05dfd0>

    @pytest.mark.fast
    def test_run_tests_parallel_includes_cov_and_n_auto(monkeypatch):
        """ReqID: RUN-TESTS-PARALLEL-1
    
        When parallel=True and no explicit node ids are collected (single-pass branch),
        run_tests should include '-n auto' and explicit coverage instrumentation in the
        pytest command.
        """
    
        import devsynth.testing.run_tests as rt
    
        # We won't validate the collection step here; the single-pass branch does not
        # pre-collect node ids when speed_categories is None.
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                # Assert parallel-related flags are present
                assert "-n" in cmd and "auto" in cmd, f"parallel flags missing in: {cmd}"
                cov_flag = f"--cov={rt.COVERAGE_TARGET}"
                json_flag = f"--cov-report=json:{rt.COVERAGE_JSON_PATH}"
                html_flag = f"--cov-report=html:{rt.COVERAGE_HTML_DIR}"
                assert cov_flag in cmd, f"{cov_flag} missing in: {cmd}"
                assert json_flag in cmd, f"{json_flag} missing in: {cmd}"
                assert html_flag in cmd, f"{html_flag} missing in: {cmd}"
                assert "--cov-append" in cmd, f"--cov-append missing in: {cmd}"
                self.returncode = 0
    
            def communicate(self):
                return ("ok\n", "")
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,  # triggers non-collection single-pass branch
            verbose=False,
            report=False,
            parallel=True,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_parallel_flags.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
/root/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:548: in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.unit.testing.test_run_tests_parallel_flags.test_run_tests_parallel_includes_cov_and_n_auto.<locals>.FakePopen object at 0x7ff8dd098da0>
cmd = ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...], stdout = -1
stderr = -1, text = True, env = None

    def __init__(
        self, cmd, stdout=None, stderr=None, text=False, env=None
    ):  # noqa: ANN001
        # Assert parallel-related flags are present
>       assert "-n" in cmd and "auto" in cmd, f"parallel flags missing in: {cmd}"
E       AssertionError: parallel flags missing in: ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', '-o', 'addopts=', '-m', 'fast and not memory_intensive']
E       assert ('-n' in ['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...])

/workspace/devsynth/tests/unit/testing/test_run_tests_parallel_flags.py:25: AssertionError
_______________________________________ test_parallel_injects_cov_reports_and_xdist_auto _______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05d190>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_parallel_injects_cov_repo0')

    @pytest.mark.fast
    def test_parallel_injects_cov_reports_and_xdist_auto(monkeypatch, tmp_path: Path):
        """ReqID: TR-RT-11 — Parallel path injects -n auto with coverage reports.
    
        Verify that when parallel=True, run_tests injects xdist flags and preserves
        coverage instrumentation so JSON/HTML artifacts are generated.
        """
    
        called = {}
    
        class FakeCompleted:
            def __init__(self, stdout: str = "", stderr: str = "", returncode: int = 0):
                self.stdout = stdout
                self.stderr = stderr
                self.returncode = returncode
    
        test_a = tmp_path / "test_alpha.py"
        test_b = tmp_path / "test_beta.py"
        test_a.write_text("def test_one():\n    assert True\n")
        test_b.write_text("def test_two():\n    assert True\n")
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        monkeypatch.setitem(rt.TARGET_PATHS, "all-tests", str(tmp_path))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        def fake_run(
            cmd, check=False, capture_output=False, text=False
        ):  # type: ignore[no-untyped-def]
            # Simulate collection with two node ids; pattern
            # ".*\\.py(::|$)" will match them.
            stdout = "\n".join(
                [
                    f"{test_a}::test_one",
                    f"{test_b}::test_two",
                ]
            )
            return FakeCompleted(stdout=stdout, stderr="", returncode=0)
    
        # pragma: no cover - communicate() path is asserted via effects
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # type: ignore[no-untyped-def]
                called["cmd"] = cmd
                self.returncode = 0
    
            def communicate(self):  # type: ignore[no-untyped-def]
                return ("", "")
    
        # Patch subprocess in module under test
        monkeypatch.setattr("devsynth.testing.run_tests.subprocess.run", fake_run)
        monkeypatch.setattr("devsynth.testing.run_tests.subprocess.Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=True,
            segment=False,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_parallel_no_cov.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_parallel_injects_cov_reports_and_xdist_auto.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________ test_collect_tests_with_cache_handles_subprocess_timeout ___________________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_12')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfc8a10>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dd09a720>

    @pytest.mark.fast
    def test_collect_tests_with_cache_handles_subprocess_timeout(
        tmp_path: Path,
        monkeypatch: pytest.MonkeyPatch,
        caplog: pytest.LogCaptureFixture,
    ) -> None:
        """Timeouts during collection surface a warning and yield no tests."""
    
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", tmp_path / ".cache")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tmp_path))
        (tmp_path / "sample_test.py").write_text("def test_sample():\n    assert True\n")
    
        def fake_run(*_args: object, **_kwargs: object) -> subprocess.CompletedProcess[str]:
            raise subprocess.TimeoutExpired(
                cmd=["pytest"], timeout=rt.DEFAULT_COLLECTION_TIMEOUT_SECONDS
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        with caplog.at_level(logging.WARNING, logger="devsynth.testing.run_tests"):
            collected = rt.collect_tests_with_cache("unit-tests")
    
        assert collected == []
>       assert "Test collection failed" in caplog.text
E       AssertionError: assert 'Test collection failed' in 'WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=unit-tests (all); falling back to path\n'
E        +  where 'WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=unit-tests (all); falling back to path\n' = <_pytest.logging.LogCaptureFixture object at 0x7ff8dd09a720>.text

/workspace/devsynth/tests/unit/testing/test_run_tests_plugin_timeouts.py:35: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=unit-tests (all); falling back to path
________________________________________ test_pytest_plugins_registers_pytest_bdd_once _________________________________________

    @pytest.mark.fast
    def test_pytest_plugins_registers_pytest_bdd_once() -> None:
        """Ensure the centralized helper exports pytest-bdd exactly once."""
    
        import importlib
    
        registry = importlib.import_module("tests.pytest_plugin_registry")
        plugin_list = list(registry.PYTEST_PLUGINS)
    
>       assert plugin_list.count("pytest_bdd.plugin") == 1
E       AssertionError: assert 0 == 1
E        +  where 0 = <built-in method count of list object at 0x7ff8dd7fd800>('pytest_bdd.plugin')
E        +    where <built-in method count of list object at 0x7ff8dd7fd800> = [].count

/workspace/devsynth/tests/unit/testing/test_run_tests_pytest_plugins_bdd.py:107: AssertionError
___________________________________ test_run_tests_report_injects_html_args_and_creates_dir ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd4a9970>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_report_injects_0')

    @pytest.mark.fast
    def test_run_tests_report_injects_html_args_and_creates_dir(monkeypatch, tmp_path):
        """
        ReqID: TR-RT-12 — Report HTML generation and directory creation.
    
        Validate that when report=True, run_tests:
        - adds --html=<test_reports/.../target>/report.html and --self-contained-html
        - creates the report directory path
        - executes pytest with node ids (non-parallel path)
        """
    
        # Arrange a tmp tests dir and map unit-tests target to it
        tests_dir = tmp_path / "tests" / "unit"
        tests_dir.mkdir(parents=True)
        monkeypatch.chdir(tmp_path)
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
    
        # Collection returns a couple of node ids
        collected = [
            "tests/unit/test_alpha.py::test_a",
            "tests/unit/test_beta.py::test_b",
        ]
    
        def fake_run(cmd, check=False, capture_output=False, text=False):  # noqa: ANN001
            if "--collect-only" in cmd:
                return SimpleNamespace(stdout="\n".join(collected), stderr="", returncode=0)
            return SimpleNamespace(stdout="", stderr="", returncode=0)
    
        seen_cmds: list[list[str]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=True, env=None
            ):  # noqa: ANN001
                seen_cmds.append(cmd)
                self.returncode = 0
    
            def communicate(self):  # noqa: D401
                return ("", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        # Act
>       ok, output = rt.run_tests(
            target="unit-tests",
            speed_categories=[
                "fast"
            ],  # go through segmented-speed path without segmentation
            verbose=False,
            report=True,
            parallel=False,
            segment=False,
            segment_size=50,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_report.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_report_injects_html_args_and_creates_dir.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_____________________________________ test_single_pass_non_keyword_returncode_5_is_success _____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd4a93a0>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_single_pass_non_keyword_returncode_5_is_success(monkeypatch) -> None:
        """ReqID: TR-RT-10 — Return code 5 is success in single-pass non-keyword path.
    
        In the single-pass, non-keyword path (no speed_categories), pytest return
        code 5 (no tests collected) should be treated as success. This exercises
        the branch where we do not pre-collect node ids and simply pass a category
        expression to pytest via '-m'.
        """
    
        # Force the branch: speed_categories=None, no extra_marker or keyword filter,
        # parallel=False to avoid xdist flags.
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                # Ensure the '-m' category expression is present and no '-k' keyword filter
                assert "-m" in cmd, f"expected -m category expression in cmd: {cmd}"
                assert "-k" not in cmd, f"did not expect -k in cmd: {cmd}"
                # Simulate pytest exit code 5 (no tests collected)
                self.returncode = 5
    
            def communicate(self):
                return ("", "")
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=None,
            verbose=False,
            report=False,
            parallel=False,
            segment=False,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_returncode5_success.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: in _collect_via_pytest
    result = subprocess.run(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 300.0, check = False
popenargs = (['/workspace/devsynth/.venv/bin/python', '-m', 'pytest', 'tests/unit/', '--collect-only', '-q', ...],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout (seconds) is given and the process takes too long,
         a TimeoutExpired exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
>       with Popen(*popenargs, **kwargs) as process:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'FakePopen' object does not support the context manager protocol

/root/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:548: TypeError
_______________________________ test_segmented_batches_surface_plugin_fallbacks_and_failure_tips _______________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05da60>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segmented_batches_surface0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dcdee150>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_segmented_batches_surface_plugin_fallbacks_and_failure_tips(
        monkeypatch: pytest.MonkeyPatch, tmp_path: Path, caplog: pytest.LogCaptureFixture
    ) -> None:
        """ReqID: RUN-TESTS-SEGMENTATION-1 — Segmented failures emit rich diagnostics.
    
        This test simulates a segmented execution where the first batch fails with a
        coverage gate error. It verifies that fallback plugin injection occurs for the
        subprocess environment, coverage warnings propagate to stdout/stderr, and the
        aggregated failure guidance from :func:`_failure_tips` is appended exactly once.
        """
    
        caplog.set_level(logging.INFO)
    
        tests_dir = tmp_path / "segmented"
        tests_dir.mkdir()
        test_one = tests_dir / "test_one.py"
        test_two = tests_dir / "test_two.py"
        test_one.write_text("def test_one():\n    assert True\n")
        test_two.write_text("def test_two():\n    assert True\n")
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", str(tmp_path / "cache"))
    
        # Avoid mutating real coverage artifacts while exercising segmentation logic.
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        coverage_calls: list[str] = []
        monkeypatch.setattr(
            rt, "_ensure_coverage_artifacts", lambda: coverage_calls.append("ensured")
        )
    
        ensure_calls: list[tuple[str, bool, str]] = []
    
        def fake_cov(env: dict[str, str]) -> bool:
            ensure_calls.append(("cov", env is os.environ, env.get("PYTEST_ADDOPTS", "")))
            if env is os.environ:
                # Simulate a no-op at the process level so the subprocess copy applies the fix.
                return False
            env["PYTEST_ADDOPTS"] = (
                env.get("PYTEST_ADDOPTS", "") + " -p pytest_cov"
            ).strip()
            return True
    
        def fake_bdd(env: dict[str, str]) -> bool:
            ensure_calls.append(("bdd", env is os.environ, env.get("PYTEST_ADDOPTS", "")))
            if env is os.environ:
                return False
            env["PYTEST_ADDOPTS"] = (
                env.get("PYTEST_ADDOPTS", "") + " -p pytest_bdd.plugin"
            ).strip()
            return True
    
        monkeypatch.setattr(rt, "ensure_pytest_cov_plugin_env", fake_cov)
        monkeypatch.setattr(rt, "ensure_pytest_bdd_plugin_env", fake_bdd)
    
        collect_output = "\n".join(
            [
                f"{test_one}::test_one",
                f"{test_two}::test_two",
            ]
        )
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd, "collection command expected"
            return SimpleNamespace(returncode=0, stdout=collect_output, stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        batch_plan = iter(
            [
                {
                    "returncode": 1,
                    "stdout": "batch-one\n",
                    "stderr": "FAIL Required test coverage of 90% not reached.\n",
                },
                {
                    "returncode": 0,
                    "stdout": "batch-two\n",
                    "stderr": "",
                },
            ]
        )
        popen_calls: list[dict[str, object]] = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                popen_calls.append({"cmd": list(cmd), "env": dict(env or {})})
                try:
                    result = next(batch_plan)
                except StopIteration as exc:  # pragma: no cover - guards test integrity
                    raise AssertionError("Unexpected extra Popen invocation") from exc
                self.returncode = result["returncode"]
                self._stdout = result["stdout"]
                self._stderr = result["stderr"]
    
            def communicate(self):  # noqa: D401 - signature mirrors subprocess API
                """Return the stubbed stdout/stderr pair."""
    
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmentation.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

target = 'unit-tests', speed_category = 'fast'

    def collect_tests_with_cache(
        target: str,
        speed_category: str | None = None,
        *,
        keyword_filter: str | None = None,
        _allow_all_target_decomposition: bool = True,
        _timeout_override: float | None = None,
        _propagate_timeout: bool = False,
    ) -> list[str]:
        """Collect tests for the given target and speed category.
    
        Args:
            target: Logical test target such as ``unit-tests`` or ``all-tests``.
            speed_category: Optional speed marker used to scope collection.
            keyword_filter: Optional ``-k`` expression applied during collection.
    
        Returns:
            A list of pytest node identifiers matching the requested filters.
        """
        test_path = TARGET_PATHS.get(target, TARGET_PATHS["all-tests"])
    
        # Build the marker expression we'll use and compute a simple fingerprint of
        # the test tree (latest mtime) to detect changes that should invalidate cache.
        marker_expr = "not memory_intensive"
        category_expr = marker_expr
        if speed_category:
            category_expr = f"{speed_category} and {marker_expr}"
    
        normalized_filter = _normalize_keyword_filter(keyword_filter)
        latest_mtime = _latest_mtime(test_path)
        base_cache_key = f"{target}_{speed_category or 'all'}"
        suffix = _cache_key_suffix(normalized_filter)
        cache_key = f"{base_cache_key}_{suffix}" if suffix else base_cache_key
        cache_file = (
>           COLLECTION_CACHE_DIR / f"{cache_key}_tests.json"
        )  # Use Path object for cache_file
E       TypeError: unsupported operand type(s) for /: 'str' and 'str'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1179: TypeError
____________________________ test_collect_tests_with_cache_timeout_falls_back_to_direct_collection _____________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_collect_tests_with_cache_15')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05e120>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dcdedfa0>

    @pytest.mark.fast
    def test_collect_tests_with_cache_timeout_falls_back_to_direct_collection(
        tmp_path: Path, monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture
    ) -> None:
        """ReqID: RUN-TESTS-SEG-7 — retries smaller batches before broad fallback."""
    
        cache_dir = tmp_path / ".cache"
        monkeypatch.setattr(rt, "COLLECTION_CACHE_DIR", cache_dir)
        monkeypatch.setattr(
            rt, "TEST_COLLECTION_CACHE_FILE", cache_dir / "collection_cache.json"
        )
    
        tests_root = tmp_path / "tests"
        unit_dir = tests_root / "unit"
        integration_dir = tests_root / "integration"
        behavior_dir = tests_root / "behavior"
        for path in (unit_dir, integration_dir, behavior_dir):
            path.mkdir(parents=True)
            (path / "test_example.py").write_text(
                "def test_ok():\n    pass\n", encoding="utf-8"
            )
    
        monkeypatch.setattr(
            rt,
            "TARGET_PATHS",
            {
                "unit-tests": str(unit_dir),
                "integration-tests": str(integration_dir),
                "behavior-tests": str(behavior_dir),
                "all-tests": str(tests_root),
            },
        )
    
        calls: list[str] = []
    
        class DummyProcess:
            def __init__(self, stdout: str) -> None:
                self.stdout = stdout
                self.stderr = ""
                self.returncode = 0
    
        fallback_output = (
            "tests/unit/test_example.py::test_ok\n"
            "tests/integration/test_example.py::test_ok\n"
            "tests/behavior/test_example.py::test_ok\n"
        )
    
        timeout_targets = {str(unit_dir), str(integration_dir), str(behavior_dir)}
    
        def fake_run(cmd, capture_output, text, timeout):  # type: ignore[no-untyped-def]
            test_path = cmd[3]
            calls.append(test_path)
            if test_path in timeout_targets:
                raise subprocess.TimeoutExpired(cmd, timeout)
            if test_path == str(tests_root):
                return DummyProcess(fallback_output)
            raise AssertionError(f"Unexpected test path {test_path}")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        caplog.set_level(logging.INFO)
    
        result = rt.collect_tests_with_cache("all-tests", "fast")
    
        assert result == [
            "tests/unit/test_example.py::test_ok",
            "tests/integration/test_example.py::test_ok",
            "tests/behavior/test_example.py::test_ok",
        ]
        assert calls[-1] == str(tests_root)
>       assert any(
            getattr(record, "event", "") == "test_collection_timeout_retry"
            for record in caplog.records
        )
E       assert False
E        +  where False = any(<generator object test_collect_tests_with_cache_timeout_falls_back_to_direct_collection.<locals>.<genexpr> at 0x7ff8deae0ac0>)

/workspace/devsynth/tests/unit/testing/test_run_tests_segmentation_helpers.py:401: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     devsynth.testing.run_tests:logging_setup.py:600 test collection cache miss for target=all-tests (fast) — decomposing all-tests into dependent targets
INFO     devsynth.testing.run_tests:logging_setup.py:600 test collection cache miss for target=unit-tests (fast) — collecting via pytest
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=unit-tests (fast); falling back to path
INFO     devsynth.testing.run_tests:logging_setup.py:600 test collection cache miss for target=integration-tests (fast) — collecting via pytest
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=integration-tests (fast); falling back to path
INFO     devsynth.testing.run_tests:logging_setup.py:600 test collection cache miss for target=behavior-tests (fast) — collecting via pytest
WARNING  devsynth.testing.run_tests:logging_setup.py:600 Test collection timeout for target=behavior-tests (fast); falling back to path
___________________________________________ test_run_tests_segmented_batches_execute ___________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd171a60>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_run_tests_segmented_batches_execute(monkeypatch):
        """ReqID: RUN-TESTS-SEGMENTED-1
    
        Cover the segmented execution branch: when speed_categories are provided and
        segment=True, run_tests should execute tests in batches via Popen.
        """
        # Simulate collection of two node IDs for a given speed category
        collected_ids = (
            "tests/unit/module_a_test.py::test_a1\n"
            "tests/unit/module_b_test.py::test_b1\n"
        )
    
        import devsynth.testing.run_tests as rt
    
        # Fake subprocess.run to return our collected node ids
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            # Ensure --collect-only was requested for the marker-based collection
            assert "--collect-only" in cmd and "-q" in cmd
            return SimpleNamespace(returncode=0, stdout=collected_ids, stderr="")
    
        # Counter to verify batches executed
        calls = []
    
        class FakePopen:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                # The command should contain exactly one node id per batch
                node_args = [c for c in cmd if c.startswith("tests/") and "::" in c]
                assert (
                    len(node_args) == 1
                ), f"expected single test node id per batch, got: {node_args}"
                calls.append(node_args[0])
                self.returncode = 0
    
            def communicate(self):
                return ("ok\n", "")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,  # force 1 test per batch
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_segmented_batches_execute.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
________________________________________ test_run_tests_segmented_honors_keyword_filter ________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dd05f560>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_honor0')

    @pytest.mark.fast
    def test_run_tests_segmented_honors_keyword_filter(monkeypatch, tmp_path):
        """ReqID: RUN-TESTS-SEGMENTED-2 — Keyword filter applies during segmented runs."""
    
        tests_dir = tmp_path / "keyword"
        tests_dir.mkdir()
        (tests_dir / "test_one.py").write_text("def test_one():\n    assert True\n")
        (tests_dir / "test_two.py").write_text("def test_two():\n    assert True\n")
    
        import devsynth.testing.run_tests as rt
    
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
    
        collect_calls: list[list[str]] = []
    
        class FakeCollectProc:
            def __init__(self, stdout: str) -> None:
                self.stdout = stdout
                self.stderr = ""
                self.returncode = 0
    
        def fake_run(cmd, check=False, capture_output=True, text=True):
            collect_calls.append(cmd[:])
            assert "-k" in cmd, "keyword filter should be applied during collection"
            return FakeCollectProc(
                "\n".join(["test_one.py::test_one", "test_two.py::test_two"])
            )
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
    
        batch_cmds: list[list[str]] = []
    
        class FakeBatchProcess:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                batch_cmds.append(cmd[:])
                self.returncode = 0
                self._stdout = "ok\n"
                self._stderr = ""
    
            def communicate(self):
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakeBatchProcess)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker="requires_resource('lmstudio')",
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_segmented_honors_keyword_filter.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
______________________________________ test_segmented_failure_appends_aggregate_tips_once ______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfd3650>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_segmented_failure_appends0')

    @pytest.mark.fast
    def test_segmented_failure_appends_aggregate_tips_once(monkeypatch, tmp_path):
        """
        ReqID: RT-11 — Aggregated troubleshooting tips appended once after segments.
        """
        # Arrange a fake tests directory and map unit-tests to it
        tests_dir = tmp_path / "tests" / "unit"
        tests_dir.mkdir(parents=True)
        monkeypatch.chdir(tmp_path)
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
    
        # Collected node ids => 2 batches with size=2
        collected = [
            "tests/unit/test_a.py::test_1",
            "tests/unit/test_a.py::test_2",
            "tests/unit/test_b.py::test_3",
            "tests/unit/test_b.py::test_4",
        ]
    
        def fake_run(cmd, check=False, capture_output=False, text=False):
            if "--collect-only" in cmd:
                return _DummyCompleted(stdout="\n".join(collected), stderr="", returncode=0)
            return _DummyCompleted(stdout="", stderr="", returncode=0)
    
        # First batch fails (rc=1), second succeeds (rc=0)
        dummy_popen = _DummyPopen(rc_sequence=[1, 0])
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", dummy_popen)
    
        # Act
>       ok, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=2,
            maxfail=1,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented_aggregate_fail_tips_once.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_failure_appends_aggregate_tips_once.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
____________________________________ test_segmented_aggregate_tips_command_includes_maxfail ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dead6cf0>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_segmented_aggregate_tips_command_includes_maxfail(monkeypatch) -> None:
        """
        ReqID: RT-11 — When segmented mode runs and any batch fails, the aggregated
        troubleshooting tips are generated using a command that includes --maxfail
        if maxfail was provided.
        """
    
        collected_ids = "tests/unit/sample_test.py::test_a\n"
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            # collection phase returns one node id (ensures one batch)
            return SimpleNamespace(returncode=0, stdout=collected_ids, stderr="")
    
        class FailingBatch:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                # Simulate a failing batch
                self.returncode = 1
    
            def communicate(self) -> tuple[str, str]:
                return ("", "boom")
    
        captured = {}
    
        def fake_failure_tips(returncode, cmd):  # noqa: ANN001
            # Capture the command used to generate tips for later assertion
            captured["cmd"] = cmd
            return "\nTroubleshooting tips: ...\n"
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", FailingBatch)
        monkeypatch.setattr(rt, "_failure_tips", fake_failure_tips)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=5,
            maxfail=2,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented_aggregate_maxfail.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segmented_aggregate_tips_command_includes_maxfail.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________ test_run_tests_segmented_falls_back_on_empty_collection ____________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfd2a80>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-1/test_run_tests_segmented_falls0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8dd7311f0>

    @pytest.mark.fast
    def test_run_tests_segmented_falls_back_on_empty_collection(
        monkeypatch: pytest.MonkeyPatch,
        tmp_path: Path,
        caplog: pytest.LogCaptureFixture,
    ) -> None:
        """ReqID: RUN-TESTS-SEGMENTED-5 — Fallback run executes when no node ids exist."""
    
        tests_dir = tmp_path / "segmented-empty"
        tests_dir.mkdir()
        monkeypatch.setitem(rt.TARGET_PATHS, "unit-tests", str(tests_dir))
        monkeypatch.setattr(rt, "_reset_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "_ensure_coverage_artifacts", lambda: None)
        monkeypatch.setattr(rt, "ensure_pytest_cov_plugin_env", lambda _env: False)
        monkeypatch.setattr(rt, "ensure_pytest_bdd_plugin_env", lambda _env: False)
    
        def fake_collect(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd
            return SimpleNamespace(returncode=0, stdout="", stderr="")
    
        monkeypatch.setattr(rt.subprocess, "run", fake_collect)
    
        popen_calls: list[list[str]] = []
    
        class FakePopen:
            def __init__(
                self,
                cmd,
                stdout=None,
                stderr=None,
                text=True,
                env=None,
            ):  # noqa: ANN001
                popen_calls.append(cmd[:])
                self.returncode = 0
                self._stdout = "ok\n"
                self._stderr = ""
    
            def communicate(self):  # noqa: D401 - simple stub
                return self._stdout, self._stderr
    
        monkeypatch.setattr(rt.subprocess, "Popen", FakePopen)
    
        caplog.set_level(logging.WARNING)
    
>       success, output = rt.run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=10,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented_empty_node_ids.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_run_tests_segmented_falls_back_on_empty_collection.<locals>.fake_collect() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
___________________________________________ test_segment_batch_failure_appends_tips ____________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfd3c80>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_segment_batch_failure_appends_tips(monkeypatch) -> None:
        """ReqID: RT-08 — segmented batch failure appends troubleshooting tips and fails."""
    
        collected_ids = (
            "tests/unit/mod_x_test.py::test_x1\n" "tests/unit/mod_y_test.py::test_y1\n"
        )
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            assert "--collect-only" in cmd and "-q" in cmd
            return SimpleNamespace(returncode=0, stdout=collected_ids, stderr="")
    
        class FailingBatch:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                self._stderr = "boom"  # no benchmark warning
                self.returncode = 1
    
            def communicate(self) -> tuple[str, str]:
                return ("", self._stderr)
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", FailingBatch)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented_failure_paths.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segment_batch_failure_appends_tips.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
_____________________________________ test_segment_batch_benchmark_warning_forces_success ______________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8dcfd3fe0>

    @pytest.mark.fast
    @pytest.mark.requires_resource("codebase")
    def test_segment_batch_benchmark_warning_forces_success(monkeypatch) -> None:
        """ReqID: RT-09 — PytestBenchmarkWarning in stderr forces success for the batch."""
    
        collected_ids = (
            "tests/unit/mod_x_test.py::test_x1\n" "tests/unit/mod_y_test.py::test_y1\n"
        )
    
        def fake_run(cmd, check=False, capture_output=True, text=True):  # noqa: ANN001
            return SimpleNamespace(returncode=0, stdout=collected_ids, stderr="")
    
        class WarnBatch:
            def __init__(
                self, cmd, stdout=None, stderr=None, text=False, env=None
            ):  # noqa: ANN001
                self._stderr = "PytestBenchmarkWarning: calibration"
                self.returncode = 1  # would fail without the special-case handling
    
            def communicate(self) -> tuple[str, str]:
                return ("ok\n", self._stderr)
    
        monkeypatch.setattr(rt.subprocess, "run", fake_run)
        monkeypatch.setattr(rt.subprocess, "Popen", WarnBatch)
    
>       success, output = run_tests(
            target="unit-tests",
            speed_categories=["fast"],
            verbose=False,
            report=False,
            parallel=False,
            segment=True,
            segment_size=1,
            maxfail=None,
            extra_marker=None,
        )

/workspace/devsynth/tests/unit/testing/test_run_tests_segmented_failure_paths.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/devsynth/src/devsynth/testing/run_tests.py:1451: in run_tests
    nodes = collect_callable(
/workspace/devsynth/src/devsynth/testing/run_tests.py:1274: in collect_tests_with_cache
    node_ids = _collect_via_pytest(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _collect_via_pytest(
        *,
        target: str,
        test_path: str,
        category_expr: str,
        normalized_filter: str | None,
        timeout_seconds: float,
    ) -> list[str]:
        """Execute ``pytest --collect-only`` and return node identifiers."""
    
        collect_cmd = [
            sys.executable,
            "-m",
            "pytest",
            test_path,
            "--collect-only",
            "-q",
            "-o",
            "addopts=",
            "-m",
            category_expr,
        ]
    
        if normalized_filter:
            collect_cmd.extend(["-k", normalized_filter])
    
>       result = subprocess.run(
            collect_cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
E       TypeError: test_segment_batch_benchmark_warning_forces_success.<locals>.fake_run() got an unexpected keyword argument 'timeout'

/workspace/devsynth/src/devsynth/testing/run_tests.py:1080: TypeError
======================================================= warnings summary =======================================================
.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1290
  /workspace/devsynth/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio
    self._mark_plugins_for_rewrite(hook, disable_autoload)

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:833
  /workspace/devsynth/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:833: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; tests.fixtures.optional_deps
    self.import_plugin(import_spec)

tests/unit/testing/test_run_tests_cli_invocation.py::test_run_tests_generates_artifacts_for_normal_profile
tests/unit/testing/test_run_tests_cli_invocation.py::test_run_tests_generates_artifacts_with_autoload_disabled
  /workspace/devsynth/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:145: FutureWarning: 
  The default value will be `edges="edges" in NetworkX 3.6.
  
  To make this warning go away, explicitly set the edges kwarg, e.g.:
  
    nx.node_link_data(G, edges="links") to preserve current behavior, or
    nx.node_link_data(G, edges="edges") for forward compatibility.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================================= Test Categorization Summary ==================================================
Test Type Distribution:
  Unit Tests: 199
  Integration Tests: 0
  Behavior Tests: 0

Test Speed Distribution:
  Fast Tests (< 1s): 199
  Medium Tests (1-5s): 0
  Slow Tests (> 5s): 0
===================================================== Top 10 Slowest Tests =====================================================
1. tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_uses_cache: 0.41s
2. tests/unit/testing/test_run_tests_additional_coverage.py::test_collect_tests_with_cache_handles_timeout: 0.14s
3. tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_with_env_var_propagation: 0.13s
4. tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_marker_expression_includes_extra_marker: 0.11s
5. tests/unit/testing/test_run_tests_additional_coverage.py::test_ensure_pytest_cov_plugin_env_injects_and_skips: 0.09s
6. tests/unit/testing/test_run_tests_extra.py::test_failure_tips_appended_on_nonzero_return: 0.09s
7. tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_keyword_filter_returns_success_when_no_matches: 0.08s
8. tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_segment_failure_emits_aggregate_tips: 0.08s
9. tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_marker_filters_merge_extra_marker: 0.07s
10. tests/unit/testing/test_run_tests_parallel_flags.py::test_run_tests_parallel_includes_cov_and_n_auto: 0.07s
=================================================== short test summary info ====================================================
FAILED tests/unit/testing/test_run_tests_additional_coverage.py::test_collect_tests_with_cache_handles_timeout - TypeError: t...
FAILED tests/unit/testing/test_run_tests_additional_error_paths.py::test_collect_tests_with_cache_handles_subprocess_exception
FAILED tests/unit/testing/test_run_tests_additional_error_paths.py::test_run_tests_handles_unexpected_execution_error - Asser...
FAILED tests/unit/testing/test_run_tests_additional_error_paths.py::test_run_tests_segment_merges_extra_marker - TypeError: t...
FAILED tests/unit/testing/test_run_tests_artifacts.py::test_coverage_artifacts_status_detects_empty_html - AssertionError: as...
FAILED tests/unit/testing/test_run_tests_artifacts.py::test_failure_tips_includes_command_context - AssertionError: assert 'R...
FAILED tests/unit/testing/test_run_tests_benchmark_warning.py::test_segmented_run_treats_benchmark_warning_as_success - TypeE...
FAILED tests/unit/testing/test_run_tests_cache_prune_and_tips.py::test_collect_tests_with_cache_prunes_nonexistent_and_caches
FAILED tests/unit/testing/test_run_tests_cache_pruning.py::test_prunes_nonexistent_paths_and_uses_cache - TypeError: test_pru...
FAILED tests/unit/testing/test_run_tests_cli_helpers_focus.py::test_segmented_batches_inject_plugins_and_emit_tips - TypeErro...
FAILED tests/unit/testing/test_run_tests_cli_helpers_focus.py::test_segmented_batch_exception_emits_tips_and_plugins - TypeEr...
FAILED tests/unit/testing/test_run_tests_cli_helpers_focus.py::test_segmented_batches_reinject_when_env_mutates - TypeError: ...
FAILED tests/unit/testing/test_run_tests_cli_helpers_focus.py::test_run_tests_env_var_propagation_retains_existing_addopts - ...
FAILED tests/unit/testing/test_run_tests_cli_helpers_focus.py::test_run_tests_option_wiring_includes_expected_flags - TypeErr...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_marker_expression_includes_extra_marker - TypeError: 'Du...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_failure_surfaces_actionable_tips - AssertionError: asser...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_segment_batches_follow_segment_size - TypeError: test_cl...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_segment_failure_emits_aggregate_tips - TypeError: test_c...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_keyword_filter_handles_resource_marker - TypeError: test...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_marker_filters_merge_extra_marker - TypeError: test_cli_...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_report_mode_adds_html_argument - TypeError: test_cli_rep...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_env_passthrough_and_coverage_lifecycle - TypeError: test...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_cli_keyword_filter_returns_success_when_no_matches - TypeErr...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_run_tests_generates_artifacts_for_normal_profile - Assertion...
FAILED tests/unit/testing/test_run_tests_cli_invocation.py::test_run_tests_generates_artifacts_with_autoload_disabled - Asser...
FAILED tests/unit/testing/test_run_tests_extra.py::test_keyword_filter_no_matches_returns_success - TypeError: test_keyword_f...
FAILED tests/unit/testing/test_run_tests_extra.py::test_failure_tips_appended_on_nonzero_return - TypeError: 'DummyProc' obje...
FAILED tests/unit/testing/test_run_tests_extra_marker.py::test_keyword_filter_lmstudio_no_matches_returns_success - TypeError...
FAILED tests/unit/testing/test_run_tests_extra_marker.py::test_extra_marker_merges_into_m_expression - TypeError: test_extra_...
FAILED tests/unit/testing/test_run_tests_extra_marker_passthrough.py::test_run_tests_merges_extra_marker_into_category_expression
FAILED tests/unit/testing/test_run_tests_extra_paths.py::test_collect_fallback_on_behavior_speed_no_tests - TypeError: unsupp...
FAILED tests/unit/testing/test_run_tests_extra_paths.py::test_collect_malformed_cache_regenerates - TypeError: unsupported op...
FAILED tests/unit/testing/test_run_tests_extra_paths.py::test_run_tests_lmstudio_extra_marker_keyword_early_success - TypeErr...
FAILED tests/unit/testing/test_run_tests_failure_tips.py::test_failure_tips_include_common_flags - TypeError: test_failure_ti...
FAILED tests/unit/testing/test_run_tests_keyword_exec.py::test_keyword_marker_executes_matching_node_ids - TypeError: test_ke...
FAILED tests/unit/testing/test_run_tests_keyword_filter.py::test_keyword_filter_no_matches_returns_success_message - TypeErro...
FAILED tests/unit/testing/test_run_tests_keyword_filter.py::test_keyword_filter_honors_report_flag_and_creates_report_dir - T...
FAILED tests/unit/testing/test_run_tests_keyword_filter_empty.py::test_run_tests_lmstudio_keyword_filter_with_no_matches_returns_success
FAILED tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_uses_cache - RuntimeError: Test collection f...
FAILED tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_regenerates_when_expired - AssertionError: a...
FAILED tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_miss - AssertionError: assert [] == ['/tmp/p...
FAILED tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_invalidated_by_mtime - AssertionError: asser...
FAILED tests/unit/testing/test_run_tests_logic.py::test_collect_tests_with_cache_invalidated_by_marker - AssertionError: asse...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_verbose_and_report - KeyError: 'PYTEST_DISABLE_PLUGIN_...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_with_markers_and_keyword_filter - AssertionError: asse...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_collection_failure_returns_false - AssertionError: ass...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_no_tests_collected_returns_true_with_message - Asserti...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_segmented_execution - AssertionError: assert 6 == 3
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_segmented_execution_with_failure - AssertionError: ass...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_parallel_execution - AssertionError: assert '-n auto' ...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_parallel_execution_disabled_by_segment - AssertionErro...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_with_env_var_propagation - NameError: name 'test_file'...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_with_empty_speed_categories_uses_all - NameError: name...
FAILED tests/unit/testing/test_run_tests_main_logic.py::test_run_tests_with_specific_speed_categories - AssertionError: asser...
FAILED tests/unit/testing/test_run_tests_module.py::test_collect_tests_with_cache_uses_cache_and_respects_ttl - TypeError: te...
FAILED tests/unit/testing/test_run_tests_module.py::test_run_tests_translates_args_and_handles_return_codes - TypeError: test...
FAILED tests/unit/testing/test_run_tests_module.py::test_run_tests_keyword_filter_for_extra_marker_lmstudio - TypeError: test...
FAILED tests/unit/testing/test_run_tests_module.py::test_run_tests_handles_popen_exception_without_speed_filters - AssertionE...
FAILED tests/unit/testing/test_run_tests_module.py::test_collect_unknown_target_uses_all_tests_path - TypeError: unsupported ...
FAILED tests/unit/testing/test_run_tests_module.py::test_run_tests_segment_appends_aggregation_tips - TypeError: test_run_tes...
FAILED tests/unit/testing/test_run_tests_no_xdist_assertions.py::test_run_tests_completes_without_xdist_assertions - TypeErro...
FAILED tests/unit/testing/test_run_tests_orchestration.py::test_report_flag_adds_html_report_to_command - assert False
FAILED tests/unit/testing/test_run_tests_orchestration.py::test_no_parallel_flag_adds_n0_to_command - AssertionError: assert ...
FAILED tests/unit/testing/test_run_tests_orchestration.py::test_maxfail_flag_adds_maxfail_to_command - AssertionError: assert...
FAILED tests/unit/testing/test_run_tests_orchestration.py::test_segment_flags_trigger_segmented_run - AssertionError: Expecte...
FAILED tests/unit/testing/test_run_tests_parallel_flags.py::test_run_tests_parallel_includes_cov_and_n_auto - AssertionError:...
FAILED tests/unit/testing/test_run_tests_parallel_no_cov.py::test_parallel_injects_cov_reports_and_xdist_auto - TypeError: te...
FAILED tests/unit/testing/test_run_tests_plugin_timeouts.py::test_collect_tests_with_cache_handles_subprocess_timeout - Asser...
FAILED tests/unit/testing/test_run_tests_pytest_plugins_bdd.py::test_pytest_plugins_registers_pytest_bdd_once - AssertionErro...
FAILED tests/unit/testing/test_run_tests_report.py::test_run_tests_report_injects_html_args_and_creates_dir - TypeError: test...
FAILED tests/unit/testing/test_run_tests_returncode5_success.py::test_single_pass_non_keyword_returncode_5_is_success - TypeE...
FAILED tests/unit/testing/test_run_tests_segmentation.py::test_segmented_batches_surface_plugin_fallbacks_and_failure_tips - ...
FAILED tests/unit/testing/test_run_tests_segmentation_helpers.py::test_collect_tests_with_cache_timeout_falls_back_to_direct_collection
FAILED tests/unit/testing/test_run_tests_segmented.py::test_run_tests_segmented_batches_execute - TypeError: test_run_tests_s...
FAILED tests/unit/testing/test_run_tests_segmented.py::test_run_tests_segmented_honors_keyword_filter - TypeError: test_run_t...
FAILED tests/unit/testing/test_run_tests_segmented_aggregate_fail_tips_once.py::test_segmented_failure_appends_aggregate_tips_once
FAILED tests/unit/testing/test_run_tests_segmented_aggregate_maxfail.py::test_segmented_aggregate_tips_command_includes_maxfail
FAILED tests/unit/testing/test_run_tests_segmented_empty_node_ids.py::test_run_tests_segmented_falls_back_on_empty_collection
FAILED tests/unit/testing/test_run_tests_segmented_failure_paths.py::test_segment_batch_failure_appends_tips - TypeError: tes...
FAILED tests/unit/testing/test_run_tests_segmented_failure_paths.py::test_segment_batch_benchmark_warning_forces_success - Ty...
========================================== 80 failed, 119 passed, 4 warnings in 6.67s ==========================================
