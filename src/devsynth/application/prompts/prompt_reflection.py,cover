> """
> Prompt Reflection module.
  
> This module defines the PromptReflection class for implementing structured
> reflection on prompt responses, enhancing explainability and prompt optimization.
> """
  
! from typing import Dict, List, Optional, Any
! import os
! import json
! from datetime import datetime
! import uuid
  
! from devsynth.logging_setup import DevSynthLogger
! from devsynth.ports.llm_port import LLMPort
  
  # Create a logger for this module
! logger = DevSynthLogger(__name__)
  
  
! class PromptReflection:
!     """
!     Implements structured reflection on prompt responses.
      
!     This class provides methods for preparing reflections, executing reflection
!     steps, and storing reflection results for future optimization.
!     """
      
!     def __init__(self, llm_port: LLMPort, storage_path: Optional[str] = None):
!         """
!         Initialize the prompt reflection system.
          
!         Args:
!             llm_port: LLM port for generating reflections
!             storage_path: Path to store reflection data (defaults to .devsynth/prompts/reflections)
!         """
!         self.llm_port = llm_port
!         self.storage_path = storage_path or os.path.join(os.getcwd(), ".devsynth", "prompts", "reflections")
!         self.reflections: Dict[str, Dict[str, Any]] = {}
          
          # Create the storage directory if it doesn't exist
!         os.makedirs(self.storage_path, exist_ok=True)
          
          # Load any existing reflection data
!         self._load_data()
          
!         logger.info(f"Prompt reflection system initialized with storage path: {self.storage_path}")
      
!     def prepare_reflection(self, template_name: str, variables: Dict[str, str], 
!                           rendered_prompt: str) -> str:
!         """
!         Prepare for reflection on a prompt response.
          
!         Args:
!             template_name: The name of the template
!             variables: The variables used to render the prompt
!             rendered_prompt: The rendered prompt
              
!         Returns:
!             A unique reflection ID
!         """
!         reflection_id = str(uuid.uuid4())
          
          # Store the reflection data
!         self.reflections[reflection_id] = {
!             "template_name": template_name,
!             "variables": variables,
!             "rendered_prompt": rendered_prompt,
!             "timestamp": datetime.now().isoformat(),
!             "response": None,
!             "reflection_result": None
!         }
          
!         self._save_data()
          
!         logger.debug(f"Prepared reflection for template '{template_name}' with ID {reflection_id}")
!         return reflection_id
      
!     def reflect(self, reflection_id: str, response: str) -> Dict[str, Any]:
!         """
!         Reflect on a prompt response.
          
!         Args:
!             reflection_id: The ID of the reflection to use
!             response: The response to reflect on
              
!         Returns:
!             A dictionary containing the reflection results
!         """
!         if reflection_id not in self.reflections:
!             logger.warning(f"No reflection found for ID {reflection_id}")
!             return {"error": f"No reflection found for ID {reflection_id}"}
          
!         reflection_data = self.reflections[reflection_id]
!         reflection_data["response"] = response
          
          # Generate the reflection
!         reflection_result = self._generate_reflection(
!             reflection_data["template_name"],
!             reflection_data["rendered_prompt"],
!             response
!         )
          
          # Store the reflection result
!         reflection_data["reflection_result"] = reflection_result
!         reflection_data["reflection_timestamp"] = datetime.now().isoformat()
          
!         self._save_data()
          
!         logger.info(f"Generated reflection for ID {reflection_id}")
!         return reflection_result
      
!     def get_reflection(self, reflection_id: str) -> Optional[Dict[str, Any]]:
!         """
!         Get a reflection by ID.
          
!         Args:
!             reflection_id: The ID of the reflection to retrieve
              
!         Returns:
!             The reflection data, or None if not found
!         """
!         return self.reflections.get(reflection_id)
      
!     def list_reflections(self, template_name: Optional[str] = None) -> List[Dict[str, Any]]:
!         """
!         List all reflections, optionally filtered by template name.
          
!         Args:
!             template_name: Optional template name to filter by
              
!         Returns:
!             A list of reflection metadata dictionaries
!         """
!         result = []
!         for reflection_id, data in self.reflections.items():
!             if template_name and data["template_name"] != template_name:
!                 continue
              
!             result.append({
!                 "reflection_id": reflection_id,
!                 "template_name": data["template_name"],
!                 "timestamp": data["timestamp"],
!                 "has_response": data["response"] is not None,
!                 "has_reflection": data["reflection_result"] is not None
!             })
          
!         return result
      
!     def _generate_reflection(self, template_name: str, prompt: str, response: str) -> Dict[str, Any]:
!         """Generate a reflection on a prompt response."""
          # Create a reflection prompt
!         reflection_prompt = f"""
!         You are a prompt optimization expert. Analyze the following prompt and response pair:
          
!         PROMPT:
!         {prompt}
          
!         RESPONSE:
!         {response}
          
!         Provide a structured analysis with the following:
!         1. Effectiveness: How well did the response address the prompt's requirements?
!         2. Completeness: Did the response cover all aspects requested in the prompt?
!         3. Clarity: Was the prompt clear and unambiguous?
!         4. Improvement suggestions: How could the prompt be improved?
!         5. Rating: Rate the prompt's effectiveness on a scale of 1-10.
          
!         Format your response as JSON with the following structure:
!         {{
!             "effectiveness": "Your analysis here",
!             "completeness": "Your analysis here",
!             "clarity": "Your analysis here",
!             "improvement_suggestions": ["Suggestion 1", "Suggestion 2", ...],
!             "rating": 7,
!             "overall_assessment": "Your overall assessment here"
!         }}
!         """
          
!         try:
              # Generate the reflection using the LLM
!             reflection_text = self.llm_port.generate(reflection_prompt)
              
              # Parse the JSON response
              # The response might have extra text before or after the JSON, so we need to extract it
!             try:
                  # Try to parse the entire response as JSON
!                 reflection_result = json.loads(reflection_text)
!             except json.JSONDecodeError:
                  # If that fails, try to extract the JSON part
!                 import re
!                 json_match = re.search(r'({[\s\S]*})', reflection_text)
!                 if json_match:
!                     try:
!                         reflection_result = json.loads(json_match.group(1))
!                     except json.JSONDecodeError:
                          # If that still fails, return a structured error
!                         logger.error(f"Failed to parse reflection response as JSON for template '{template_name}'")
!                         reflection_result = {
!                             "error": "Failed to parse reflection response as JSON",
!                             "raw_response": reflection_text
!                         }
!                 else:
                      # If no JSON-like structure is found, return a structured error
!                     logger.error(f"No JSON found in reflection response for template '{template_name}'")
!                     reflection_result = {
!                         "error": "No JSON found in reflection response",
!                         "raw_response": reflection_text
!                     }
              
!             return reflection_result
!         except Exception as e:
!             logger.error(f"Error generating reflection for template '{template_name}': {str(e)}")
!             return {
!                 "error": f"Error generating reflection: {str(e)}",
!                 "template_name": template_name
!             }
      
!     def _load_data(self) -> None:
!         """Load reflection data from the storage path."""
!         data_file = os.path.join(self.storage_path, "reflection_data.json")
!         if os.path.exists(data_file):
!             try:
!                 with open(data_file, "r") as f:
!                     self.reflections = json.load(f)
!                 logger.debug("Loaded prompt reflection data")
!             except Exception as e:
!                 logger.error(f"Error loading reflection data: {str(e)}")
!                 self.reflections = {}
!         else:
!             self.reflections = {}
      
!     def _save_data(self) -> None:
!         """Save reflection data to the storage path."""
!         data_file = os.path.join(self.storage_path, "reflection_data.json")
!         try:
!             with open(data_file, "w") as f:
!                 json.dump(self.reflections, f, indent=2)
!             logger.debug("Saved prompt reflection data")
!         except Exception as e:
!             logger.error(f"Error saving reflection data: {str(e)}")
