#!/usr/bin/env python
"""
Generate a mypy baseline report and per-module triage issue files.

- Runs mypy on src/devsynth using the project's configuration.
- Parses error output and groups by file/module.
- Writes a machine-readable JSON summary to mypy_baseline.json.
- Generates Markdown issue files under issues/triage/mypy/ for each file with errors.

Usage:
  poetry run python scripts/generate_mypy_baseline_issues.py

Notes:
- This script does not attempt to open GitHub issues. Instead, it creates
  local triage files which can be curated and turned into issues manually.
- It aligns with docs/tasks.md Task 4.1: capture baseline errors and create issues per module.
"""
from __future__ import annotations

import json
import os
import re
import subprocess
import sys
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List, Optional

ROOT = Path(__file__).resolve().parents[1]
SRC_DIR = ROOT / "src" / "devsynth"
OUT_JSON = ROOT / "mypy_baseline.json"
ISSUES_DIR = ROOT / "issues" / "triage" / "mypy"

ERR_LINE_RE = re.compile(
    r"^(?P<file>.*?):(?P<line>\d+)(?::(?P<col>\d+))?: (?P<level>error|note|warning): (?P<message>.*)$"
)


@dataclass
class MypyError:
    file: str
    line: int
    col: int | None
    level: str
    message: str


@dataclass
class FileReport:
    file: str
    error_count: int
    errors: list[MypyError]


def run_mypy() -> str:
    if not SRC_DIR.exists():
        raise SystemExit(f"[error] source directory not found: {SRC_DIR}")

    cmd = [sys.executable, "-m", "mypy", str(SRC_DIR)]
    try:
        proc = subprocess.run(cmd, capture_output=True, text=True, cwd=str(ROOT))
    except FileNotFoundError:
        raise SystemExit(
            "[error] mypy is not installed in this environment. Run: poetry install --with dev"
        )

    # mypy returns non-zero when there are type errors; that's expected. We still parse stdout.
    stdout = proc.stdout or ""
    # Some versions print notes to stderr; include for completeness.
    if proc.stderr:
        stdout += "\n" + proc.stderr

    return stdout


def parse_mypy_output(output: str) -> dict[str, list[MypyError]]:
    grouped: dict[str, list[MypyError]] = {}
    for line in output.splitlines():
        m = ERR_LINE_RE.match(line.strip())
        if not m:
            continue
        level = m.group("level")
        # Only record errors for baseline; notes/warnings can be noisy.
        if level != "error":
            continue
        file_path = os.path.relpath(m.group("file"), start=str(ROOT))
        try:
            line_no = int(m.group("line"))
        except ValueError:
            line_no = 0
        col_str = m.group("col")
        col_no = int(col_str) if col_str and col_str.isdigit() else None
        msg = m.group("message").strip()
        err = MypyError(
            file=file_path, line=line_no, col=col_no, level=level, message=msg
        )
        grouped.setdefault(file_path, []).append(err)
    return grouped


def write_json_summary(grouped: dict[str, list[MypyError]]) -> None:
    summary = {
        "total_files_with_errors": len(grouped),
        "total_errors": sum(len(v) for v in grouped.values()),
        "files": [
            asdict(FileReport(file=f, error_count=len(errs), errors=errs))
            for f, errs in sorted(grouped.items())
        ],
    }
    OUT_JSON.write_text(json.dumps(summary, indent=2))
    print(
        f"[info] wrote {OUT_JSON} (files={summary['total_files_with_errors']} errors={summary['total_errors']})"
    )


def sanitize_filename(path: str) -> str:
    # Convert a/b/c.py -> a_b_c_py
    return re.sub(r"[^A-Za-z0-9._-]", "_", path)


def gen_issue_md(file_path: str, errors: list[MypyError]) -> str:
    header = f"# Mypy baseline for {file_path}\n\n"
    meta = (
        "This issue file was auto-generated by scripts/generate_mypy_baseline_issues.py for Task 4.1 (Static analysis baseline).\n\n"
        "Context: Run mypy on src/devsynth and capture baseline errors; create issues per module.\n\n"
        "Action items:\n"
        "- [ ] Fix type errors incrementally.\n"
        "- [ ] Add/adjust annotations or narrow types where needed.\n"
        "- [ ] Consider enabling stricter checks in targeted modules once clean.\n\n"
    )
    lines = [header, meta, "## Errors\n", "\n"]
    for e in errors:
        loc = f"{file_path}:{e.line}"
        msg = e.message
        lines.append(f"- [ ] {loc}: {msg}\n")
    lines.append(
        "\n---\nGenerated: Task 4.1 on "
        + __import__("datetime").datetime.now().strftime("%Y-%m-%d")
        + "\n"
    )
    return "".join(lines)


def write_issue_files(grouped: dict[str, list[MypyError]]) -> None:
    if not grouped:
        print("[info] no mypy errors found; no issue files generated")
        return
    ISSUES_DIR.mkdir(parents=True, exist_ok=True)
    for rel_file, errs in grouped.items():
        name = sanitize_filename(rel_file)
        issue_path = ISSUES_DIR / f"MYPY_{name}.md"
        issue_path.write_text(gen_issue_md(rel_file, errs))
        print(f"[info] wrote {issue_path} ({len(errs)} errors)")


def main() -> None:
    print(f"[info] running mypy baseline against {SRC_DIR}")
    output = run_mypy()
    grouped = parse_mypy_output(output)
    write_json_summary(grouped)
    write_issue_files(grouped)


if __name__ == "__main__":
    main()
